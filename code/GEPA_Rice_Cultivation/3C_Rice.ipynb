{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridded EPA Methane Inventory\n",
    "## Category: 4C Rice Cultivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### Authors: \n",
    "Joannes D. Maasakkers, Candice F. Z. Chen, Erin E. McDuffie\n",
    "#### Date Last Updated: \n",
    "see Step 0\n",
    "#### Notebook Purpose: \n",
    "This notebook calculates gridded (0.1⁰x0.1⁰) annual and monthly emission fluxes of methane (molecules CH4/cm2/s) from rice cultivation activities in the CONUS region for the years 2012 - 2018. Emission fluxes are reported at both annual and monthly time resolution.  \n",
    "#### Summary & Notes:\n",
    "The national EPA GHGI emissions from rice cultivation are read in from the EPA GHG Inventory Rice workbook. Emissions are available as national totals (for entire time series) and state-level allocations (until 2015). National emissions are allocated to the state level using relative state-level emissions data. State-level emissions are allocated to the county level and then on to 0.01⁰x0.01⁰ grid using county and gridded data of rice harvested areas from USDA. Data are then re-gridded to 0.1⁰x0.1⁰ and converted to fluxes (molecules CH4/cm2/s). Lastly, a monthly scaling factor is applied to the annual flux data (constant for all years). Annual and monthly emission fluxes (molecules CH4/cm2/s) are written to final netCDFs in the ‘/code/Final_Gridded_Data/’ folder.  \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "## Step 0. Set-Up Notebook Modules, Functions, and Local Parameters and Constants\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirm working directory\n",
    "import os\n",
    "import time\n",
    "modtime = os.path.getmtime('./3C_Rice.ipynb')\n",
    "modificationTime = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(modtime))\n",
    "print(\"This file was last modified on: \", modificationTime)\n",
    "print('')\n",
    "print(\"The directory we are working in is {}\" .format(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Include plots within notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import base modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import datetime\n",
    "from copy import copy\n",
    "\n",
    "# Import additional modules\n",
    "# Load plotting package Basemap \n",
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "# Load netCDF (for manipulating netCDF file types)\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "# Set up ticker\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "#add path for the global function module (file)\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../Global_Functions/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# Load Tabula (for reading tables from PDFs)\n",
    "import tabula as tb   \n",
    "    \n",
    "# Load user-defined global functions (modules)\n",
    "import data_load_functions as data_load_fn\n",
    "import data_functions as data_fn\n",
    "import data_IO_functions as data_IO_fn\n",
    "import data_plot_functions as data_plot_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INPUT Files\n",
    "# Assign global file names\n",
    "global_filenames = data_load_fn.load_global_file_names()\n",
    "State_ANSI_inputfile = global_filenames[0]\n",
    "County_ANSI_inputfile = global_filenames[1]\n",
    "pop_map_inputfile = global_filenames[2]\n",
    "Grid_area01_inputfile = global_filenames[3]\n",
    "Grid_area001_inputfile = global_filenames[4]\n",
    "Grid_state001_ansi_inputfile = global_filenames[5]\n",
    "Grid_county001_ansi_inputfile = global_filenames[6]\n",
    "\n",
    "# Specify names of inputs files used in this notebook\n",
    "#EPA Data\n",
    "EPA_rice_inputfile = '../Global_InputData/GHGI/Ch5_Agriculture/Rice_1990-2018_PR_FINAL.xlsx'\n",
    "\n",
    "#Proxy Data file\n",
    "Rice_Mapping_inputfile = \"./InputData/Rice_ProxyMapping.xlsx\"\n",
    "\n",
    "\n",
    "#Activity Data\n",
    "#USDA Census Data\n",
    "State_2012rice_file = \"./InputData/Census_2012_RiceAcres_State.csv\"\n",
    "State_2017rice_file = \"./InputData/Census_2017_RiceAcres_State.csv\"\n",
    "County_2012rice_file = \"./InputData/Census_2012_RiceAcres_County.csv\"\n",
    "County_2017rice_file = \"./InputData/Census_2017_RiceAcres_County.csv\"\n",
    "\n",
    "#USDA gridded rice crop acreage\n",
    "Rice_list = \"./InputData/Rice_\"\n",
    "\n",
    "#monthly scaling factors\n",
    "Bloom_month_factors_file = './InputData/Rice_Emissions_Scenario_D_MAY16.nc'\n",
    "\n",
    "#OUTPUT FILES\n",
    "gridded_outputfile = '../Final_Gridded_Data/EPA_v2_3C_Rice_Cultivation.nc'\n",
    "netCDF_description = 'Gridded EPA Inventory - Rice Cultivation Emissions - IPCC Source Category 3C'\n",
    "netCDF_description_m = 'Gridded EPA Inventory - Monthly Rice Cultivation Emissions - IPCC Source Category 3C'\n",
    "gridded_month_outputfile = '../Final_Gridded_Data/EPA_v2_3C_Rice_Cultivation_Monthly.nc'\n",
    "title_str = \"EPA methane emissions from rice cultivation\"\n",
    "title_diff_str = \"Emissions from rice cultivation difference: 2018-2012\"\n",
    "\n",
    "#output gridded proxy data\n",
    "grid_emi_outputfile = '../Final_Gridded_Data/Extension/v2_input_data/Rice_Grid_Emi.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define local variables\n",
    "start_year = 2012  #First year in emission timeseries\n",
    "end_year = 2018    #Last year in emission timeseries\n",
    "year_range = [*range(start_year, end_year+1,1)] #List of emission years\n",
    "year_range_str=[str(i) for i in year_range]\n",
    "num_years = len(year_range)\n",
    "\n",
    "# Define constants\n",
    "Avogadro   = 6.02214129 * 10**(23)  #molecules/mol\n",
    "Molarch4   = 16.04                  #g/mol\n",
    "Res01      = 0.1                    # degrees\n",
    "Res_01     = 0.01\n",
    "tg_scale   = 0.001                  #Tg scale number [New file allows for the exclusion of the territories] \n",
    "\n",
    "# Continental US Lat/Lon Limits (for netCDF files)\n",
    "Lon_left = -130       #deg\n",
    "Lon_right = -60       #deg\n",
    "Lat_low  = 20         #deg\n",
    "Lat_up  = 55          #deg\n",
    "loc_dimensions = [Lat_low, Lat_up, Lon_left, Lon_right]\n",
    "\n",
    "ilat_start = int((90+Lat_low)/Res01) #1100:1450 (continental US range)\n",
    "ilat_end = int((90+Lat_up)/Res01)\n",
    "ilon_start = abs(int((-180-Lon_left)/Res01)) #500:1200 (continental US range)\n",
    "ilon_end = abs(int((-180-Lon_right)/Res01))\n",
    "\n",
    "# Number of days in each month\n",
    "month_day_leap  = [  31,  29,  31,  30,  31,  30,  31,  31,  30,  31,  30,  31]\n",
    "month_day_nonleap = [  31,  28,  31,  30,  31,  30,  31,  31,  30,  31,  30,  31]\n",
    "\n",
    "# Month arrays\n",
    "month_range_str = ['January','February','March','April','May','June','July','August','September','October','November','December']\n",
    "num_months = len(month_range_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.auto_scroll_threshold = 9999;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track run time\n",
    "ct = datetime.datetime.now() \n",
    "it = ct.timestamp() \n",
    "print(\"current time:\", ct) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "## Step 1. Load in State ANSI data and Area Maps\n",
    "_____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State-level ANSI Data\n",
    "#Read the state ANSI file array\n",
    "State_ANSI, name_dict = data_load_fn.load_state_ansi(State_ANSI_inputfile)[0:2]\n",
    "#QA: number of states\n",
    "print('Read input file: '+ f\"{State_ANSI_inputfile}\")\n",
    "print('Total \"States\" found: ' + '%.0f' % len(State_ANSI))\n",
    "print(' ')\n",
    "\n",
    "#County ANSI Data\n",
    "#Includes State ANSI number, county ANSI number, county name, and country area (square miles)\n",
    "County_ANSI = pd.read_csv(County_ANSI_inputfile,encoding='latin-1')\n",
    "\n",
    "#QA: number of counties\n",
    "print ('Read input file: ' + f\"{County_ANSI_inputfile}\")\n",
    "print('Total \"Counties\" found (include PR): ' + '%.0f' % len(County_ANSI))\n",
    "print(' ')\n",
    "\n",
    "#Create a placeholder array for county data\n",
    "county_array = np.zeros([len(County_ANSI),3])\n",
    "\n",
    "#Populate array with State ANSI number (0), county ANSI number (1), and county area (2)\n",
    "for icounty in np.arange(0,len(County_ANSI)):\n",
    "    county_array[icounty,0] = int(County_ANSI.values[icounty,0])\n",
    "    county_array[icounty,1] = int(County_ANSI.values[icounty,1])\n",
    "    county_array[icounty,2] = County_ANSI.values[icounty,3]\n",
    "\n",
    "# 0.01 x0.01 degree Data\n",
    "# State ANSI IDs and grid cell area (m2) maps\n",
    "state_ANSI_map = data_load_fn.load_state_ansi_map(Grid_state001_ansi_inputfile)\n",
    "state_ANSI_map = state_ANSI_map.astype('int32')\n",
    "county_ANSI_map = data_load_fn.load_county_ansi_map(Grid_county001_ansi_inputfile)\n",
    "county_ANSI_map = county_ANSI_map.astype('int32')\n",
    "area_map, lat001, lon001 = data_load_fn.load_area_map_001(Grid_area001_inputfile)\n",
    "\n",
    "# 0.1 x0.1 degree data\n",
    "# grid cell area and state and county ANSI maps\n",
    "area_map01, Lat01, Lon01 = data_load_fn.load_area_map_01(Grid_area01_inputfile)[0:3]\n",
    "#Select relevant Continental 0.1 x0.1 domain\n",
    "Lat_01 = Lat01[ilat_start:ilat_end]\n",
    "Lon_01 = Lon01[ilon_start:ilon_end]\n",
    "area_matrix_01 = data_fn.regrid001_to_01(area_map, Lat_01, Lon_01)\n",
    "area_matrix_01 *= 10000  #convert from m2 to cm2\n",
    "\n",
    "state_ANSI_map_01 = data_fn.regrid001_to_01(state_ANSI_map, Lat_01, Lon_01)\n",
    "\n",
    "# Print time\n",
    "ct = datetime.datetime.now() \n",
    "print(\"current time:\", ct) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "## Step 2: Read-in and Format Proxy Data\n",
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.1 Read In Proxy Mapping File & Make Proxy Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load GHGI Mapping Groups\n",
    "names = pd.read_excel(Rice_Mapping_inputfile, sheet_name = \"GHGI Map - Rice\", usecols = \"A:B\",skiprows = 1, header = 0)\n",
    "colnames = names.columns.values\n",
    "ghgi_rice_map = pd.read_excel(Rice_Mapping_inputfile, sheet_name = \"GHGI Map - Rice\", usecols = \"A:B\", skiprows = 1, names = colnames)\n",
    "#drop rows with no data, remove the parentheses and \"\"\n",
    "ghgi_rice_map = ghgi_rice_map[ghgi_rice_map['GHGI_Emi_Group'] != 'na']\n",
    "ghgi_rice_map = ghgi_rice_map[ghgi_rice_map['GHGI_Emi_Group'].notna()]\n",
    "ghgi_rice_map['GHGI_Source']= ghgi_rice_map['GHGI_Source'].str.replace(r\"\\(\",\"\")\n",
    "ghgi_rice_map['GHGI_Source']= ghgi_rice_map['GHGI_Source'].str.replace(r\"\\)\",\"\")\n",
    "ghgi_rice_map.reset_index(inplace=True, drop=True)\n",
    "display(ghgi_rice_map)\n",
    "\n",
    "#load emission group - proxy map\n",
    "names = pd.read_excel(Rice_Mapping_inputfile, sheet_name = \"Proxy Map - Rice\", usecols = \"A:G\",skiprows = 1, header = 0)\n",
    "colnames = names.columns.values\n",
    "proxy_rice_map = pd.read_excel(Rice_Mapping_inputfile, sheet_name = \"Proxy Map - Rice\", usecols = \"A:G\", skiprows = 1, names = colnames)\n",
    "display((proxy_rice_map))\n",
    "\n",
    "#create empty proxy and emission group arrays (add months for proxy variables that have monthly data)\n",
    "for igroup in np.arange(0,len(proxy_rice_map)):\n",
    "    if proxy_rice_map.loc[igroup, 'Grid_Month_Flag'] ==0:\n",
    "        vars()[proxy_rice_map.loc[igroup,'Proxy_Group']] = np.zeros([len(Lat_01),len(Lon_01),num_years])\n",
    "        vars()[proxy_rice_map.loc[igroup,'Proxy_Group']+'_nongrid'] = np.zeros([num_years])\n",
    "    else:\n",
    "        vars()[proxy_rice_map.loc[igroup,'Proxy_Group']] = np.zeros([len(Lat_01),len(Lon_01),num_years,num_months])\n",
    "        vars()[proxy_rice_map.loc[igroup,'Proxy_Group']+'_nongrid'] = np.zeros([num_years,num_months])\n",
    "        \n",
    "    vars()[proxy_rice_map.loc[igroup,'GHGI_Emi_Group']] = np.zeros([num_years])\n",
    "    \n",
    "    if proxy_rice_map.loc[igroup,'State_Proxy_Group'] != '-':\n",
    "        if proxy_rice_map.loc[igroup,'State_Month_Flag'] == 0:\n",
    "            vars()[proxy_rice_map.loc[igroup,'State_Proxy_Group']] = np.zeros([len(State_ANSI),num_years])\n",
    "        else:\n",
    "            vars()[proxy_rice_map.loc[igroup,'State_Proxy_Group']] = np.zeros([len(State_ANSI),num_years,num_months])\n",
    "    else:\n",
    "        continue # do not make state proxy variable if no variable assigned in mapping file\n",
    "        \n",
    "    if proxy_rice_map.loc[igroup,'County_Proxy_Group'] != '-':\n",
    "        if proxy_rice_map.loc[igroup,'County_Month_Flag'] == 0:\n",
    "            vars()[proxy_rice_map.loc[igroup,'County_Proxy_Group']] = np.zeros([len(State_ANSI),len(County_ANSI),num_years])\n",
    "        else:\n",
    "            vars()[proxy_rice_map.loc[igroup,'County_Proxy_Group']] = np.zeros([len(State_ANSI),len(County_ANSI),num_years,num_months])\n",
    "    else:\n",
    "        continue # do not make state proxy variable if no variable assigned in mapping file\n",
    "\n",
    "        \n",
    "emi_group_names = np.unique(ghgi_rice_map['GHGI_Emi_Group'])\n",
    "\n",
    "print('QA/QC: Is the number of emission groups the same for the proxy and emissions tabs?')\n",
    "if (len(emi_group_names) == len(np.unique(proxy_rice_map['GHGI_Emi_Group']))):\n",
    "    print('PASS')\n",
    "else:\n",
    "    print('FAIL')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.2. Read in the State Emissions Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#State Emissions data from the GHGI workbook will be used as the State-level proxy here\n",
    "# EPA methane emissions in units of MMT CO2e, convert to kt (/25)\n",
    "\n",
    "#initialize \n",
    "state_emis = np.zeros([len(State_ANSI),num_years])\n",
    "idx_2015 = year_range.index(2015)\n",
    "#Read in emissions\n",
    "EPA_Rice_Emissions = pd.read_excel(EPA_rice_inputfile,skiprows=3, sheet_name = 'Total Methane Emissions')\n",
    "EPA_Rice_Emissions.dropna(axis=0,inplace=True)\n",
    "\n",
    "#Remove non-state rows\n",
    "for irow in np.arange(len(EPA_Rice_Emissions)):\n",
    "    if EPA_Rice_Emissions['State'][irow] == 'Tier 1':\n",
    "        EPA_Rice_Emissions.drop([irow],inplace=True)\n",
    "    elif EPA_Rice_Emissions['State'][irow] == 'Tier 3':\n",
    "        EPA_Rice_Emissions.drop([irow],inplace=True)\n",
    "    elif EPA_Rice_Emissions['State'][irow] == 'Tier 1 Total':\n",
    "        EPA_Rice_Emissions.drop([irow],inplace=True)\n",
    "    elif EPA_Rice_Emissions['State'][irow] == 'Tier 3 Total':\n",
    "        EPA_Rice_Emissions.drop([irow],inplace=True)\n",
    "EPA_Rice_Emissions = EPA_Rice_Emissions.drop(columns = [*range(1990, start_year,1)])\n",
    "EPA_Rice_Emissions = EPA_Rice_Emissions[EPA_Rice_Emissions['State'] != 'Total'] #drop total row\n",
    "EPA_Rice_Emissions = EPA_Rice_Emissions.replace('NE',0)\n",
    "EPA_Rice_Emissions.reset_index(inplace=True, drop=True)\n",
    "\n",
    "#for all years after 2015, apply the 2013-2015 average value (to be consistant with the GHGI)\n",
    "for iyear in np.arange(0, num_years):\n",
    "    if year_range[iyear] <= 2015:\n",
    "        for istate in np.arange(0, len(EPA_Rice_Emissions)):\n",
    "            match_state = np.where(EPA_Rice_Emissions['State'][istate] == State_ANSI['name'])[0][0]\n",
    "            state_emis[match_state,iyear] = EPA_Rice_Emissions.loc[istate,year_range[iyear]]/(25*1e-3) #covert from MMT CO2e to kt\n",
    "    else:\n",
    "        state_emis[:,iyear] = np.mean(state_emis[:,idx_2015-2:idx_2015+1],axis=1)\n",
    "\n",
    "    print('Total emissions (kt)', year_range_str[iyear],np.sum(state_emis[:,iyear]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.3. Read In USDA Census/Survey data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.3.1 2012 State Census Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Make state array of 2012 rice acreage\n",
    "\n",
    "# Read in 2012 USDA Census Data\n",
    "State_temp = pd.read_csv(State_2012rice_file)\n",
    "\n",
    "Census12_State = State_temp[['State ANSI','Value']]\n",
    "# Make array with ansi, state abbreviation, and area harvested\n",
    "State_rice_12 = State_ANSI.iloc[:,[0,1]].copy()\n",
    "State_rice_12['Area_harvested'] = 0.0\n",
    "\n",
    "# place area harvested in correct state location\n",
    "for istate in np.arange(0,len(Census12_State)):\n",
    "    #print(istate)\n",
    "    # Check to see if value contains a comma. If so, remove comma.\n",
    "    if \",\" in Census12_State.loc[istate,'Value']:\n",
    "        Census12_State.loc[istate,'Value'] = Census12_State.loc[istate,'Value'].replace(\",\",\"\") #= Census12_State.loc[istate,'Value'].replace(\",\",\"\")\n",
    "    # Replace (D) in Value field with zeroes\n",
    "    if  Census12_State.loc[istate,'Value'].strip() == '(D)':\n",
    "        Census12_State.loc[istate,'Value'] = 0\n",
    "        \n",
    "    # Some census data are read in as strings. Convert all values to float.\n",
    "    Census12_State.loc[istate,'Value'] = np.float(Census12_State.loc[istate,'Value'])\n",
    "        \n",
    "    # Copy state area harvested numbers to appropriate location in State_rice\n",
    "    match_state = np.where(State_rice_12.ansi==Census12_State.loc[istate,'State ANSI'])[0][0]\n",
    "    State_rice_12.loc[match_state,'Area_harvested'] = Census12_State.loc[istate,'Value']\n",
    "    \n",
    "display(State_rice_12.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.3.2. 2017 State Census Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make state array of 2017 rice acreage\n",
    "\n",
    "# Read in 2017 USDA Census Data\n",
    "State_temp = pd.read_csv(State_2017rice_file)\n",
    "Census17_State = State_temp[['State ANSI','Value']]\n",
    "\n",
    "State_rice_17 = State_ANSI.iloc[:,[0,1]]\n",
    "State_rice_17['Area_harvested'] = 0.0\n",
    "\n",
    "for istate in np.arange(0,len(Census17_State)):\n",
    "    \n",
    "    # Check to see if value contains a comma. If so, remove comma.\n",
    "    if \",\" in Census17_State.loc[istate,'Value']:\n",
    "        Census17_State.loc[istate,'Value'] = Census17_State.loc[istate,'Value'].replace(\",\",\"\")\n",
    "\n",
    "    # Replace (D) in Value field with zeroes\n",
    "    if  Census17_State.loc[istate,'Value'].strip() == '(D)':\n",
    "        Census17_State.loc[istate,'Value'] = 0\n",
    "        \n",
    "    # Some census data are read in as strings. Convert all values to int64.\n",
    "    Census17_State.loc[istate,'Value'] = np.float(Census17_State.loc[istate,'Value'])\n",
    "        \n",
    "    # Copy state area harvested numbers to appropriate location in State_rice\n",
    "    match_state = np.where(State_rice_17.ansi==Census17_State.loc[istate,'State ANSI'])[0][0]\n",
    "    State_rice_17.loc[match_state,'Area_harvested'] = Census17_State.loc[istate,'Value']\n",
    "    \n",
    "State_rice_17.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.3.3. 2012 County data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make county array of 2012 rice acreage\n",
    "\n",
    "# Read in 2012 County census data\n",
    "County_temp = pd.read_csv(County_2012rice_file)\n",
    "Census12_County = County_temp[['State ANSI','County ANSI','Value']]\n",
    "\n",
    "County_rice_12 = County_ANSI.iloc[:,[0,1,3]]\n",
    "County_rice_12['Area_harvested'] = 0.0\n",
    "\n",
    "for icounty in np.arange(0,len(Census12_County)):\n",
    "\n",
    "    # Check to see if value contains a comma. If so, remove comma.\n",
    "    if \",\" in Census12_County.loc[icounty,'Value']:\n",
    "        Census12_County.loc[icounty,'Value'] = Census12_County.loc[icounty,'Value'].replace(\",\",\"\")\n",
    "    \n",
    "    #Replace (D) in Value field with minus ones [for excess allocation]\n",
    "    if  Census12_County.loc[icounty,'Value'].strip() == '(D)':\n",
    "        Census12_County.loc[icounty,'Value'] = -1\n",
    "    \n",
    "    #Make Value int\n",
    "    Census12_County.loc[icounty,'Value'] = int(Census12_County.loc[icounty,'Value'])\n",
    "        \n",
    "    #Replace negatives in Value field with 0 (prevent negative emissions)\n",
    "    if  Census12_County.loc[icounty,'Value'] < 0:\n",
    "        Census12_County.loc[icounty,'Value'] = 0\n",
    "    \n",
    "    # Some census data are read in as strings. Convert all values to int64.\n",
    "    Census12_County.loc[icounty,'Value'] = np.float(Census12_County.loc[icounty,'Value'])\n",
    "    \n",
    "    # Find index of the county in the County_rice array\n",
    "    match_county = np.where((County_rice_12['State']==Census12_County.loc[icounty,'State ANSI']) & \n",
    "                        (County_rice_12['County']==Census12_County.loc[icounty,'County ANSI']))[0][0]\n",
    "    County_rice_12.loc[match_county,'Area_harvested'] = Census12_County.loc[icounty,'Value']\n",
    "\n",
    "#Set one reporting Florida county to -1 to be consistent with other Florida counties\n",
    "match_county = np.where((County_rice_12['State']==12) & (County_rice_12['County']==49 ))[0][0]\n",
    "County_rice_12.loc[match_county,'Area_harvested'] = -1\n",
    "\n",
    "County_rice_12.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.3.4. 2017 County data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make county array of 2017 rice acreage\n",
    "\n",
    "#Read in USDA Census data\n",
    "County_temp = pd.read_csv(County_2017rice_file)\n",
    "Census17_County = County_temp[['State ANSI','County ANSI','Value']]\n",
    "\n",
    "County_rice_17 = County_ANSI.iloc[:,[0,1,3]]\n",
    "County_rice_17['Area_harvested'] = 0.0\n",
    "\n",
    "for icounty in np.arange(0,len(Census17_County)):\n",
    "\n",
    "    # Check to see if value contains a comma. If so, remove comma.\n",
    "    if \",\" in Census17_County.loc[icounty,'Value']:\n",
    "        Census17_County.loc[icounty,'Value'] = Census17_County.loc[icounty,'Value'].replace(\",\",\"\")\n",
    "    \n",
    "    #Replace (D) in Value field with minus ones [for excess allocation]\n",
    "    if  Census17_County.loc[icounty,'Value'].strip() == '(D)':\n",
    "        Census17_County.loc[icounty,'Value'] = -1\n",
    "    \n",
    "    #Make Value int\n",
    "    Census17_County.loc[icounty,'Value'] = int(Census17_County.loc[icounty,'Value'])\n",
    "        \n",
    "    #Replace negatives in Value field with 0 (prevent negative emissions)\n",
    "    if  Census17_County.loc[icounty,'Value'] < 0:\n",
    "        Census17_County.loc[icounty,'Value'] = 0\n",
    "    \n",
    "    # Some census data are read in as strings. Convert all values to int64.\n",
    "    Census17_County.loc[icounty,'Value'] = np.float(Census17_County.loc[icounty,'Value'])\n",
    "    \n",
    "    # Find index of the county in the County_rice array\n",
    "    match_county = np.where((County_rice_17['State']==Census17_County.loc[icounty,'State ANSI']) & \n",
    "                        (County_rice_17['County']==Census17_County.loc[icounty,'County ANSI']))[0][0]\n",
    "    County_rice_17.loc[match_county,'Area_harvested'] = Census17_County.loc[icounty,'Value']\n",
    "\n",
    "#Set one reporting Florida county to -1 to be consistent with other Florida counties\n",
    "match_county = np.where((County_rice_17['State']==12) & (County_rice_17['County']==49 ))[0][0]\n",
    "County_rice_17.loc[match_county,'Area_harvested'] = -1\n",
    "\n",
    "County_rice_17.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.4. Format USDA Census Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2.4.1 Update the USDA County-level rice harvested acreage data for 2012 and 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The sum of the county data does not equal the state total acreage. Therefore, the \n",
    "# sum of state and county data are\n",
    "# compared for each state, and the 'missing' data for each relevant county is estimated based on the ratio of \n",
    "# 'missing' acres to total area in that county\n",
    "\n",
    "\n",
    "# For both 2012 and 2017...\n",
    "# 1a) Record the area of rice harvested in each state (from the state census and sum of country census data).\n",
    "# 1b) if county data is missing (area harvest ==-1), then add the total area for that county \n",
    "#     in a running state sum\n",
    "# 2)  For the states with missing county data, calculate the ratio of the missing data per \n",
    "#     county area\n",
    "# 3)  Calculate the missing acres at the state level \n",
    "\n",
    "#Initialize variables\n",
    "State_rice_Area_harvested_12 = np.array(State_rice_12['Area_harvested'])\n",
    "State_rice_Area_harvested_17 = np.array(State_rice_17['Area_harvested'])\n",
    "County_rice_Area_harvested_12 = np.array(County_rice_12['Area_harvested'])\n",
    "County_rice_Area_harvested_17 = np.array(County_rice_17['Area_harvested'])\n",
    "\n",
    "\n",
    "## 1) Record Area where data is Missing\n",
    "\n",
    "#Save the sum of the harvested area for each state (from sum of county data)\n",
    "# Also record the area in each county and state that does not report rice area harvested\n",
    "\n",
    "#2012 Data\n",
    "Census_summary_RH_State_12 = np.zeros(len(State_ANSI))\n",
    "Census_summary_RH_County_12 = np.zeros(len(State_ANSI))\n",
    "Census_summary_RH_Missing_Area_12 = np.zeros(len(State_ANSI))\n",
    "Census_summary_RH_per_area_12 = np.zeros(len(State_ANSI))\n",
    "\n",
    "for istate in np.arange(0,len(State_rice_12)):\n",
    "    # Copy state rice harvested numbers to appropriate location in State_rice\n",
    "    match_state = np.where(State_ANSI['ansi']==State_rice_12.ansi[istate])[0][0]\n",
    "    Census_summary_RH_State_12[match_state] = State_rice_Area_harvested_12[istate]\n",
    "\n",
    "for icounty in np.arange(0,len(County_rice_12)):\n",
    "    match_state = np.where(State_ANSI['ansi']==County_rice_12['State'][icounty])[0][0]\n",
    "    #Add all county totals for the state together [don't add -1]\n",
    "    if County_rice_Area_harvested_12[icounty] > 0:\n",
    "        Census_summary_RH_County_12[match_state] += County_rice_Area_harvested_12[icounty]\n",
    "    # If area is missing in the county census data, save the total area for each missing county for each state\n",
    "    if (County_rice_Area_harvested_12[icounty] == -1):        \n",
    "        #Add area of counties missing rice harvested numbers\n",
    "        Census_summary_RH_Missing_Area_12[match_state] += County_rice_12['Area'][icounty]\n",
    "\n",
    "#Set Florida to 1 to allocate to correct counties\n",
    "Census_summary_RH_State_12[State_ANSI.index[State_ANSI['abbr'] =='FL'].tolist()[0]] = 1.0\n",
    "\n",
    "\n",
    "#2017 Data\n",
    "Census_summary_RH_State_17 = np.zeros(len(State_ANSI))\n",
    "Census_summary_RH_County_17 = np.zeros(len(State_ANSI))\n",
    "Census_summary_RH_Missing_Area_17 = np.zeros(len(State_ANSI))\n",
    "Census_summary_RH_per_area_17 = np.zeros(len(State_ANSI))\n",
    "\n",
    "for istate in np.arange(0,len(State_rice_17)):\n",
    "    # Copy state rice harvested numbers to appropriate location in State_rice\n",
    "    match_state = np.where(State_ANSI['ansi']==State_rice_17.ansi[istate])[0][0]\n",
    "    Census_summary_RH_State_17[match_state] = State_rice_Area_harvested_17[istate]\n",
    "\n",
    "for icounty in np.arange(0,len(County_rice_17)):\n",
    "    match_state = np.where(State_ANSI['ansi']==County_rice_17['State'][icounty])[0][0]\n",
    "    #Add all county totals for the state together [don't add -1]\n",
    "    if County_rice_Area_harvested_17[icounty] > 0:\n",
    "        Census_summary_RH_County_17[match_state] += County_rice_Area_harvested_17[icounty]\n",
    "    if (County_rice_Area_harvested_17[icounty] == -1):        \n",
    "        #Add area of counties missing rice harvested numbers\n",
    "        Census_summary_RH_Missing_Area_17[match_state] += County_rice_17['Area'][icounty]\n",
    "\n",
    "#Set Florida to 1 to allocate to correct counties\n",
    "Census_summary_RH_State_17[State_ANSI.index[State_ANSI['abbr'] =='FL'].tolist()[0]] = 1.0\n",
    "\n",
    "\n",
    "\n",
    "##2) Calculate missing acres per area\n",
    "\n",
    "# Calculate the fraction of harvested rice that was not recorded (per area)\n",
    "# = (state data - available county data)/ missing state area data\n",
    "\n",
    "#2012\n",
    "for istate in np.arange(0,len(State_ANSI)):\n",
    "    if Census_summary_RH_Missing_Area_12[istate] > 0:\n",
    "        #Calculate number of \"extra\" rice acres per unit area for each state ((state sum - county sum)/missing area)\n",
    "        Census_summary_RH_per_area_12[istate] = (np.float64(Census_summary_RH_State_12[istate]) - \n",
    "            np.float64(Census_summary_RH_County_12[istate])) / np.float64(Census_summary_RH_Missing_Area_12[istate])\n",
    "    else:\n",
    "        Census_summary_RH_per_area_12[istate] = 0.0\n",
    "    #Make sure we don't have negative areas\n",
    "    if (Census_summary_RH_per_area_12[istate] < 0):\n",
    "        Census_summary_RH_per_area_12[istate] = 0.0\n",
    "\n",
    "#2017 data\n",
    "for istate in np.arange(0,len(State_ANSI)):\n",
    "    if Census_summary_RH_Missing_Area_17[istate] > 0:\n",
    "        #Calculate number of \"extra\" acres rice per unit area for each state\n",
    "        Census_summary_RH_per_area_17[istate] = (np.float64(Census_summary_RH_State_17[istate]) - \n",
    "            np.float64(Census_summary_RH_County_17[istate])) / np.float64(Census_summary_RH_Missing_Area_17[istate])\n",
    "    else:\n",
    "        Census_summary_RH_per_area_17[istate] = 0.0\n",
    "    #Make sure we don't have negative areas\n",
    "    if (Census_summary_RH_per_area_17[istate] < 0):\n",
    "        Census_summary_RH_per_area_17[istate] = 0.0\n",
    "        \n",
    "        \n",
    "## 3) Calculate missing county rice data ( = rice harvest per county area * county area)\n",
    "\n",
    "#2012\n",
    "for icounty in np.arange(0,len(County_rice_12)):\n",
    "    match_state = np.where(State_ANSI['ansi']==County_rice_12['State'][istate])[0][0]\n",
    "    if (County_rice_Area_harvested_12[icounty] == -1):\n",
    "        County_rice_Area_harvested_12[icounty] = Census_summary_RH_per_area_12[match_state] * County_rice_12['Area'][icounty]\n",
    "\n",
    "#2017\n",
    "for icounty in np.arange(0,len(County_rice_17)):\n",
    "    match_state = np.where(State_ANSI['ansi']==County_rice_17['State'][icounty])[0][0]\n",
    "    if (County_rice_Area_harvested_17[icounty] == -1):\n",
    "        County_rice_Area_harvested_17[icounty] = Census_summary_RH_per_area_17[match_state] * County_rice_17['Area'][icounty]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2.4.2. Use County data to find total area and total rice area harvest in each state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2012\n",
    "\n",
    "print('QA/QC: Check formatting')\n",
    "# Use county data to sum total area and total area rice harvested\n",
    "State_total_Area_12 = np.zeros(len(State_ANSI))\n",
    "State_total_Area_harvested_12 = np.zeros(len(State_ANSI))\n",
    "    \n",
    "for icounty in np.arange(0,len(County_rice_12)):\n",
    "    match_state = np.where(State_ANSI['ansi']==County_rice_12['State'][icounty])[0][0]\n",
    "\n",
    "    # Add all county totals for the state together\n",
    "    State_total_Area_12[match_state] += County_rice_12['Area'][icounty].astype(float)\n",
    "    State_total_Area_harvested_12[match_state] += County_rice_Area_harvested_12[icounty]\n",
    "\n",
    "print('2012 Should be zero: ')\n",
    "print(np.min(County_rice_Area_harvested_12))\n",
    "\n",
    "\n",
    "#2017\n",
    "\n",
    "#First calculate the area of each state from the county \n",
    "State_total_Area_17 = np.zeros(len(State_ANSI))\n",
    "State_total_Area_harvested_17 = np.zeros(len(State_ANSI))\n",
    "    \n",
    "for icounty in np.arange(0,len(County_rice_17)):\n",
    "    match_state = np.where(State_ANSI['ansi']==County_rice_17['State'][icounty])[0][0]\n",
    "    \n",
    "    # Add all county totals for the state together\n",
    "    State_total_Area_17[match_state] += County_rice_17['Area'][icounty].astype(float)\n",
    "    State_total_Area_harvested_17[match_state] += County_rice_Area_harvested_17[icounty]\n",
    "\n",
    "print('2017 Should be zero: ')\n",
    "print(np.min(County_rice_Area_harvested_17))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2.4.3 Interpolate County Area Harvested to Gap Fill Remaining Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#1 ) State Data\n",
    "#Create array to hold rice state data\n",
    "State_total_Area_harvested = np.zeros([len(State_ANSI),num_years])\n",
    "\n",
    "#Find average annual change 2012-2017\n",
    "State_slope = (State_total_Area_harvested_17-State_total_Area_harvested_12)/5\n",
    "\n",
    "#Calculate 2013-2016, 2018 & store in array:\n",
    "for iyear in np.arange(0,num_years):\n",
    "    State_total_Area_harvested[:,iyear] = State_total_Area_harvested_12 + iyear*State_slope\n",
    "\n",
    "\n",
    "#2) County Data\n",
    "#Create array to hold rice county data\n",
    "County_rice_Area_harvested = np.zeros([len(County_ANSI),num_years])\n",
    "\n",
    "#Find average annual change 2012-2017\n",
    "County_slope = (County_rice_Area_harvested_17-County_rice_Area_harvested_12)/5\n",
    "\n",
    "#Calculate 2013-2016, 2018:\n",
    "for iyear in np.arange(0,num_years):\n",
    "    County_rice_Area_harvested[:,iyear] = County_rice_Area_harvested_12 + iyear*County_slope\n",
    "County_rice_Area_harvested[County_rice_Area_harvested<0] = 0\n",
    "    \n",
    "#Make proxy matrix\n",
    "map_county_harvest_area = np.zeros([len(State_ANSI),len(County_ANSI),num_years])\n",
    "for iyear in np.arange(0,num_years):\n",
    "    for icounty in np.arange(0,len(County_ANSI)):\n",
    "        istate = np.where(State_ANSI['ansi']==County_ANSI['State'][icounty])[0][0]\n",
    "        map_county_harvest_area[istate,icounty,iyear] = County_rice_Area_harvested[icounty,iyear]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.5 Read in and create yearly gridded rice crop area arrays (from the USDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make year specific gridded areas of the total area of rice crops (from USDA) (0.1 x0.1)\n",
    " \n",
    "rice_array = np.zeros([len(lat001), len(lon001), num_years])\n",
    "rice_array_nongrid = np.zeros(num_years)\n",
    "rice_county_sum = np.zeros([len(State_ANSI), len(County_ANSI), num_years])\n",
    "\n",
    "print('QA/QC: Check Gridded Area Sums')\n",
    "for iyear in np.arange(0, num_years):\n",
    "    filename = Rice_list + year_range_str[iyear]+ '_001x001.csv'\n",
    "    Rice_list_temp = pd.read_csv(filename)\n",
    "    \n",
    "    for idx in np.arange(len(Rice_list_temp)):\n",
    "        #Filter inside domain\n",
    "        if Rice_list_temp['Longitude'][idx] > Lon_left and Rice_list_temp['Longitude'][idx] < Lon_right and \\\n",
    "               Rice_list_temp['Latitude'][idx] > Lat_low and Rice_list_temp['Latitude'][idx] < Lat_up:\n",
    "            #Set ilon and ilat\n",
    "            ilat = int((Rice_list_temp['Latitude'][idx] - Lat_low)/Res_01)\n",
    "            ilon = int((Rice_list_temp['Longitude'][idx] - Lon_left)/Res_01)\n",
    "            rice_array[ilat,ilon,iyear] += Rice_list_temp['SUM_Area_Rice'][idx]\n",
    "        else:\n",
    "            rice_array_nongrid[iyear] += Rice_list_temp['SUM_Area_Rice'][idx]\n",
    "\n",
    "    sum_area = np.sum(rice_array[:,:,iyear])+np.sum(rice_array_nongrid[iyear])\n",
    "    net_area = np.sum(Rice_list_temp['SUM_Area_Rice'])\n",
    "    area_diff = abs((sum_area - net_area)/((net_area+sum_area)/2))\n",
    "    if abs(area_diff) < 0.0001:\n",
    "        print('Year '+ year_range_str[iyear]+': Difference < 0.01%: PASS')\n",
    "    else: \n",
    "        print('Year '+ year_range_str[iyear]+': Difference > 0.01%: FAIL, diff: '+str(area_diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "## Step 3. Read in and Format US EPA GHGI Emissions\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in emissions total EPA emissions (in MMT CO2e, converted to kt)\n",
    "EPA_Rice_Emissions = pd.read_excel(EPA_rice_inputfile,skiprows=3, sheet_name = 'Total Methane Emissions')\n",
    "EPA_Rice_Emissions.dropna(axis=0,inplace=True)\n",
    "\n",
    "#Remove non-state rows\n",
    "for irow in np.arange(len(EPA_Rice_Emissions)):\n",
    "    if EPA_Rice_Emissions['State'][irow] == 'Tier 1':\n",
    "        EPA_Rice_Emissions.drop([irow],inplace=True)\n",
    "    elif EPA_Rice_Emissions['State'][irow] == 'Tier 3':\n",
    "        EPA_Rice_Emissions.drop([irow],inplace=True)\n",
    "    elif EPA_Rice_Emissions['State'][irow] == 'Tier 1 Total':\n",
    "        EPA_Rice_Emissions.drop([irow],inplace=True)\n",
    "    elif EPA_Rice_Emissions['State'][irow] == 'Tier 3 Total':\n",
    "        EPA_Rice_Emissions.drop([irow],inplace=True)\n",
    "EPA_Rice_Emissions = EPA_Rice_Emissions.drop(columns = [*range(1990, start_year,1)])\n",
    "EPA_Rice_Emissions = EPA_Rice_Emissions[EPA_Rice_Emissions['State'] == 'Total'] #drop total row\n",
    "EPA_Rice_Emissions.rename(columns={EPA_Rice_Emissions.columns[0]:'Source'}, inplace=True)\n",
    "EPA_Rice_Emissions.reset_index(inplace=True, drop=True)\n",
    "for iyear in np.arange(0,num_years):\n",
    "    EPA_Rice_Emissions.iloc[0,iyear+1] = EPA_Rice_Emissions.iloc[0,iyear+1]/(25*1e-3)\n",
    "display(EPA_Rice_Emissions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Split Emissions into Gridding Groups (each Group will have the same proxy applied during the state allocation/gridding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#split emissions into scaling groups\n",
    "# In this case, data are only availabe for total emissions\n",
    "\n",
    "DEBUG =1\n",
    "\n",
    "start_year_idx = EPA_Rice_Emissions.columns.get_loc((start_year))\n",
    "end_year_idx = EPA_Rice_Emissions.columns.get_loc((end_year))+1\n",
    "ghgi_rice_groups = ghgi_rice_map['GHGI_Emi_Group'].unique()\n",
    "sum_emi = np.zeros([num_years])\n",
    "\n",
    "\n",
    "for igroup in np.arange(0,len(ghgi_rice_groups)): #loop through all groups, finding the GHGI sources in that group and summing emissions for that region, year        vars()[ghgi_prod_groups[igroup]] = np.zeros([num_regions-1,num_years])\n",
    "    ##DEBUG## print(ghgi_rice_groups[igroup])\n",
    "    vars()[ghgi_rice_groups[igroup]] = np.zeros([num_years])\n",
    "    source_temp = ghgi_rice_map.loc[ghgi_rice_map['GHGI_Emi_Group'] == ghgi_rice_groups[igroup], 'GHGI_Source']\n",
    "    pattern_temp  = '|'.join(source_temp) \n",
    "    emi_temp = EPA_Rice_Emissions[EPA_Rice_Emissions['Source'].str.contains(pattern_temp)]\n",
    "    ##DEBUG## display(emi_temp)\n",
    "    vars()[ghgi_rice_groups[igroup]][:] = emi_temp.iloc[:,start_year_idx:].sum()\n",
    "    ##DEBUG## display(vars()[ghgi_rice_groups[igroup]][:])\n",
    "        \n",
    "        \n",
    "#Check against total summary emissions \n",
    "print('QA/QC #1: Check Processing Emission Sum against GHGI Summary Emissions')\n",
    "for iyear in np.arange(0,num_years): \n",
    "    for igroup in np.arange(0,len(ghgi_rice_groups)):\n",
    "        sum_emi[iyear] += vars()[ghgi_rice_groups[igroup]][iyear]\n",
    "        \n",
    "    summary_emi = EPA_Rice_Emissions.iloc[0,iyear+1]  \n",
    "    diff1 = abs(sum_emi[iyear] - summary_emi)/((sum_emi[iyear] + summary_emi)/2)\n",
    "    if DEBUG ==1:\n",
    "        print(summary_emi)\n",
    "        print(sum_emi[iyear])\n",
    "    if diff1 < 0.0001:\n",
    "        print('Year ', year_range[iyear],': PASS, difference < 0.01%')\n",
    "    else:\n",
    "        print('Year ', year_range[iyear],': FAIL (check Production & summary tabs): ', diff1,'%') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "## Step 4. Grid Data\n",
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4.1. Allocate emissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 4.1.1 Assign the Appropriate Proxy Variable Names (state & grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The names on the *left* need to match the 'Stationary_ProxyMapping' 'State_Proxy_Group' names \n",
    "# (these are initialized in Step 2). \n",
    "# The names on the *right* are the variable names used to caluclate the proxies in this code.\n",
    "# Names on the right need to match those from the code in Step 2\n",
    "\n",
    "#national --> state proxies (state x year [X month])\n",
    "State_Emis = state_emis\n",
    "\n",
    "#state --> county proxies (state x county x year)\n",
    "County_rice_acreage = map_county_harvest_area\n",
    "\n",
    "#county --> grid proxies (0.01x0.01)\n",
    "Map_rice_area = rice_array\n",
    "Map_rice_area_nongrid = rice_array_nongrid\n",
    "\n",
    "\n",
    "\n",
    "# remove variables to clear space for larger arrays \n",
    "#del sedsind_coal_state,sedsind_wood_state,sedsind_oil_state,sedsind_gas_state,sedsres_coal_state,sedsres_wood_state\n",
    "##del sedsres_oil_state,sedsres_gas_state,sedscom_coal_state,sedscom_wood_state,sedscom_oil_state,sedscom_gas_state\n",
    "#del arp_wood_array,arp_wood_array_nongrid,arp_coal_array,arp_coal_array_nongrid,arp_oil_array,arp_oil_array_nongrid\n",
    "#del arp_gas_array,arp_gas_array_nongrid,ghgrp_emi_array,ghgrp_emi_array_nongrid,pop_den_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 4.1.2 Allocate National EPA Emissions to the State-Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate state-level emissions \n",
    "# Emissions in kt\n",
    "# State data = national GHGI emissions * state proxy/national total\n",
    "\n",
    "DEBUG = 1\n",
    "\n",
    "# Note that national emissions are retained for groups that do not have state proxies (identified in the mapping file)\n",
    "# and are gridded in the next step\n",
    "\n",
    "# Make placeholder emission arrays for each group\n",
    "for igroup in np.arange(0,len(proxy_rice_map)):\n",
    "    vars()['State_'+proxy_rice_map.loc[igroup,'GHGI_Emi_Group']] = np.zeros([len(State_ANSI),num_years])\n",
    "    vars()['NonState_'+proxy_rice_map.loc[igroup,'GHGI_Emi_Group']] = np.zeros([num_years])\n",
    "        \n",
    "#Loop over years\n",
    "for iyear in np.arange(num_years):\n",
    "    #Loop over states\n",
    "    for istate in np.arange(len(State_ANSI)):\n",
    "        for igroup in np.arange(0,len(proxy_rice_map)):    \n",
    "            if proxy_rice_map.loc[igroup,'State_Proxy_Group'] != '-' and proxy_rice_map.loc[igroup,'GHGI_Emi_Group'] != 'Emi_not_mapped':\n",
    "                vars()['State_'+proxy_rice_map.loc[igroup,'GHGI_Emi_Group']][istate,iyear] = \\\n",
    "                    vars()[proxy_rice_map.loc[igroup,'GHGI_Emi_Group']][iyear]* \\\n",
    "                    data_fn.safe_div(vars()[proxy_rice_map.loc[igroup,'State_Proxy_Group']][istate,iyear], \\\n",
    "                                     np.sum(vars()[proxy_rice_map.loc[igroup,'State_Proxy_Group']][:,iyear]))   \n",
    "            else:\n",
    "                vars()['NonState_'+proxy_rice_map.loc[igroup,'GHGI_Emi_Group']][iyear] = vars()[proxy_rice_map.loc[igroup,'GHGI_Emi_Group']][iyear]\n",
    "                \n",
    "# Check sum of all gridded emissions + emissions not included in state allocation\n",
    "print('QA/QC #1: Check weighted emissions against GHGI')   \n",
    "for iyear in np.arange(0,num_years):\n",
    "    summary_emi = EPA_Rice_Emissions.iloc[0,iyear+1] \n",
    "    calc_emi = 0\n",
    "    for igroup in np.arange(0,len(proxy_rice_map)):\n",
    "        calc_emi +=  np.sum(vars()['State_'+proxy_rice_map.loc[igroup,'GHGI_Emi_Group']][:,iyear])+\\\n",
    "            vars()['NonState_'+proxy_rice_map.loc[igroup,'GHGI_Emi_Group']][iyear] #np.sum(Emissions[:,iyear]) + Emissions_nongrid[iyear] + Emissions_nonstate[iyear]\n",
    "    if DEBUG ==1:\n",
    "        print(summary_emi)\n",
    "        print(calc_emi)\n",
    "    diff = abs(summary_emi-calc_emi)/((summary_emi+calc_emi)/2)\n",
    "    if diff < 0.0001:\n",
    "        print('Year ', year_range[iyear], ': PASS, difference < 0.01%')\n",
    "    else:\n",
    "        print('Year ', year_range[iyear], ': FAIL -- Difference = ', diff*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.3 Allocate emissions to the county level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate state-level emissions for commencial, residential, and industrial sectors\n",
    "# Emissions in kt\n",
    "# State data = national GHGI emissions * state proxy/national total\n",
    "\n",
    "DEBUG = 1\n",
    "\n",
    "# Make placeholder emission arrays for each group\n",
    "for igroup in np.arange(0,len(proxy_rice_map)):\n",
    "    vars()['County_'+proxy_rice_map.loc[igroup,'GHGI_Emi_Group']] = \\\n",
    "            np.zeros([len(State_ANSI),len(County_ANSI),num_years])\n",
    "    vars()['NonCounty_'+proxy_rice_map.loc[igroup,'GHGI_Emi_Group']] = np.zeros([num_years])\n",
    "        \n",
    "#Loop over years\n",
    "for iyear in np.arange(0,num_years):\n",
    "    for icounty in np.arange(0,len(County_ANSI)):\n",
    "        istate = np.where(State_ANSI['ansi']==County_ANSI['State'][icounty])[0][0]\n",
    "        state_ansi = State_ANSI['ansi'][istate]\n",
    "        for igroup in np.arange(0,len(proxy_rice_map)):    \n",
    "            emi_temp = vars()['State_'+proxy_rice_map.loc[igroup,'GHGI_Emi_Group']][istate,iyear]\n",
    "            frac_temp = data_fn.safe_div(vars()[proxy_rice_map.loc[igroup,'County_Proxy_Group']][istate,icounty,iyear], \\\n",
    "                            np.sum(vars()[proxy_rice_map.loc[igroup,'County_Proxy_Group']][istate,:,iyear]))\n",
    "            if emi_temp > 0 and frac_temp > 0:\n",
    "                vars()['County_'+proxy_rice_map.loc[igroup,'GHGI_Emi_Group']][istate,icounty,iyear] = emi_temp * frac_temp\n",
    "            elif emi_temp > 0 and np.sum(vars()[proxy_rice_map.loc[igroup,'County_Proxy_Group']][istate,:,iyear]) == 0:\n",
    "                \n",
    "                frac_temp = data_fn.safe_div(County_ANSI.loc[icounty,'Area'],np.sum(County_ANSI['Area'][County_ANSI['State'] == state_ansi]))\n",
    "                vars()['County_'+proxy_rice_map.loc[igroup,'GHGI_Emi_Group']][istate,icounty,iyear] = emi_temp * frac_temp  \n",
    "            else:\n",
    "                vars()['NonCounty_'+proxy_rice_map.loc[igroup,'GHGI_Emi_Group']][iyear] = \\\n",
    "                    np.sum(vars()['State_'+proxy_rice_map.loc[igroup,'GHGI_Emi_Group']][istate,iyear])\n",
    "\n",
    "# Check sum of all gridded emissions + emissions not included in state allocation\n",
    "print('QA/QC #1: Check weighted emissions against GHGI')   \n",
    "for iyear in np.arange(0,num_years):\n",
    "    summary_emi = EPA_Rice_Emissions.iloc[0,iyear+1] \n",
    "    calc_emi = 0\n",
    "    for igroup in np.arange(0,len(proxy_rice_map)):\n",
    "        calc_emi +=  np.sum(vars()['County_'+proxy_rice_map.loc[igroup,'GHGI_Emi_Group']][:,:,iyear])+\\\n",
    "            vars()['NonCounty_'+proxy_rice_map.loc[igroup,'GHGI_Emi_Group']][iyear]\n",
    "    if DEBUG ==1:\n",
    "        print(summary_emi)\n",
    "        print(calc_emi)\n",
    "    diff = abs(summary_emi-calc_emi)/((summary_emi+calc_emi)/2)\n",
    "    if diff < 0.0001:\n",
    "        print('Year ', year_range[iyear], ': PASS, difference < 0.01%')\n",
    "    else:\n",
    "        print('Year ', year_range[iyear], ': FAIL -- Difference = ', diff*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.4 Allocate county emissions to the CONUS region (0.1x0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Allocate County-Level emissions (kt) onto a 0.1x0.1 grid using gridcell level 'Proxy_Groups'\n",
    "\n",
    "DEBUG =1\n",
    "#Define emission arrays\n",
    "Emissions_array_01 = np.zeros([len(Lat_01),len(Lon_01),num_years])\n",
    "#Emissions_array_001 = np.zeros([len(lat001),len(lon001),num_years])\n",
    "Emissions_nongrid = np.zeros([num_years])\n",
    "\n",
    "\n",
    "# For each year, (2a) distribute state-level emissions onto a grid using proxies defined above ....\n",
    "# To speed up the code, masks are used rather than looping individually through each lat/lon. \n",
    "# In this case, a mask of 1's is made for the grid cells that match the ANSI values for a given state\n",
    "# The masked values are set to zero, remaining values = 1. \n",
    "# AK and HI and territories are removed from the analysis at this stage. \n",
    "# The emissions allocated to each state are at 0.01x0.01 degree resolution, as required to calculate accurate 'mask'\n",
    "# arrays for each state. \n",
    "# (2b - not applicable here) For emission groups that were not first allocated to states, national emissions for those groups are gridded\n",
    "# based on the relevant gridded proxy arrays (0.1x0.1 resolution). These emissions are at 0.1x0.1 degrees resolution. \n",
    "# (2c - not applicable here) - record 'not mapped' emission groups in the 'non-grid' array# For the state on MN - the EPA GHGI includes Rice emissions for the state of MN, however the USDA does not \n",
    "# include rice harvested area for this state. Therefore, emissions are allocated based on the total area in that country\n",
    "\n",
    "print('**QA/QC Check: Sum of national gridded emissions vs. GHGI national emissions')\n",
    "  \n",
    "# for iyear in np.arange(0,num_years):\n",
    "    #calc_mn = 0\n",
    "    \n",
    "#1. Step through each gridding group\n",
    "for igroup in np.arange(0,len(proxy_rice_map)):\n",
    "    proxy_temp = vars()[proxy_rice_map.loc[igroup,'Proxy_Group']]\n",
    "    proxy_temp_nongrid = vars()[proxy_rice_map.loc[igroup,'Proxy_Group']+'_nongrid']\n",
    "    vars()['Ext_'+proxy_rice_map.loc[igroup,'GHGI_Emi_Group']] = np.zeros([len(Lat_01),len(Lon_01),num_years])\n",
    "    \n",
    "    #2a. Step through each county (if group was previously allocated to county level)\n",
    "    if proxy_rice_map.loc[igroup,'County_Proxy_Group'] != '-' and proxy_rice_map.loc[igroup,'County_Proxy_Group'] != 'state_not_mapped':\n",
    "        for icounty in np.arange(0,len(County_ANSI)):\n",
    "            print(icounty, 'of',len(County_ANSI))\n",
    "            istate = np.where(State_ANSI['ansi']==County_ANSI['State'][icounty])[0][0]\n",
    "            #print(icounty, istate)\n",
    "            if State_ANSI['abbr'][istate] not in {'AK','HI'} and istate < 51:\n",
    "                #print()\n",
    "                mask_county = np.ma.ones(np.shape(county_ANSI_map))\n",
    "                mask_county = np.ma.masked_where(county_ANSI_map != County_ANSI['County'][icounty], mask_county)\n",
    "                mask_county = np.ma.masked_where(state_ANSI_map != County_ANSI['State'][icounty], mask_county)\n",
    "                mask_county = np.ma.filled(mask_county,0)\n",
    "                for iyear in np.arange(0,num_years):\n",
    "                    county_temp = vars()['County_'+proxy_rice_map.loc[igroup,'GHGI_Emi_Group']][istate,icounty,iyear]\n",
    "                    if county_temp > 0 :\n",
    "                        if np.sum(mask_county*proxy_temp[:,:,iyear]) > 0: \n",
    "                            weighted_array = data_fn.safe_div(mask_county*proxy_temp[:,:,iyear],np.sum(mask_county*proxy_temp[:,:,iyear]))\n",
    "                            weighted_array_01 = data_fn.regrid001_to_01(weighted_array, Lat_01, Lon_01)\n",
    "                            Emissions_array_01[:,:,iyear] += county_temp*weighted_array_01\n",
    "                            vars()['Ext_'+proxy_rice_map.loc[igroup,'GHGI_Emi_Group']][:,:,iyear]+= county_temp*weighted_array_01\n",
    "                        elif np.sum(mask_county*proxy_temp[:,:,iyear]) == 0:\n",
    "                            # if there is no rice harvested data, but there are county emissions, weighted by area in county... \n",
    "                            weighted_array = data_fn.safe_div(mask_county*area_map[:,:],np.sum(mask_county*area_map[:,:]))\n",
    "                            weighted_array_01 = data_fn.regrid001_to_01(weighted_array, Lat_01, Lon_01)\n",
    "                            Emissions_array_01[:,:,iyear] += county_temp*weighted_array_01\n",
    "                            vars()['Ext_'+proxy_rice_map.loc[igroup,'GHGI_Emi_Group']][:,:,iyear]+= county_temp*weighted_array_01\n",
    "                        else:\n",
    "                            Emissions_nongrid[iyear] += county_temp\n",
    "            else:\n",
    "                for iyear in np.arange(0, num_years):\n",
    "                    county_temp = vars()['County_'+proxy_rice_map.loc[igroup,'GHGI_Emi_Group']][istate,icounty,iyear]\n",
    "                    Emissions_nongrid[iyear] += county_temp \n",
    "    \n",
    "for iyear in np.arange(0, num_years):    \n",
    "    calc_emi = np.sum(Emissions_array_01[:,:,iyear]) + np.sum(Emissions_nongrid[iyear]) \n",
    "    calc_emi2 = 0\n",
    "    for igroup in np.arange(0,len(proxy_rice_map)):\n",
    "        calc_emi2 += np.sum(vars()['Ext_'+proxy_rice_map.loc[igroup,'GHGI_Emi_Group']][:,:,iyear])\n",
    "    calc_emi2 += np.sum(Emissions_nongrid[iyear]) \n",
    "    summary_emi = EPA_Rice_Emissions.iloc[0,iyear+1] \n",
    "    emi_diff = abs(summary_emi-calc_emi)/((summary_emi+calc_emi)/2)\n",
    "    if DEBUG ==1:\n",
    "        print(summary_emi)\n",
    "        print(calc_emi)\n",
    "        print(calc_emi2)\n",
    "    diff = abs(summary_emi-calc_emi)/((summary_emi+calc_emi)/2)\n",
    "    if diff < 0.0001:\n",
    "        print('Year ', year_range[iyear], ': PASS, difference < 0.01%')\n",
    "    else:\n",
    "        print('Year ', year_range[iyear], ': FAIL -- Difference = ', diff*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4.1.4 Save gridded emissions (kt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save gridded emissions for each gridding group - for extension\n",
    "\n",
    "#Initialize file\n",
    "data_IO_fn.initialize_netCDF(grid_emi_outputfile, netCDF_description, 0, year_range, loc_dimensions, Lat_01, Lon_01)\n",
    "\n",
    "unique_groups = np.unique(proxy_rice_map['GHGI_Emi_Group'])\n",
    "unique_groups = unique_groups[unique_groups != 'Emi_not_mapped']\n",
    "\n",
    "nc_out = Dataset(grid_emi_outputfile, 'r+', format='NETCDF4')\n",
    "\n",
    "for igroup in np.arange(0,len(unique_groups)):\n",
    "    print('Ext_'+unique_groups[igroup])\n",
    "    if len(np.shape(vars()['Ext_'+unique_groups[igroup]])) ==4:\n",
    "        ghgi_temp = np.sum(vars()[unique_groups[igroup]],axis=3) #sum month data if data is monthly\n",
    "    else:\n",
    "        ghgi_temp = vars()['Ext_'+unique_groups[igroup]]\n",
    "\n",
    "    # Write data to netCDF\n",
    "    data_out = nc_out.createVariable('Ext_'+unique_groups[igroup], 'f8', ('lat', 'lon','year'), zlib=True)\n",
    "    data_out[:,:,:] = ghgi_temp[:,:,:]\n",
    "\n",
    "#save nongrid data to calculate non-grid fraction extension\n",
    "data_out = nc_out.createVariable('Emissions_nongrid', 'f8', ('year'), zlib=True)  \n",
    "data_out[:] = Emissions_nongrid[:]\n",
    "nc_out.close()\n",
    "\n",
    "#Confirm file location\n",
    "print('** SUCCESS **')\n",
    "print(\"Gridded emissions (kt) written to file: {}\" .format(os.getcwd())+grid_emi_outputfile)\n",
    "print(' ')\n",
    "\n",
    "del data_out, ghgi_temp, nc_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2. Calculate Gridded Emission Fluxes (molec./cm2/s) (0.1x0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert emissions to emission flux\n",
    "# conversion: kt emissions to molec/cm2/s flux\n",
    "\n",
    "DEBUG = 1\n",
    "\n",
    "Flux_array_01_annual = np.zeros([len(Lat_01),len(Lon_01),num_years])\n",
    "print('**QA/QC Check: Sum of national gridded emissions vs. GHGI national emissions')\n",
    "  \n",
    "for iyear in np.arange(0,num_years):\n",
    "    if year_range[iyear]==2012 or year_range[iyear]==2016:\n",
    "        year_days = np.sum(month_day_leap)\n",
    "    else:\n",
    "        year_days = np.sum(month_day_nonleap)\n",
    "        \n",
    "    conversion_factor_01 = 10**9 * Avogadro / float(Molarch4 *year_days * 24 * 60 *60) / area_matrix_01\n",
    "    Flux_array_01_annual[:,:,iyear] += Emissions_array_01[:,:,iyear]*conversion_factor_01\n",
    "    \n",
    "    calc_emi = np.sum(Flux_array_01_annual[:,:,iyear]/conversion_factor_01)+np.sum(Emissions_nongrid[iyear])\n",
    "    summary_emi = EPA_Rice_Emissions.iloc[0,iyear+1] \n",
    "    emi_diff = abs(summary_emi-calc_emi)/((summary_emi+calc_emi)/2)\n",
    "    if DEBUG ==1:\n",
    "        print(calc_emi)\n",
    "        print(summary_emi)\n",
    "    if abs(emi_diff) < 0.0001:\n",
    "        print('Year '+ year_range_str[iyear]+': Difference < 0.01%: PASS')\n",
    "    else: \n",
    "        print('Year '+ year_range_str[iyear]+': Difference > 0.01%: FAIL, diff: '+str(emi_diff))\n",
    "        \n",
    "Flux_Emissions_Total_annual = Flux_array_01_annual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4.3. Apply Gridded Month Scaling Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Monthly emissions and emission fluxes (the same motnhly scaling factor is applied to all years)\n",
    "DEBUG =1\n",
    "\n",
    "Flux_array_01 = np.zeros([len(Lat_01),len(Lon_01),num_years,num_months])\n",
    "Emissions_array = np.zeros([len(Lat_01),len(Lon_01),num_years,num_months])\n",
    "\n",
    "#Read in normalized monthly data from Anthony Bloom\n",
    "month_file = Dataset(Bloom_month_factors_file)\n",
    "month_map = np.array(month_file.variables['data'])\n",
    "month_file.close()\n",
    "\n",
    "#Scale the annual emissions data (apply the same scaling factors for each year)\n",
    "for iyear in np.arange(0, num_years):\n",
    "    for imonth in np.arange(0, num_months):\n",
    "        map_scaling_factor = np.sum(month_map[imonth,:,:])/np.sum(month_map[:,:,:])\n",
    "        Emissions_array[:,:,iyear,imonth] = map_scaling_factor * Emissions_array_01[:,:,iyear]\n",
    "        \n",
    "    #Check against total\n",
    "    calc_emi = 0\n",
    "    if year_range[iyear]==2012 or year_range[iyear]==2016:\n",
    "        year_days = np.sum(month_day_leap)\n",
    "        month_days = month_day_leap\n",
    "    else:\n",
    "        year_days = np.sum(month_day_nonleap)\n",
    "        month_days = month_day_nonleap\n",
    "    for imonth in np.arange(0, num_months):\n",
    "        conversion_factor_01 = 10**9 * Avogadro / float(Molarch4 *month_days[imonth] * 24 * 60 *60) / area_matrix_01\n",
    "        Flux_array_01[:,:,iyear,imonth] = Emissions_array[:,:,iyear,imonth]*conversion_factor_01\n",
    "        calc_emi += np.sum(Flux_array_01[:,:,iyear,imonth]/conversion_factor_01)\n",
    "    calc_emi += np.sum(Emissions_nongrid[iyear])\n",
    "    summary_emi = EPA_Rice_Emissions.iloc[0,iyear+1] \n",
    "    emi_diff = abs(summary_emi-calc_emi)/((summary_emi+calc_emi)/2)\n",
    "    if DEBUG ==1:\n",
    "        print(calc_emi)\n",
    "        print(summary_emi)\n",
    "    if abs(emi_diff) < 0.0001:\n",
    "        print('Year '+ year_range_str[iyear]+': Difference < 0.01%: PASS')\n",
    "    else: \n",
    "        print('Year '+ year_range_str[iyear]+': Difference > 0.01%: FAIL, diff: '+str(emi_diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "## Step 5. Write netCDF\n",
    "------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# monthly data\n",
    "#Initialize file\n",
    "data_IO_fn.initialize_netCDF(gridded_month_outputfile, netCDF_description_m, 1, year_range, loc_dimensions, Lat_01, Lon_01)\n",
    "\n",
    "# Write data to netCDF\n",
    "nc_out = Dataset(gridded_month_outputfile, 'r+', format='NETCDF4')\n",
    "nc_out.variables['emi_ch4'][:,:,:,:] = Flux_array_01\n",
    "nc_out.close()\n",
    "#Confirm file location\n",
    "print('** SUCCESS **')\n",
    "print(\"Gridded fluxes written to file: {}\" .format(os.getcwd())+gridded_month_outputfile)\n",
    "\n",
    "# yearly data\n",
    "#Initialize file\n",
    "data_IO_fn.initialize_netCDF(gridded_outputfile, netCDF_description, 0, year_range, loc_dimensions, Lat_01, Lon_01)\n",
    "\n",
    "# Write data to netCDF\n",
    "nc_out = Dataset(gridded_outputfile, 'r+', format='NETCDF4')\n",
    "nc_out.variables['emi_ch4'][:,:,:] = Flux_Emissions_Total_annual\n",
    "nc_out.close()\n",
    "#Confirm file location\n",
    "print('** SUCCESS **')\n",
    "print(\"Gridded fluxes written to file: {}\" .format(os.getcwd())+gridded_outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "## Step 6. Plot Gridded Data\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6.1. Plot Annual Emission Fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plot Annual Data\n",
    "scale_max = 10\n",
    "save_flag =0\n",
    "save_outfile = ''\n",
    "data_plot_fn.plot_annual_emission_flux_map(Flux_Emissions_Total_annual, Lat_01, Lon_01, year_range, title_str,scale_max,save_flag,save_outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6.2 Plot Difference between first and last inventory year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot difference between last and first year\n",
    "save_flag =0\n",
    "save_outfile = ''\n",
    "data_plot_fn.plot_diff_emission_flux_map(Flux_Emissions_Total_annual, Lat_01, Lon_01, year_range, title_diff_str,save_flag, save_outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Create arrays for plotting illustrative figures\n",
    "\n",
    "#State\n",
    "Emissions_array_state_01 = np.zeros([len(lat001),len(lon001)])\n",
    "mask_land = np.zeros([len(lat001),len(lon001)])\n",
    "Emissions_array_national_01 = np.zeros([len(lat001),len(lon001)])\n",
    "national_sum = np.sum(Emissions_array_01[:,:,6])\n",
    "for istate in np.arange(len(State_ANSI)):\n",
    "    #find given state (map of values of 1)\n",
    "    mask_state = np.ma.ones(np.shape(state_ANSI_map))\n",
    "    mask_state = np.ma.masked_where(state_ANSI_map != State_ANSI['ansi'][istate], mask_state)\n",
    "    mask_state = np.ma.filled(mask_state,0)\n",
    "    if np.sum(mask_state)>0:\n",
    "        #display(np.shape(Emissions_array))\n",
    "        # find the sum of 2018 emissions from that state\n",
    "        state_emis = np.sum(mask_state * Emissions_array_001[:,:,6])\n",
    "        # assign each grid cell for that state to the state total value\n",
    "        Emissions_array_state_01[:,:] += (state_emis*mask_state)\n",
    "        mask_land += mask_state\n",
    "mask_land[mask_land >1] ==1\n",
    "Emissions_array_national_01[:,:] = (national_sum*mask_land)\n",
    "Emissions_array_state = data_fn.regrid001_to_01(Emissions_array_state_01, Lat_01, Lon_01)\n",
    "Emissions_array_national = data_fn.regrid001_to_01(Emissions_array_national_01, Lat_01, Lon_01)\n",
    "Emissions_array_national /= 100\n",
    "Emissions_array_state /= 100\n",
    "del Emissions_array_national_01,Emissions_array_state_01 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#County\n",
    "Emissions_array_county_01 = np.zeros([len(lat001),len(lon001)])\n",
    "for icounty in np.arange(len(County_ANSI)):\n",
    "    mask_county = np.ma.ones(np.shape(county_ANSI_map))\n",
    "    mask_county = np.ma.masked_where(county_ANSI_map != County_ANSI['County'][icounty], mask_county)\n",
    "    mask_county = np.ma.masked_where(state_ANSI_map != County_ANSI['State'][icounty], mask_county)\n",
    "    mask_county = np.ma.filled(mask_county,0)\n",
    "    # find the sum of 2018 emissions from that county\n",
    "    county_emis = np.sum(mask_county * Emissions_array_001[:,:,6])\n",
    "    # assign each grid cell for that county to the county total value\n",
    "    Emissions_array_county_01[:,:] += county_emis*mask_county\n",
    "    print(icounty,'of',len(County_ANSI))\n",
    "Emissions_array_county = data_fn.regrid001_to_01(Emissions_array_county_01, Lat_01, Lon_01)\n",
    "Emissions_array_county /= 100\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_max = np.max(Emissions_array_national[43:300,50:632])\n",
    "my_cmap = copy(plt.cm.get_cmap('rainbow',lut=3000))\n",
    "my_cmap._init()\n",
    "slopen = 200\n",
    "alphas_slope = np.abs(np.linspace(0, 1.0, slopen))\n",
    "alphas_stable = np.ones(3003-slopen)\n",
    "alphas = np.concatenate((alphas_slope, alphas_stable))\n",
    "my_cmap._lut[:,-1] = alphas\n",
    "my_cmap.set_under('gray', alpha=0)\n",
    "    \n",
    "Lon_cor = Lon_01[50:632]-0.05\n",
    "Lat_cor = Lat_01[43:300]-0.05\n",
    "    \n",
    "xpoints = Lon_cor\n",
    "ypoints = Lat_cor\n",
    "yp,xp = np.meshgrid(ypoints,xpoints)\n",
    "    \n",
    "        #if np.shape(Emi_flux_map)[0] == len(year_range):\n",
    "\n",
    "#NATIONAL\n",
    "zp = Emissions_array_national[43:300,50:632]\n",
    "        #elif np.shape(Emi_flux_map)[2] == len(year_range):\n",
    "        #    zp = Emi_flux_map[43:300,50:632,iyear]\n",
    "        #zp = zp/float(10**6 * Avogadro) * (year_days * 24 * 60 * 60) * Molarch4 * float(1e10)\n",
    "    \n",
    "fig, ax = plt.subplots(dpi=300)\n",
    "m = Basemap(llcrnrlon=xp.min(), llcrnrlat=yp.min(), urcrnrlon=xp.max(),\n",
    "            urcrnrlat=yp.max(), projection='merc', resolution='h', area_thresh=5000)\n",
    "m.drawmapboundary(fill_color='Azure')\n",
    "m.fillcontinents(color='FloralWhite', lake_color='Azure',zorder=1)\n",
    "m.drawcoastlines(linewidth=0.5,zorder=3)\n",
    "#m.drawstates(linewidth=0.25,zorder=3)\n",
    "m.drawcountries(linewidth=0.5,zorder=3)\n",
    "    \n",
    "xpi,ypi = m(xp,yp)\n",
    "plot = m.pcolor(xpi,ypi,zp.transpose(), cmap=my_cmap, vmin=10**-15, vmax=scale_max, snap=True,zorder=2)\n",
    "cb = m.colorbar(plot, location = \"bottom\", pad = \"1%\")\n",
    "tick_locator = ticker.MaxNLocator(nbins=5)\n",
    "cb.locator = tick_locator\n",
    "cb.update_ticks()\n",
    "    \n",
    "cb.ax.set_xlabel('2018 Methane Emissions (kt a$^{-1}$)',fontsize=10)\n",
    "cb.ax.tick_params(labelsize=10)\n",
    "Titlestring = str(year_range[iyear])+' '+title_str\n",
    "fig1 = plt.gcf()\n",
    "plt.title(Titlestring, fontsize=14);\n",
    "plt.show();\n",
    "        #if save_flag ==1:\n",
    "fig1.savefig('Example_Rice_National'+'.tiff',transparent=True)\n",
    "\n",
    "#STATE     \n",
    "scale_max = np.max(Emissions_array_state[43:300,50:632]) \n",
    "state_proxy = 100*(Emissions_array_state/national_sum)\n",
    "scale_max = 100\n",
    "zp=state_proxy[43:300,50:632]\n",
    "#zp = Emissions_array_state[43:300,50:632]\n",
    "fig, ax = plt.subplots(dpi=300)\n",
    "m = Basemap(llcrnrlon=xp.min(), llcrnrlat=yp.min(), urcrnrlon=xp.max(),\n",
    "            urcrnrlat=yp.max(), projection='merc', resolution='h', area_thresh=5000)\n",
    "m.drawmapboundary(fill_color='Azure')\n",
    "m.fillcontinents(color='FloralWhite', lake_color='Azure',zorder=1)\n",
    "m.drawcoastlines(linewidth=0.5,zorder=3)\n",
    "m.drawstates(linewidth=0.25,zorder=3)\n",
    "m.drawcountries(linewidth=0.5,zorder=3)\n",
    "    \n",
    "xpi,ypi = m(xp,yp)\n",
    "plot = m.pcolor(xpi,ypi,zp.transpose(), cmap=my_cmap, vmin=10**-15, vmax=scale_max, snap=True,zorder=2)\n",
    "cb = m.colorbar(plot, location = \"bottom\", pad = \"1%\")\n",
    "tick_locator = ticker.MaxNLocator(nbins=5)\n",
    "cb.locator = tick_locator\n",
    "cb.update_ticks()\n",
    "    \n",
    "cb.ax.set_xlabel('2018 State Methane Emissions (kt a$^{-1}$)',fontsize=10)\n",
    "cb.ax.tick_params(labelsize=10)\n",
    "Titlestring = str(year_range[iyear])+' '+title_str\n",
    "fig1 = plt.gcf()\n",
    "plt.title(Titlestring, fontsize=14);\n",
    "plt.show();\n",
    "fig1.savefig('Example_Rice_State_Proxy'+'.tiff',transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COUNTY\n",
    "scale_max = np.max(Emissions_array_county[43:300,50:632])  \n",
    "zp = Emissions_array_county[43:300,50:632]\n",
    "fig, ax = plt.subplots(dpi=300)\n",
    "m = Basemap(llcrnrlon=xp.min(), llcrnrlat=yp.min(), urcrnrlon=xp.max(),\n",
    "            urcrnrlat=yp.max(), projection='merc', resolution='h', area_thresh=5000)\n",
    "m.drawmapboundary(fill_color='Azure')\n",
    "m.fillcontinents(color='FloralWhite', lake_color='Azure',zorder=1)\n",
    "m.drawcoastlines(linewidth=0.5,zorder=3)\n",
    "m.drawstates(linewidth=0.25,zorder=3)\n",
    "m.drawcountries(linewidth=0.5,zorder=3)\n",
    "    \n",
    "xpi,ypi = m(xp,yp)\n",
    "plot = m.pcolor(xpi,ypi,zp.transpose(), cmap=my_cmap, vmin=10**-15, vmax=scale_max, snap=True,zorder=2)\n",
    "cb = m.colorbar(plot, location = \"bottom\", pad = \"1%\")\n",
    "tick_locator = ticker.MaxNLocator(nbins=5)\n",
    "cb.locator = tick_locator\n",
    "cb.update_ticks()\n",
    "    \n",
    "cb.ax.set_xlabel('2018 County Methane Emissions (kt a$^{-1}$)',fontsize=10)\n",
    "cb.ax.tick_params(labelsize=10)\n",
    "Titlestring = str(year_range[iyear])+' '+title_str\n",
    "fig1 = plt.gcf()\n",
    "plt.title(Titlestring, fontsize=14);\n",
    "plt.show();\n",
    "fig1.savefig('Example_Rice_County'+'.tiff',transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Gridded\n",
    "Flux_Emissions_Total_annual\n",
    "scale_max = np.max(Flux_Emissions_Total_annual[43:300,50:632,6])  \n",
    "zp = Flux_Emissions_Total_annual[43:300,50:632,6]\n",
    "fig, ax = plt.subplots(dpi=300)\n",
    "m = Basemap(llcrnrlon=xp.min(), llcrnrlat=yp.min(), urcrnrlon=xp.max(),\n",
    "            urcrnrlat=yp.max(), projection='merc', resolution='h', area_thresh=5000)\n",
    "m.drawmapboundary(fill_color='Azure')\n",
    "m.fillcontinents(color='FloralWhite', lake_color='Azure',zorder=1)\n",
    "m.drawcoastlines(linewidth=0.5,zorder=3)\n",
    "m.drawstates(linewidth=0.25,zorder=3)\n",
    "m.drawcountries(linewidth=0.5,zorder=3)\n",
    "    \n",
    "xpi,ypi = m(xp,yp)\n",
    "plot = m.pcolor(xpi,ypi,zp.transpose(), cmap=my_cmap, vmin=10**-15, vmax=scale_max, snap=True,zorder=2)\n",
    "cb = m.colorbar(plot, location = \"bottom\", pad = \"1%\")\n",
    "tick_locator = ticker.MaxNLocator(nbins=5)\n",
    "cb.locator = tick_locator\n",
    "cb.update_ticks()\n",
    "    \n",
    "cb.ax.set_xlabel('2018 Gridded Methane Emissions (Mg a$^{-1}$ km$^{-2}$)',fontsize=10)\n",
    "cb.ax.tick_params(labelsize=10)\n",
    "Titlestring = str(year_range[iyear])+' '+title_str\n",
    "fig1 = plt.gcf()\n",
    "plt.title(Titlestring, fontsize=14);\n",
    "plt.show();\n",
    "fig1.savefig('Example_Rice_Grid'+'.tiff',transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = datetime.datetime.now() \n",
    "ft = ct.timestamp() \n",
    "time_elapsed = (ft-it)/(60*60)\n",
    "print('Time to run: '+str(time_elapsed)+' hours')\n",
    "print('** GEPA_3C_Rice: COMPLETE **')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
