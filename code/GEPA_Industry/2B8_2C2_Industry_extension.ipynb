{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridded EPA Methane Inventory\n",
    "## Extension - GHGI 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### Authors: \n",
    "Erin E. McDuffie\n",
    "#### Date Last Updated: \n",
    "see Step 0\n",
    "#### Notebook Purpose: \n",
    "This Notebook extends and reports annual gridded (0.1°x0.1°) methane emission fluxes (molec./cm2/s) from Industry (Ferroalloy & Petrochemical production) sources for the years 2012-2020, using updated inventory values from the 2022 National GHGI.  \n",
    "#### Summary & Notes:\n",
    "EPA annual national methane emissions are read in for the 2022 GHGI (either from the GHGI workbooks or public data). National emissions are then scaled down to CONUS emissions using the relative fraction of CONUS/total emissions from the v2 data (for each year, held constant after 2018). Remaining CONUS data are then allocated to proxy groups using the relevant proxy mapping files and allocated to the grid using the relative mass of emissions in each grid cell from each group from version 2 (for each year, held constant after 2018). Annual emission fluxes (molec./cm2/s) for 2012-2020 are then written to final netCDFs in the ‘/code/Final_Gridded_Data/Extension/v2_ext_final’ folder.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "## Step 0. Set-Up Notebook Modules, Functions, and Local Parameters and Constants\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirm working directory\n",
    "import os\n",
    "import time\n",
    "modtime = os.path.getmtime('./2B8_2C2_Industry_extension.ipynb')\n",
    "modificationTime = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(modtime))\n",
    "print(\"This file was last modified on: \", modificationTime)\n",
    "print('')\n",
    "print(\"The directory we are working in is {}\" .format(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Include plots within notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import base modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import datetime\n",
    "from copy import copy\n",
    "\n",
    "# Import additional modules\n",
    "# Load plotting package Basemap \n",
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "# Load netCDF (for manipulating netCDF file types)\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "# Set up ticker\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "#add path for the global function module (file)\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../Global_Functions/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# Load Tabula (for reading tables from PDFs)\n",
    "import tabula as tb   \n",
    "    \n",
    "# Load user-defined global functions (modules)\n",
    "import data_load_functions as data_load_fn\n",
    "import data_functions as data_fn\n",
    "import data_IO_functions as data_IO_fn\n",
    "import data_plot_functions as data_plot_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INPUT Files\n",
    "# Assign global file names\n",
    "global_filenames = data_load_fn.load_global_file_names()\n",
    "State_ANSI_inputfile = global_filenames[0]\n",
    "County_ANSI_inputfile = global_filenames[1]\n",
    "pop_map_inputfile = global_filenames[2]\n",
    "Grid_area01_inputfile = global_filenames[3]\n",
    "Grid_area001_inputfile = global_filenames[4]\n",
    "Grid_state001_ansi_inputfile = global_filenames[5]\n",
    "Grid_county001_ansi_inputfile = global_filenames[6]\n",
    "globalinputlocation = global_filenames[0][0:20]\n",
    "print(globalinputlocation)\n",
    "\n",
    "# Specify names of inputs files used in this notebook\n",
    "EPA_inputfile = '../Global_InputData/GHGI/Ch2_Industry/IPPU CH4 emissions from ferroalloys and petrochemicals 1990-2020.xlsx'\n",
    "\n",
    "\n",
    "Ind_Mapping_inputfile = './InputData/Industry_ProxyMapping.xlsx'\n",
    "\n",
    "grid_emi_inputfile = '../Final_Gridded_Data/Extension/v2_input_data/Ind_Petro_Ferro_Grid_Emi2.nc'\n",
    "\n",
    "#OUTPUT FILES\n",
    "gridded_outputfile = '../Final_Gridded_Data/Extension/v2_ext_final/EXT_EPA_v2_2B8_2C2_Industry.nc'\n",
    "netCDF_description = '2020 Extension of the Gridded EPA Inventory (v2)- Industry - IPCC Source Category 2B5 and 2C1'\n",
    "gridded_petro_outputfile = '../Final_Gridded_Data/Extension/v2_ext_final/EXT_EPA_v2_2B8_Industry_Petrochemical.nc'\n",
    "netCDF_petro_description = 'EXTENSION to the Gridded EPA Inventory - Industry Emissions - IPCC Source Category 2B8 - Petrochemical'\n",
    "gridded_ferro_outputfile = '../Final_Gridded_Data/Extension/v2_ext_final/EXT_EPA_v2_2C2_Industry_Ferroalloy.nc'\n",
    "netCDF_ferro_description = 'EXTENSION to the Gridded EPA Inventory - Industry Emissions - IPCC Source Category 2C2 - Ferroalloy'\n",
    "title_str = \"EPA methane emissions from industry\"\n",
    "title_petro_str = \"EPA methane emissions from petrochemical industry\"\n",
    "title_ferro_str = \"EPA methane emissions from ferroalloy production\"\n",
    "title_diff_str = \"Emissions from industry total difference: 2020-2012\"\n",
    "title_petro_diff_str = \"Emissions from petrochemical difference: 2020-2012\"\n",
    "title_ferro_diff_str = \"Emissions from ferroalloy total difference: 2020-2012\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define local variables\n",
    "start_year = 2012  #First year in emission timeseries\n",
    "end_year = 2018    #Last year in emission timeseries\n",
    "ext_year = 2020    #last year in extended dataset\n",
    "end_year_idx = 2018-2012 #index of the year 2018\n",
    "year_range = [*range(start_year, ext_year+1,1)] #List of emission years\n",
    "year_range_str=[str(i) for i in year_range]\n",
    "num_years = len(year_range)\n",
    "\n",
    "# Define constants\n",
    "Avogadro   = 6.02214129 * 10**(23)  #molecules/mol\n",
    "Molarch4   = 16.04                  #g/mol\n",
    "Res01      = 0.1                    # degrees\n",
    "Res_01     = 0.01\n",
    "tg_scale   = 0.001                  #Tg scale number [New file allows for the exclusion of the territories] \n",
    "\n",
    "# Continental US Lat/Lon Limits (for netCDF files)\n",
    "Lon_left = -130       #deg\n",
    "Lon_right = -60       #deg\n",
    "Lat_low  = 20         #deg\n",
    "Lat_up  = 55          #deg\n",
    "loc_dimensions = [Lat_low, Lat_up, Lon_left, Lon_right]\n",
    "\n",
    "ilat_start = int((90+Lat_low)/Res01) #1100:1450 (continental US range)\n",
    "ilat_end = int((90+Lat_up)/Res01)\n",
    "ilon_start = abs(int((-180-Lon_left)/Res01)) #500:1200 (continental US range)\n",
    "ilon_end = abs(int((-180-Lon_right)/Res01))\n",
    "\n",
    "# Number of days in each month\n",
    "month_day_leap  = [  31,  29,  31,  30,  31,  30,  31,  31,  30,  31,  30,  31]\n",
    "month_day_nonleap = [  31,  28,  31,  30,  31,  30,  31,  31,  30,  31,  30,  31]\n",
    "\n",
    "# Month arrays\n",
    "month_range_str = ['January','February','March','April','May','June','July','August','September','October','November','December']\n",
    "num_months = len(month_range_str)\n",
    "\n",
    "area_map, lat001, lon001 = data_load_fn.load_area_map_001(Grid_area001_inputfile)\n",
    "area_map01, Lat01, Lon01 = data_load_fn.load_area_map_01(Grid_area01_inputfile)[0:3]\n",
    "#Select relevant Continental 0.1 x0.1 domain\n",
    "Lat_01 = Lat01[ilat_start:ilat_end]\n",
    "Lon_01 = Lon01[ilon_start:ilon_end]\n",
    "area_matrix_01 = data_fn.regrid001_to_01(area_map, Lat_01, Lon_01)\n",
    "area_matrix_01 *= 10000  #convert from m2 to cm2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.auto_scroll_threshold = 9999;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track run time\n",
    "ct = datetime.datetime.now() \n",
    "it = ct.timestamp() \n",
    "print(\"current time:\", ct) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. Specify Input Files\n",
    "    a. 2022 GHGI\n",
    "    b. Proxy Mapping\n",
    "    c. gridded group emissions\n",
    "2. Read in v2 gridded emission groups\n",
    "3. Calculate CONUS fraction\n",
    "4. Read in 2022 GHGI Data\n",
    "6. Split national data into gridding groups (may need to adjust if source names have changed)\n",
    "7. For each gridding group, multiply by map of relative emissions - and scale by CONUS fractions\n",
    "8. Convert to flux\n",
    "9. Save new extension data\n",
    "10. Plot new extension data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Read in Gridding Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load GHGI Mapping Groups\n",
    "names = pd.read_excel(Ind_Mapping_inputfile, sheet_name = \"GHGI Map - Ind\", usecols = \"A:B\",skiprows = 1, header = 0)\n",
    "colnames = names.columns.values\n",
    "ghgi_ind_map = pd.read_excel(Ind_Mapping_inputfile, sheet_name = \"GHGI Map - Ind\", usecols = \"A:B\", skiprows = 1, names = colnames)\n",
    "#drop rows with no data, remove the parentheses and \"\"\n",
    "ghgi_ind_map = ghgi_ind_map[ghgi_ind_map['GHGI_Emi_Group'] != 'na']\n",
    "ghgi_ind_map = ghgi_ind_map[ghgi_ind_map['GHGI_Emi_Group'].notna()]\n",
    "ghgi_ind_map['GHGI_Source']= ghgi_ind_map['GHGI_Source'].str.replace(r\"\\(\",\"\")\n",
    "ghgi_ind_map['GHGI_Source']= ghgi_ind_map['GHGI_Source'].str.replace(r\"\\)\",\"\")\n",
    "ghgi_ind_map.reset_index(inplace=True, drop=True)\n",
    "display(ghgi_ind_map)\n",
    "\n",
    "#load emission group - proxy map\n",
    "names = pd.read_excel(Ind_Mapping_inputfile, sheet_name = \"Proxy Map - Ind\", usecols = \"A:D\",skiprows = 1, header = 0)\n",
    "colnames = names.columns.values\n",
    "proxy_ind_map = pd.read_excel(Ind_Mapping_inputfile, sheet_name = \"Proxy Map - Ind\", usecols = \"A:D\", skiprows = 1, names = colnames)\n",
    "display((proxy_ind_map))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "## Step 2. Read in v2 Grid Group Emissions\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These data will be assigned to 'proxy_+ghgi_emi_name' (because original proxy mapping is not 1:1 with GHGI group)\n",
    "#All proxy data will be in 0.1x0.1xyear dimensions\n",
    "#asign 2018 values to years 2019 ad 2020\n",
    "\n",
    "nc_in = Dataset(grid_emi_inputfile, 'r', format='NETCDF4')\n",
    "sum_emi = 0\n",
    "Emissions_nongrid = np.zeros([num_years])\n",
    "\n",
    "for igroup in np.arange(0,len(proxy_ind_map)):\n",
    "    vars()['Proxy_'+proxy_ind_map.loc[igroup,'GHGI_Emi_Group']] = np.zeros([len(Lat_01),len(Lon_01),num_years])\n",
    "    temp = nc_in['Ext_'+proxy_ind_map['GHGI_Emi_Group'][igroup]][:,:,:]\n",
    "    for iyear in np.arange(0,num_years):\n",
    "        if year_range[iyear] <= end_year:\n",
    "            vars()['Proxy_'+proxy_ind_map.loc[igroup,'GHGI_Emi_Group']][:,:,iyear] = temp[:,:,iyear]\n",
    "        else:\n",
    "            vars()['Proxy_'+proxy_ind_map.loc[igroup,'GHGI_Emi_Group']][:,:,iyear] = temp[:,:,end_year_idx]\n",
    "\n",
    "#assign 2018 values to years 2019 and 2020\n",
    "for iyear in np.arange(0,num_years):\n",
    "    if year_range[iyear] <= end_year:\n",
    "        Emissions_nongrid[iyear] = nc_in['Emissions_nongrid'][iyear]\n",
    "    else:\n",
    "        Emissions_nongrid[iyear] = nc_in['Emissions_nongrid'][end_year_idx]\n",
    "\n",
    "CONUS_frac = np.zeros([num_years])\n",
    "\n",
    "for iyear in np.arange(0, num_years):\n",
    "    for igroup in np.arange(0,len(proxy_ind_map)):\n",
    "        sum_emi += np.sum( vars()['Proxy_'+proxy_ind_map.loc[igroup,'GHGI_Emi_Group']][:,:,iyear])\n",
    "    CONUS_frac[iyear] = Emissions_nongrid[iyear]/sum_emi\n",
    "        \n",
    "print(CONUS_frac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "## Step 3. Read in and Format 2022 US EPA GHGI Emissions\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read Petrochemical GHGI emissions (1990-2020), in kt\n",
    "\n",
    "#Petrochemicals\n",
    "names = pd.read_excel(EPA_inputfile, skiprows=11,usecols='B:AH')\n",
    "colnames = names.columns.values\n",
    "EPA_petro_emissions = pd.read_excel(EPA_inputfile, skiprows = 14, rows=1,names = colnames,usecols='B:AH')\n",
    "EPA_petro_emissions = EPA_petro_emissions.drop(columns = [*range(1990, start_year,1)])\n",
    "EPA_petro_emissions= EPA_petro_emissions.drop(columns = ['Unnamed: 2'])\n",
    "EPA_petro_emissions['Source'] = 'Total Petrochemicals'\n",
    "\n",
    "#Ferroalloy\n",
    "EPA_ferro_emissions = pd.read_excel(EPA_inputfile, skiprows = 14, rows=1,names=colnames,usecols='B:AH')\n",
    "EPA_ferro_emissions= EPA_ferro_emissions.drop(columns = ['Unnamed: 2'])\n",
    "EPA_ferro_emissions = EPA_ferro_emissions.drop(columns = [*range(1990, start_year,1)])\n",
    "EPA_ferro_emissions['Source'] = 'Total Ferroalloy'\n",
    "\n",
    "EPA_Industry = pd.concat([EPA_petro_emissions,EPA_ferro_emissions])\n",
    "display(EPA_Industry)\n",
    "\n",
    "Total_EPA_Industry_Emissions = EPA_ferro_emissions.iloc[0,1:]+EPA_petro_emissions.iloc[0,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Split Emissions into Gridding Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Final Emissions in Units of kt\n",
    "# Use mapping proxy and source files to split the GHGI emissions\n",
    "\n",
    "DEBUG =1\n",
    "\n",
    "start_year_idx = EPA_Industry.columns.get_loc(start_year)\n",
    "end_year_idx = EPA_Industry.columns.get_loc(end_year)+1\n",
    "sum_emi = np.zeros(num_years)\n",
    "\n",
    "ghgi_ind_groups = ghgi_ind_map['GHGI_Emi_Group'].unique()\n",
    "\n",
    "for igroup in np.arange(0,len(ghgi_ind_groups)): #loop through all groups, finding the GHGI sources in that group and summing emissions for that region, year\n",
    "        vars()[ghgi_ind_groups[igroup]] = np.zeros([num_years])\n",
    "        source_temp = ghgi_ind_map.loc[ghgi_ind_map['GHGI_Emi_Group'] == ghgi_ind_groups[igroup], 'GHGI_Source']\n",
    "        pattern_temp  = '|'.join(source_temp)\n",
    "        ##DEBUG## display(pattern_temp)\n",
    "        emi_temp = EPA_Industry[EPA_Industry['Source'].str.contains(pattern_temp)]\n",
    "        ##DEBUG## display(emi_temp)\n",
    "        vars()[ghgi_ind_groups[igroup]][:] = np.where(emi_temp.iloc[:,start_year_idx:] =='',[0],emi_temp.iloc[:,start_year_idx:]).sum(axis=0)#/float(1000) #convert Mg to kt\n",
    "        \n",
    "#Check against total summary emissions \n",
    "print('QA/QC #1: Check Processing Emission Sum against GHGI Summary Emissions')\n",
    "for iyear in np.arange(0,num_years): \n",
    "    sum_emi = 0\n",
    "    for igroup in np.arange(0,len(ghgi_ind_groups)):\n",
    "        sum_emi += vars()[ghgi_ind_groups[igroup]][iyear]\n",
    "        \n",
    "    summary_emi = Total_EPA_Industry_Emissions[year_range[iyear]]  \n",
    "    #Check 1 - make sure that the sums from all the regions equal the totals reported\n",
    "    diff1 = abs(sum_emi - summary_emi)/((sum_emi + summary_emi)/2)\n",
    "    if DEBUG ==1:\n",
    "        print(summary_emi)\n",
    "        print(sum_emi)\n",
    "    if diff1 < 0.0001:\n",
    "        print('Year ', year_range[iyear],': PASS, difference < 0.01%')\n",
    "    else:\n",
    "        print('Year ', year_range[iyear],': FAIL (check Production & summary tabs): ', diff1,'%') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "## Step 4. Grid Data\n",
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 4.1 Allocate emissions to the CONUS region (0.1x0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Allocate national emissions (Tg) onto a 0.1x0.1 grid using gridcell level 'Proxy_Groups'\n",
    "\n",
    "DEBUG =1\n",
    "#Define emission arrays\n",
    "Emissions_array_01 = np.zeros([len(Lat_01),len(Lon_01),num_years])\n",
    "Emissions_nongrid = np.zeros([num_years])\n",
    "Emissions_Ferro = np.zeros([len(Lat_01),len(Lon_01),num_years])\n",
    "Emissions_Petro = np.zeros([len(Lat_01),len(Lon_01),num_years])\n",
    "\n",
    "\n",
    "# For each year, distribute natinal emissions onto a grid proxies specified in the Proxy_Mapping file\n",
    "\n",
    "print('**QA/QC Check: Sum of national gridded emissions vs. GHGI national emissions')\n",
    "#running_sum = np.zeros([len(proxy_abdcoal_map),num_years])\n",
    "\n",
    "for igroup in np.arange(0,len(proxy_ind_map)):\n",
    "    proxy_temp = vars()['Proxy_'+proxy_ind_map.loc[igroup,'GHGI_Emi_Group']][:,:,:]\n",
    "    vars()['Flux_'+proxy_ind_map.loc[igroup,'GHGI_Emi_Group']] = np.zeros([len(Lat_01),len(Lon_01),num_years])\n",
    "    vars()['Flux_'+proxy_ind_map.loc[igroup,'GHGI_Emi_Group']+'_nongrid'] = np.zeros([num_years])\n",
    "\n",
    "    for iyear in np.arange(0,num_years):\n",
    "        proxy_frac = data_fn.safe_div(proxy_temp[:,:,iyear], np.sum(proxy_temp[:,:,iyear]))\n",
    "        ghgi_temp = vars()[proxy_ind_map.loc[igroup,'GHGI_Emi_Group']][iyear] * (1-CONUS_frac[iyear])\n",
    "        vars()['Flux_'+proxy_ind_map.loc[igroup,'GHGI_Emi_Group']][:,:,iyear] += ghgi_temp * proxy_frac[:,:]\n",
    "        if 'Ferro' in proxy_ind_map.loc[igroup,'GHGI_Emi_Group']:\n",
    "            Emissions_Ferro[:,:,iyear] += vars()['Flux_'+proxy_ind_map.loc[igroup,'GHGI_Emi_Group']][:,:,iyear]\n",
    "        if 'Petro' in proxy_ind_map.loc[igroup,'GHGI_Emi_Group']:\n",
    "            Emissions_Petro[:,:,iyear] += vars()['Flux_'+proxy_ind_map.loc[igroup,'GHGI_Emi_Group']][:,:,iyear]\n",
    "        Emissions_array_01[:,:,iyear] += vars()['Flux_'+proxy_ind_map.loc[igroup,'GHGI_Emi_Group']][:,:,iyear]\n",
    "        Emissions_nongrid[iyear] += vars()[proxy_ind_map.loc[igroup,'GHGI_Emi_Group']][iyear] - ghgi_temp\n",
    "       \n",
    "        \n",
    "for iyear in np.arange(0, num_years):    \n",
    "    calc_emi = np.sum(Emissions_Petro[:,:,iyear]) +np.sum(Emissions_Ferro[:,:,iyear])+ np.sum(Emissions_nongrid[iyear]) \n",
    "    summary_emi = Total_EPA_Industry_Emissions[year_range[iyear]]\n",
    "    emi_diff = abs(summary_emi-calc_emi)/((summary_emi+calc_emi)/2)\n",
    "    if DEBUG==1:\n",
    "        print(calc_emi)\n",
    "        print(summary_emi)\n",
    "    if abs(emi_diff) < 0.0001:\n",
    "        print('Year '+ year_range_str[iyear]+': Difference < 0.01%: PASS')\n",
    "    else: \n",
    "        print('Year '+ year_range_str[iyear]+': Difference > 0.01%: FAIL, diff: '+str(emi_diff))\n",
    "        \n",
    "ct = datetime.datetime.now() \n",
    "print(\"current time:\", ct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Calculate Gridded Emission Fluxes (molec./cm2/s) (0.1x0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2 -- #Convert emissions to emission flux\n",
    "# conversion: kt emissions to molec/cm2/s flux\n",
    "\n",
    "DEBUG=1\n",
    "\n",
    "#Initialize arrays\n",
    "check_sum_annual = np.zeros([num_years])\n",
    "Flux_array_01_annual = np.zeros([len(Lat_01),len(Lon_01),num_years])\n",
    "Flux_array_01_ferro_annual = np.zeros([len(Lat_01),len(Lon_01),num_years])\n",
    "Flux_array_01_petro_annual = np.zeros([len(Lat_01),len(Lon_01),num_years])\n",
    "for igroup in np.arange(0,len(proxy_ind_map)):\n",
    "    vars()['Flux_'+proxy_ind_map.loc[igroup,'GHGI_Emi_Group']+'_annual'] = np.zeros([len(Lat_01),len(Lon_01),num_years])\n",
    "\n",
    "\n",
    "#Calculate fluxes\n",
    "for iyear in np.arange(0,num_years):\n",
    "    if year_range[iyear]==2012 or year_range[iyear]==2016:\n",
    "        year_days = np.sum(month_day_leap)\n",
    "        month_days = month_day_leap\n",
    "    else:\n",
    "        year_days = np.sum(month_day_nonleap)\n",
    "        month_days = month_day_nonleap \n",
    "    \n",
    "    # calculate fluxes for annual data  (=kt * grams/kt *molec/mol *mol/g *s^-1 * cm^-2)\n",
    "    conversion_factor_annual = 10**9 * Avogadro / float(Molarch4 * np.sum(month_days) * 24 * 60 *60) / area_matrix_01\n",
    "    for igroup in np.arange(0,len(proxy_ind_map)):\n",
    "        vars()['Flux_'+proxy_ind_map.loc[igroup,'GHGI_Emi_Group']][:,:,iyear] *= conversion_factor_annual\n",
    "        vars()['Flux_'+proxy_ind_map.loc[igroup,'GHGI_Emi_Group']+'_annual'][:,:,iyear] = vars()['Flux_'+proxy_ind_map.loc[igroup,'GHGI_Emi_Group']][:,:,iyear]\n",
    "        Flux_array_01_annual[:,:,iyear] = Emissions_array_01[:,:,iyear]*conversion_factor_annual\n",
    "        Flux_array_01_ferro_annual[:,:,iyear] = Emissions_Ferro[:,:,iyear]*conversion_factor_annual\n",
    "        Flux_array_01_petro_annual[:,:,iyear] = Emissions_Petro[:,:,iyear]*conversion_factor_annual\n",
    "    check_sum_annual[iyear] = np.sum(Flux_array_01_ferro_annual[:,:,iyear]/conversion_factor_annual) +\\\n",
    "                                np.sum(Flux_array_01_petro_annual[:,:,iyear]/conversion_factor_annual)#convert back to emissions to check at end\n",
    "\n",
    "print(' ')\n",
    "print('QA/QC #2: Check final gridded fluxes against GHGI')  \n",
    "# for the sum, check the converted annual emissions (convert back from flux) plus all the non-gridded emissions\n",
    "for iyear in np.arange(0,num_years):\n",
    "    calc_emi = check_sum_annual[iyear] + Emissions_nongrid[iyear]\n",
    "    summary_emi = Total_EPA_Industry_Emissions[year_range[iyear]]\n",
    "    if DEBUG==1:\n",
    "        print(calc_emi)\n",
    "        print(summary_emi)\n",
    "    diff = abs(summary_emi-calc_emi)/((summary_emi+calc_emi)/2)\n",
    "    if diff < 0.0001:\n",
    "        print('Year ', year_range[iyear], ': PASS, difference < 0.01%')\n",
    "    else:\n",
    "        print('Year ', year_range[iyear], ': FAIL -- Difference = ', diff*100,'%')\n",
    "        \n",
    "Flux_Emissions_Total_annual = Flux_array_01_annual\n",
    "Flux_Emissions_Petro_annual = Flux_array_01_petro_annual\n",
    "Flux_Emissions_Ferro_annual = Flux_array_01_ferro_annual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "## Step 5. Write netCDF\n",
    "------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize netCDF files\n",
    "\n",
    "data_IO_fn.initialize_netCDF(gridded_outputfile, netCDF_description, 0, year_range, loc_dimensions, Lat_01, Lon_01)\n",
    "data_IO_fn.initialize_netCDF(gridded_petro_outputfile, netCDF_petro_description, 0, year_range, loc_dimensions, Lat_01, Lon_01)\n",
    "data_IO_fn.initialize_netCDF(gridded_ferro_outputfile, netCDF_ferro_description, 0, year_range, loc_dimensions, Lat_01, Lon_01)\n",
    "\n",
    "# Write the Data to netCDF\n",
    "nc_out = Dataset(gridded_outputfile, 'r+', format='NETCDF4')\n",
    "nc_out.variables['emi_ch4'][:,:,:] = Flux_Emissions_Total_annual\n",
    "nc_out.close()\n",
    "#Confirm file location\n",
    "print('** SUCCESS **')\n",
    "print(\"Gridded industry fluxes written to file: {}\" .format(os.getcwd())+gridded_outputfile)\n",
    "print('')\n",
    "\n",
    "#Petro\n",
    "# Write the Data to netCDF\n",
    "nc_out = Dataset(gridded_petro_outputfile, 'r+', format='NETCDF4')\n",
    "nc_out.variables['emi_ch4'][:,:,:] = Flux_Emissions_Petro_annual\n",
    "nc_out.close()\n",
    "#Confirm file location\n",
    "print('** SUCCESS **')\n",
    "print(\"Gridded industry fluxes written to file: {}\" .format(os.getcwd())+gridded_petro_outputfile)\n",
    "print('')\n",
    "\n",
    "#Ferro\n",
    "# Write the Data to netCDF\n",
    "nc_out = Dataset(gridded_ferro_outputfile, 'r+', format='NETCDF4')\n",
    "nc_out.variables['emi_ch4'][:,:,:] = Flux_Emissions_Ferro_annual\n",
    "nc_out.close()\n",
    "#Confirm file location\n",
    "print('** SUCCESS **')\n",
    "print(\"Gridded industry fluxes written to file: {}\" .format(os.getcwd())+gridded_ferro_outputfile)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "## Step 6. Plot Gridded Data\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6.1. Plot Annual Emission Fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plot annual data for entire timeseries\n",
    "scale_max = 2\n",
    "save_flag = 0\n",
    "save_outfile = ''\n",
    "data_plot_fn.plot_annual_emission_flux_map(Flux_Emissions_Total_annual, Lat_01, Lon_01, year_range, title_str, scale_max,save_flag,save_outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plot each individually (could change to plot each group)\n",
    "for igroup in np.arange(0,len(proxy_ind_map)):\n",
    "    temp_plot = vars()['Flux_'+proxy_ind_map.loc[igroup,'GHGI_Emi_Group']]\n",
    "    data_plot_fn.plot_annual_emission_flux_map(temp_plot, Lat_01, Lon_01, year_range, proxy_ind_map.loc[igroup,'GHGI_Emi_Group'], scale_max,save_flag,save_outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6.2 Plot Difference between first and last inventory year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot difference between last and first year for the industry total\n",
    "data_plot_fn.plot_diff_emission_flux_map(Flux_Emissions_Total_annual, Lat_01, Lon_01, year_range, title_diff_str,save_flag,save_outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = datetime.datetime.now() \n",
    "ft = ct.timestamp() \n",
    "time_elapsed = (ft-it)/(60*60)\n",
    "print('Time to run: '+str(time_elapsed)+' hours')\n",
    "print('** EXTENSION_GEPA_2B8_2C2_Industry: COMPLETE **')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
