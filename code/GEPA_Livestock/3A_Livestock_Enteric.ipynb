{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridded EPA Methane Inventory\n",
    "## Category: 3A Livestock Sector - Enteric Emissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### Authors: \n",
    "Joannes D. Maasakkers, Candice F. Z. Chen, Erin E. McDuffie\n",
    "#### Date Last Updated: \n",
    "see Step 0\n",
    "#### Notebook Purpose\n",
    "This notebook calculates gridded (0.1⁰x0.1⁰) annual emission fluxes of methane (molecules CH4/cm2/s) from enteric fermentation activities in the CONUS region for the years 2012 - 2018. Emission fluxes are reported at an annual time resolution. \n",
    "#### Summary & Notes \n",
    "The national EPA GHGI emissions data are read in from table 5-2 from the public GHGI report. First, national emissions are allocated to each state and animal type using state EPA GHGI emissions from enteric fermentation from the GHGI Inventory Enteric workbooks (for both cattle and other animals). Animal-specific emissions from 2018 are only available at the national level. National level-ratios of animal types from previous years are used to estimate state-level contributions for 2018. State-level emissions (as a function of animal type) are then allocated to the county level using USDA animal counts from the 2012 and 2017 Census. Animal counts for additional years are estimated through interpolation of census data. Resulting county-level emissions are then distributed onto a 0.1⁰x0.1⁰ grid (as a function of animal type) using a map of grid-level landcover probabilities from the USDA. Emissions as a function of animal type are then aggregated to total gridded enteric fermentation emissions. Total emissions are converted to annual emision fluxes (molec./cm2/s) and are written to final netCDFs in the '/code/Final_Gridded_Data/' folder. \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "## Step 0. Set-Up Notebook Modules, Functions, and Local Parameters and Constants\n",
    "_____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirm working directory\n",
    "import os\n",
    "import time\n",
    "modtime = os.path.getmtime('./3A_Livestock_Enteric.ipynb')\n",
    "modificationTime = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(modtime))\n",
    "print(\"This file was last modified on: \", modificationTime)\n",
    "print('')\n",
    "print(\"The directory we are working in is {}\" .format(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include plots within notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import base modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import datetime\n",
    "from copy import copy\n",
    "\n",
    "# Import additional modules\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "# Load netCDF (for manipulating netCDF file types)\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "# Set up ticker\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "#add path for the global function module (file)\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../Global_Functions/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# Load user-defined global functions (modules)\n",
    "import data_load_functions as data_load_fn\n",
    "import data_functions as data_fn\n",
    "import data_IO_functions as data_IO_fn\n",
    "import data_plot_functions as data_plot_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INPUT Files\n",
    "# Assign global file names\n",
    "global_filenames = data_load_fn.load_global_file_names()\n",
    "State_ANSI_inputfile = global_filenames[0]\n",
    "County_ANSI_inputfile = global_filenames[1]\n",
    "pop_map_inputfile = global_filenames[2]\n",
    "Grid_area01_inputfile = global_filenames[3]\n",
    "Grid_area001_inputfile = global_filenames[4]\n",
    "Grid_state001_ansi_inputfile = global_filenames[5]\n",
    "Grid_county001_ansi_inputfile = global_filenames[6]\n",
    "\n",
    "# Specify names of inputs files used in this notebook\n",
    "EPA_enteric_cattle_inputfile = \"../Global_InputData/GHGI/Ch5_Agriculture/EntericOutputs_1990-2018-final.xlsx\" #EPA_Enteric_Cattle.csv\"\n",
    "EPA_enteric_cattle2018_inputfile = \"./InputData/EPA_Enteric_Cattle_2018.csv\"\n",
    "EPA_enteric_other_inputfile = \"../Global_InputData/GHGI/Ch5_Agriculture/OtherEnteric18_master-Final.xlsx\"\n",
    "Census_12_inputloc =  \"./InputData/USDA_Census/Census_12_\"\n",
    "Census_17_inputloc =  \"./InputData/USDA_Census/Census_17_\"\n",
    "USDA_LUC_inputloc = \"./InputData/Data_map/usda_luc_rank_\"\n",
    "EPA_AGR_inputfile = \"../Global_InputData/GHGI/Ch5_Agriculture/Table 5-2.csv\"\n",
    "\n",
    "#Proxy Data file\n",
    "Livestock_Mapping_inputfile = \"./InputData/Livestock_Enteric_ProxyMapping.xlsx\"\n",
    "\n",
    "#Specify names of gridded output files\n",
    "enteric_int_out = './IntermediateOutputs/Intermediate_EPA_v2_3A_Enteric_Fermentation.nc'\n",
    "\n",
    "gridded_outputfile = '../Final_Gridded_Data/EPA_v2_3A_Enteric_Fermentation.nc'\n",
    "netCDF_description = 'Gridded EPA Inventory - Enteric Fermentation Emissions - IPCC Source Category 3A'\n",
    "title_str = \"EPA methane emissions from enteric fermentation\"\n",
    "title_diff_str = \"Emissions from enteric fermentation difference: 2018-2012\"\n",
    "\n",
    "#output gridded proxy data\n",
    "grid_emi_outputfile = '../Final_Gridded_Data/Extension/v2_input_data/Livestock_Enteric_Grid_Emi.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define local variables\n",
    "start_year = 2012  #First year in emission timeseries\n",
    "end_year = 2018    #Last year in emission timeseries\n",
    "year_range = [*range(start_year, end_year+1,1)] #List of emission years\n",
    "year_range_str=[str(i) for i in year_range]\n",
    "num_years = len(year_range)\n",
    "\n",
    "# Define constants\n",
    "Avogadro   = 6.02214129 * 10**(23)  #molecules/mol\n",
    "Molarch4   = 16.04                  #g/mol\n",
    "Res01      = 0.1                    # degrees\n",
    "\n",
    "# Continental US Lat/Lon Limits (for netCDF files)\n",
    "Lon_left = -130       #deg\n",
    "Lon_right = -60       #deg\n",
    "Lat_low  = 20         #deg\n",
    "Lat_up  = 55          #deg\n",
    "\n",
    "loc_dimensions = [Lat_low, Lat_up, Lon_left, Lon_right]\n",
    "ilat_start = int((90+Lat_low)/Res01) #1100:1450 (continental US range)\n",
    "ilat_end = int((90+Lat_up)/Res01)\n",
    "ilon_start = abs(int((-180-Lon_left)/Res01)) #500:1200 (continental US range)\n",
    "ilon_end = abs(int((-180-Lon_right)/Res01))\n",
    "\n",
    "# Number of days in each month\n",
    "month_day_leap  = [  31,  29,  31,  30,  31,  30,  31,  31,  30,  31,  30,  31]\n",
    "month_day_nonleap = [  31,  28,  31,  30,  31,  30,  31,  31,  30,  31,  30,  31]\n",
    "\n",
    "# Month arrays\n",
    "month_range_str = ['January','February','March','April','May','June','July','August','September','October','November','December']\n",
    "num_months = len(month_range_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define animal type arrays\n",
    "#Generate a vector with all the animal types in the county-level census data (use .csv naming convention):\n",
    "#animal_array = ['Beef','Bison','Broilers','Cattle','Chickens','Dairy','Goats','Hogs','Horses',\\\n",
    "#                'Layers','OnFeed','Pullets','Roosters','Sheep','Turkeys']\n",
    "\n",
    "#Generate a vector with the 9 animal types used to grid county-level emissions:\n",
    "#Census data to LUC data mapping:\n",
    "#Uniform --> animal\n",
    "#Broilers + Turkeys --> brltrk\n",
    "#On Feed --> ctlfed\n",
    "#Beef + Bison +Cattle --> ctlinv\n",
    "#Goats --> goat\n",
    "#Hogs --> hogpig\n",
    "#Horses --> hrspny\n",
    "#Chickens + Layers + Pullets + Roosters --> lyrplt\n",
    "#Dairy --> mlkcow\n",
    "#Sheep --> shplmb\n",
    "#luc_animal_array = ['animal','brltrk','ctlfed','ctlinv','goat','hogpig','hrspny','lyrplt','mlkcow','shplmb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.auto_scroll_threshold = 9999;\n",
    "//prevent auto-scrolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track run time\n",
    "ct = datetime.datetime.now() \n",
    "it = ct.timestamp() \n",
    "print(\"current time:\", ct) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "## Step 1. Load in State and County ANSI data and Area Maps\n",
    "_____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State-level ANSI Data\n",
    "#Read the state ANSI file array\n",
    "State_ANSI, name_dict, abbr_dict = data_load_fn.load_state_ansi(State_ANSI_inputfile)[0:3]\n",
    "#QA: number of states\n",
    "print('Read input file: '+ f\"{State_ANSI_inputfile}\")\n",
    "print('Total \"States\" found: ' + '%.0f' % len(State_ANSI))\n",
    "print(' ')\n",
    "\n",
    "# 0.01 x0.01 degree Data\n",
    "# State ANSI IDs and grid cell area (m2) maps\n",
    "state_ANSI_map = data_load_fn.load_state_ansi_map(Grid_state001_ansi_inputfile)\n",
    "area_map, lat001, lon001 = data_load_fn.load_area_map_001(Grid_area001_inputfile)\n",
    "\n",
    "\n",
    "#County ANSI Data\n",
    "#Includes State ANSI number, county ANSI number, county name, and country area (square miles)\n",
    "County_ANSI = pd.read_csv(County_ANSI_inputfile,encoding='latin-1')\n",
    "\n",
    "#QA: number of counties\n",
    "print ('Read input file: ' + f\"{County_ANSI_inputfile}\")\n",
    "print('Total \"Counties\" found (include PR): ' + '%.0f' % len(County_ANSI))\n",
    "print(' ')\n",
    "\n",
    "#Create a placeholder array for county data\n",
    "county_array = np.zeros([len(County_ANSI),3])\n",
    "\n",
    "#Populate array with State ANSI number (0), county ANSI number (1), and county area (2)\n",
    "for icounty in np.arange(0,len(County_ANSI)):\n",
    "    county_array[icounty,0] = int(County_ANSI.values[icounty,0])\n",
    "    county_array[icounty,1] = int(County_ANSI.values[icounty,1])\n",
    "    county_array[icounty,2] = County_ANSI.values[icounty,3]\n",
    "\n",
    "# 0.01 x0.01 degree Data\n",
    "# State ANSI IDs and grid cell area (m2) maps\n",
    "state_ANSI_map = data_load_fn.load_state_ansi_map(Grid_state001_ansi_inputfile)\n",
    "state_ANSI_map = state_ANSI_map.astype('int32')\n",
    "county_ANSI_map = data_load_fn.load_county_ansi_map(Grid_county001_ansi_inputfile)\n",
    "county_ANSI_map = county_ANSI_map.astype('int32')\n",
    "area_map, lat001, lon001 = data_load_fn.load_area_map_001(Grid_area001_inputfile)\n",
    "\n",
    "# 0.1 x0.1 degree data\n",
    "# grid cell area and state and county ANSI maps\n",
    "area_map01, Lat01, Lon01 = data_load_fn.load_area_map_01(Grid_area01_inputfile)[0:3]\n",
    "#Select relevant Continental 0.1 x0.1 domain\n",
    "Lat_01 = Lat01[ilat_start:ilat_end]\n",
    "Lon_01 = Lon01[ilon_start:ilon_end]\n",
    "area_matrix_01 = data_fn.regrid001_to_01(area_map, Lat_01, Lon_01)\n",
    "area_matrix_01 *= 10000  #convert from m2 to cm2\n",
    "\n",
    "state_ANSI_map_01 = data_fn.regrid001_to_01(state_ANSI_map, Lat_01, Lon_01)\n",
    "\n",
    "# Print time\n",
    "ct = datetime.datetime.now() \n",
    "print(\"current time:\", ct) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------\n",
    "## Step 2. Read in and Format Proxy Data\n",
    "--------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.1 Read In Proxy Mapping File & Make Proxy Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load GHGI Mapping Groups\n",
    "names = pd.read_excel(Livestock_Mapping_inputfile, sheet_name = \"GHGI Map - Livestock\", usecols = \"A:B\",skiprows = 1, header = 0)\n",
    "colnames = names.columns.values\n",
    "ghgi_livestock_map = pd.read_excel(Livestock_Mapping_inputfile, sheet_name = \"GHGI Map - Livestock\", usecols = \"A:B\", skiprows = 1, names = colnames)\n",
    "#drop rows with no data, remove the parentheses and \"\"\n",
    "ghgi_livestock_map = ghgi_livestock_map[ghgi_livestock_map['GHGI_Emi_Group'] != 'na']\n",
    "ghgi_livestock_map = ghgi_livestock_map[ghgi_livestock_map['GHGI_Emi_Group'].notna()]\n",
    "ghgi_livestock_map['GHGI_Source']= ghgi_livestock_map['GHGI_Source'].str.replace(r\"\\(\",\"\")\n",
    "ghgi_livestock_map['GHGI_Source']= ghgi_livestock_map['GHGI_Source'].str.replace(r\"\\)\",\"\")\n",
    "ghgi_livestock_map.reset_index(inplace=True, drop=True)\n",
    "display(ghgi_livestock_map)\n",
    "\n",
    "#load emission group - proxy map\n",
    "names = pd.read_excel(Livestock_Mapping_inputfile, sheet_name = \"Proxy Map - Livestock\", usecols = \"A:G\",skiprows = 1, header = 0)\n",
    "colnames = names.columns.values\n",
    "proxy_livestock_map = pd.read_excel(Livestock_Mapping_inputfile, sheet_name = \"Proxy Map - Livestock\", usecols = \"A:G\", skiprows = 1, names = colnames)\n",
    "display((proxy_livestock_map))\n",
    "\n",
    "#create empty proxy and emission group arrays (add months for proxy variables that have monthly data)\n",
    "for igroup in np.arange(0,len(proxy_livestock_map)):\n",
    "    if proxy_livestock_map.loc[igroup, 'Grid_Month_Flag'] ==0:\n",
    "        vars()[proxy_livestock_map.loc[igroup,'Proxy_Group']] = np.zeros([len(Lat_01),len(Lon_01),num_years])\n",
    "        vars()[proxy_livestock_map.loc[igroup,'Proxy_Group']+'_nongrid'] = np.zeros([num_years])\n",
    "    else:\n",
    "        vars()[proxy_livestock_map.loc[igroup,'Proxy_Group']] = np.zeros([len(Lat_01),len(Lon_01),num_years,num_months])\n",
    "        vars()[proxy_livestock_map.loc[igroup,'Proxy_Group']+'_nongrid'] = np.zeros([num_years,num_months])\n",
    "        \n",
    "    vars()[proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']] = np.zeros([num_years])\n",
    "    \n",
    "    if proxy_livestock_map.loc[igroup,'State_Proxy_Group'] != '-':\n",
    "        if proxy_livestock_map.loc[igroup,'State_Month_Flag'] == 0:\n",
    "            vars()[proxy_livestock_map.loc[igroup,'State_Proxy_Group']] = np.zeros([len(State_ANSI),num_years])\n",
    "        else:\n",
    "            vars()[proxy_livestock_map.loc[igroup,'State_Proxy_Group']] = np.zeros([len(State_ANSI),num_years,num_months])\n",
    "    else:\n",
    "        continue # do not make state proxy variable if no variable assigned in mapping file\n",
    "        \n",
    "    if proxy_livestock_map.loc[igroup,'County_Proxy_Group'] != '-':\n",
    "        if proxy_livestock_map.loc[igroup,'County_Month_Flag'] == 0:\n",
    "            vars()[proxy_livestock_map.loc[igroup,'County_Proxy_Group']] = np.zeros([len(State_ANSI),len(County_ANSI),num_years])\n",
    "        else:\n",
    "            vars()[proxy_livestock_map.loc[igroup,'County_Proxy_Group']] = np.zeros([len(State_ANSI),len(County_ANSI),num_years,num_months])\n",
    "    else:\n",
    "        continue # do not make state proxy variable if no variable assigned in mapping file\n",
    "\n",
    "        \n",
    "emi_group_names = np.unique(ghgi_livestock_map['GHGI_Emi_Group'])\n",
    "\n",
    "print('QA/QC: Is the number of emission groups the same for the proxy and emissions tabs?')\n",
    "if (len(emi_group_names) == len(np.unique(proxy_livestock_map['GHGI_Emi_Group']))):\n",
    "    print('PASS')\n",
    "else:\n",
    "    print('FAIL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.2 Read in the GHGI State Emissions Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.2.1. Enteric Fermentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2.2.1.1 Read in 2012-2017 state emissions for beef, cattle, diary, and onfeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in and format EPA enteric methane emissions (mt/yr) by state and animal type\n",
    "# This inlcude all data from 2012-2017 (state levels by animal types were not re-calculated\n",
    "# for the year 2018 in the GHGI)\n",
    "\n",
    "# Array dimensions:\n",
    "# 10 animal types x state x year\n",
    "emi_state_ent_animal = np.zeros([10,len(State_ANSI),num_years])\n",
    "\n",
    "#Note: no county data for mules (set to 'uniform')\n",
    "\n",
    "# Do cattle first\n",
    "\n",
    "#Read and format EPA enteric methane emissions (metric tons/year) from cattle\n",
    "#Loop over emission years and a) Read data, b) format data table, c) split into 4 animal categories, \n",
    "# then convert to Tg, and insert annual data into final array\n",
    "next_year_temp = np.zeros([50,num_years+1])\n",
    "\n",
    "#first read in 2011 'next year emissions'\n",
    "iyear=0\n",
    "start_loc = (year_range[iyear]-1-1989)*34+3\n",
    "num_rowvars = 27\n",
    "Ent_Cat_2011 = pd.read_excel(EPA_enteric_cattle_inputfile,skiprows=(start_loc),nrows=num_rowvars, usecols='D:BB',sheet_name = 'Output Summary')\n",
    "Ent_Cat_2011 = Ent_Cat_2011.set_index('Region').T.rename_axis('State').reset_index()#.rename_axis(None, 1).reset_index()\n",
    "Ent_Cat_2011.fillna(0, inplace=True)\n",
    "#these are added to the following year totals\n",
    "next_year_temp[:,iyear] = Ent_Cat_2011['Steer <600 Next Yr.']+\\\n",
    "                                Ent_Cat_2011['Steer 600 to 700 Next Yr.']+\\\n",
    "                                Ent_Cat_2011['Steer 700 to 800 Next Yr.']+\\\n",
    "                                Ent_Cat_2011['Steer >800 Next Yr.']+\\\n",
    "                                Ent_Cat_2011['Heifer <600 Next Yr.']+\\\n",
    "                                Ent_Cat_2011['Heifer 600 to 700 Next Yr.']+\\\n",
    "                                Ent_Cat_2011['Heifer 700 to 800 Next Yr.']+\\\n",
    "                                Ent_Cat_2011['Heifer >800 Next Yr.']\n",
    "\n",
    "for iyear in np.arange(0,num_years): \n",
    "\n",
    "    #a) Read data\n",
    "    # Rows correspond to years (1989-2020), columns to state. For each year, 27 variables (rows) are reported\n",
    "    # (34 rows total for each data block of years).Therefore, the first row that should be read for each year \n",
    "    # is the year index*34 + 3 header rows.\n",
    "    start_loc = (year_range[iyear]-1989)*34+3\n",
    "    num_rowvars = 27\n",
    "    Ent_Cat_temp = pd.read_excel(EPA_enteric_cattle_inputfile,skiprows=(start_loc),nrows=num_rowvars, usecols='D:BB',sheet_name = 'Output Summary')\n",
    "\n",
    "\n",
    "    #b) Format data table\n",
    "    # Take transpose of the array to get State by Variable, fill NaN values with '0', rename columns, remove\n",
    "    # extra rows, and select the first 50 rows (e.g., data for 50 states).\n",
    "    #Ent_Cat_temp = Ent_Cat_temp.transpose()\n",
    "    Ent_Cat_temp.fillna(0, inplace=True)\n",
    "    Ent_Cat_temp = Ent_Cat_temp.set_index('Region').T.rename_axis('State').reset_index()#.rename_axis(None, 1).reset_index()\n",
    "    \n",
    "    #c) Separate cattle into their 4 categories (Beef, Cattle, Dairy, OnFeed)\n",
    "    # For each, sum specified variables and remove the individual columns\n",
    "    #Beef\n",
    "    Ent_Cat_temp['Beef'] = Ent_Cat_temp['Bulls']+Ent_Cat_temp['Beef Calves']+\\\n",
    "                            Ent_Cat_temp['Beef Cows']+Ent_Cat_temp['Beef Repl. Heif. 0-12']+\\\n",
    "                            Ent_Cat_temp['Beef Repl. Heif. 12-24']\n",
    "    Ent_Cat_temp.drop(['Bulls','Beef Cows','Beef Repl. Heif. 0-12','Beef Repl. Heif. 12-24',\\\n",
    "                       'Beef Calves'], axis=1, inplace=True)\n",
    "    #Cattle\n",
    "    Ent_Cat_temp['Cattle'] = Ent_Cat_temp['Steer Stockers']+Ent_Cat_temp['Heifer Stockers']\n",
    "    Ent_Cat_temp.drop(['Steer Stockers','Heifer Stockers'], axis=1, inplace=True)\n",
    "    #Dairy\n",
    "    Ent_Cat_temp['Dairy'] = Ent_Cat_temp['Dairy Calves']+Ent_Cat_temp['Dairy Cows']+\\\n",
    "                            Ent_Cat_temp['Dairy Repl. Heif. 0-12']+\\\n",
    "                            Ent_Cat_temp['Dairy Repl. Heif. 12-24']\n",
    "    Ent_Cat_temp.drop(['Dairy Calves','Dairy Cows','Dairy Repl. Heif. 0-12',\\\n",
    "                       'Dairy Repl. Heif. 12-24'], axis=1, inplace=True)\n",
    "    #OnFeed\n",
    "    Ent_Cat_temp['OnFeed'] = Ent_Cat_temp['Steer <600']+Ent_Cat_temp['Steer 600 to 700']+\\\n",
    "                                Ent_Cat_temp['Steer 700 to 800']+Ent_Cat_temp['Steer >800']+\\\n",
    "                                Ent_Cat_temp['Heifer <600']+Ent_Cat_temp['Heifer 600 to 700']+\\\n",
    "                                Ent_Cat_temp['Heifer 700 to 800']+Ent_Cat_temp['Heifer >800']\n",
    "    #these are added to the following year totals (i.e., 2011 added to 2012, but won't use 2018 value here)\n",
    "    next_year_temp[:,iyear+1] = Ent_Cat_temp['Steer <600 Next Yr.']+\\\n",
    "                                Ent_Cat_temp['Steer 600 to 700 Next Yr.']+\\\n",
    "                                Ent_Cat_temp['Steer 700 to 800 Next Yr.']+\\\n",
    "                                Ent_Cat_temp['Steer >800 Next Yr.']+\\\n",
    "                                Ent_Cat_temp['Heifer <600 Next Yr.']+\\\n",
    "                                Ent_Cat_temp['Heifer 600 to 700 Next Yr.']+\\\n",
    "                                Ent_Cat_temp['Heifer 700 to 800 Next Yr.']+\\\n",
    "                                Ent_Cat_temp['Heifer >800 Next Yr.']\n",
    "    #display(Ent_Cat_temp)\n",
    "    Ent_Cat_temp.drop(['Steer <600','Steer 600 to 700','Steer 700 to 800','Steer >800',\\\n",
    "                       'Heifer <600','Heifer 600 to 700','Heifer 700 to 800','Heifer >800',\\\n",
    "                       'Steer <600 Next Yr.','Steer 600 to 700 Next Yr.','Steer 700 to 800 Next Yr.',\\\n",
    "                       'Steer >800 Next Yr.','Heifer <600 Next Yr.','Heifer 600 to 700 Next Yr.',\\\n",
    "                       'Heifer 700 to 800 Next Yr.','Heifer >800 Next Yr.'], axis=1, inplace=True)\n",
    "    \n",
    "    #Build the timeseries array using data from each year\n",
    "    for istate in np.arange(0, len(Ent_Cat_temp)):\n",
    "        match_state = np.where(Ent_Cat_temp['State'][istate].rstrip() == State_ANSI['name'])[0][0]\n",
    "        emi_state_ent_animal[0,match_state,iyear] = Ent_Cat_temp.loc[istate,'Beef']/1e3 #convert mt to kt\n",
    "        emi_state_ent_animal[1,match_state,iyear] = Ent_Cat_temp.loc[istate,'Cattle']/1e3\n",
    "        emi_state_ent_animal[2,match_state,iyear] = Ent_Cat_temp.loc[istate,'Dairy']/1e3\n",
    "        emi_state_ent_animal[3,match_state,iyear] = (Ent_Cat_temp.loc[istate,'OnFeed']+next_year_temp[istate,iyear])/1e3\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2.2.1.2 Read in 2018 GHGI state emissions for beef, cattle, diary, and onfeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate 2018 state levels for cattle\n",
    "\n",
    "# Read and format the EPA enteric methane emissions (kt/year) from cattle, for the year 2018.\n",
    "\n",
    "# The 2018 data are only available as national totals. To calculate State contributions in 2018, \n",
    "# calcualte the 2017 fractional contributions of diary, beef, cattle, and on feed emissions in \n",
    "# each state relative to the national total emissions. Then apply these fractional state \n",
    "# contributions to the 2018 national total emissions to calculate 2017 state-level emissions. \n",
    "\n",
    "national_2018_ent = np.zeros([4])\n",
    "\n",
    "#a) Read the 2018 national methane emissions data (kt/year). The Livestock type \n",
    "# data are on the first 29 rows. Format by dropping the first two empty rows, reset\n",
    "# the index numbers, and convert to floating point numbers.\n",
    "Ent_Cat_18 = pd.read_excel(EPA_enteric_cattle_inputfile,skiprows=20,nrows=32, usecols='A,E',sheet_name = '2018 Calculations')\n",
    "Ent_Cat_18.dropna(axis=0,inplace=True)\n",
    "Ent_Cat_18.reset_index(inplace=True,drop=True)\n",
    "Ent_Cat_18['2018 Methane Emissions'] = pd.to_numeric(Ent_Cat_18['2018 Methane Emissions'])\n",
    "\n",
    "#b) Calculate the total national emissions (Tg/year) as the sum of national emissions (kt/year)\n",
    "#for the relevant animal types in 2018.\n",
    "#Dairy\n",
    "select_variables = ['DAIRY ']\n",
    "mask = Ent_Cat_18.loc[Ent_Cat_18['CEFM Livestock Type'].isin(select_variables)]\n",
    "national_2018_ent[2] = float(sum(mask['2018 Methane Emissions']))#/float(1000) #Tg\n",
    "#Beef\n",
    "select_variables = ['Bulls','Beef Calves','Beef Cows','Beef Replacements 7-11 months','Beef Replacements 12-23 months']\n",
    "mask = Ent_Cat_18.loc[Ent_Cat_18['CEFM Livestock Type'].isin(select_variables)]\n",
    "national_2018_ent[0] = float(sum(mask['2018 Methane Emissions']))#/float(1000) #Tg\n",
    "#Cattle\n",
    "select_variables = ['Steer Stockers','Heifer Stockers']\n",
    "mask = Ent_Cat_18.loc[Ent_Cat_18['CEFM Livestock Type'].isin(select_variables)]\n",
    "national_2018_ent[1] = float(sum(mask['2018 Methane Emissions']))#/float(1000) #Tg\n",
    "#OnFeed\n",
    "select_variables = ['Steer Feedlot','Heifer Feedlot']\n",
    "mask = Ent_Cat_18.loc[Ent_Cat_18['CEFM Livestock Type'].isin(select_variables)]\n",
    "national_2018_ent[3] = float(sum(mask['2018 Methane Emissions']))#/float(1000) #Tg\n",
    "#print(national_2018_ent)\n",
    "#c) Calculate state-level emissions from national totals, using 2017 fractional state contributions\n",
    "# for each aggregate animal type (Beef, dairy, cattel, onfeed). Then put the calculated emissions for each \n",
    "# state into the final enteric emissions array for the year 2018. \n",
    "# 2018 = 2017 state fraction * 2018 national total\n",
    "index_2017 = year_range.index(2017)\n",
    "for ianimal in np.arange(0,4):\n",
    "    statefractions_17_temp = emi_state_ent_animal[ianimal,:,index_2017]/np.sum(emi_state_ent_animal[ianimal,:,index_2017])\n",
    "    #print(np.sum(statefractions_17_temp))\n",
    "    emi_state_ent_animal[ianimal,:,index_2017+1] = national_2018_ent[ianimal] * statefractions_17_temp\n",
    "    \n",
    "    #beef, cattle, dairy, onfeed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2.2.1.3 Read in 2012-2018 GHGI state emissions for all other animal types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ent_Other_temp = pd.read_excel(EPA_enteric_other_inputfile, sheet_name = 'ERG Pops by State')\n",
    "\n",
    "emi_state_ent_animal[4:10,:,:] = 0 #make sure all values are set to zero before populating\n",
    "\n",
    "#emissions (kt) = total counts of animals * emission factor / 1e6 (to get from kg/head to kt)\n",
    "# emission factors from 'EPA_enteric_other_inputfile', 'Emissions' tab\n",
    "# bison = 82.2 kg CH4/head/year\n",
    "# goats = 5.0 kg CH4/head/year\n",
    "# horses = 18.0 kg CH4/head/year\n",
    "# mules = 10.0 kg CH4/head/year\n",
    "# sheep = 8.0 kg CH4/head/year\n",
    "# Swine = 1.5 kg CH4/head/year\n",
    "\n",
    "for iyear in np.arange(0, num_years):\n",
    "    temp_bis = Ent_Other_temp.loc[(Ent_Other_temp['year']==year_range[iyear]) & (Ent_Other_temp['animal']=='bison')]\n",
    "    temp_bis.reset_index(inplace=True,drop=True)\n",
    "    temp_goa = Ent_Other_temp.loc[(Ent_Other_temp['year']==year_range[iyear]) & (Ent_Other_temp['animal']=='goats')]\n",
    "    temp_goa.reset_index(inplace=True,drop=True)\n",
    "    temp_hor = Ent_Other_temp.loc[(Ent_Other_temp['year']==year_range[iyear]) & (Ent_Other_temp['animal']=='horses')]\n",
    "    temp_hor.reset_index(inplace=True,drop=True)\n",
    "    temp_mul = Ent_Other_temp.loc[(Ent_Other_temp['year']==year_range[iyear]) & (Ent_Other_temp['animal']=='mules')]\n",
    "    temp_mul.reset_index(inplace=True,drop=True)\n",
    "    temp_she = Ent_Other_temp.loc[(Ent_Other_temp['year']==year_range[iyear]) & (Ent_Other_temp['animal']=='sheep')]\n",
    "    temp_she.reset_index(inplace=True,drop=True)\n",
    "    temp_swi = Ent_Other_temp.loc[(Ent_Other_temp['year']==year_range[iyear]) & (Ent_Other_temp['animal'].str.contains('swine_120_179|swine_180|swine_50|swine_50_119|swine_breeding'))]\n",
    "    temp_swi.reset_index(inplace=True,drop=True)\n",
    "    \n",
    "    #populate state array\n",
    "    for istate in np.arange(0, len(temp_bis)):\n",
    "        match_state = np.where(temp_bis['state'][istate].rstrip() == State_ANSI['abbr'])[0][0]\n",
    "        emi_state_ent_animal[4,match_state,iyear] = temp_bis.loc[istate,'head']*82.2/1e6 #(kt) #/(25*1e-3) #covert from MMT CO2e to kt\n",
    "    for istate in np.arange(0, len(temp_goa)):\n",
    "        match_state = np.where(temp_goa['state'][istate].rstrip() == State_ANSI['abbr'])[0][0]\n",
    "        emi_state_ent_animal[5,match_state,iyear] = temp_goa.loc[istate,'head']*5/1e6 #(kt) #/(25*1e-3) #covert from MMT CO2e to kt\n",
    "    for istate in np.arange(0, len(temp_hor)):\n",
    "        match_state = np.where(temp_hor['state'][istate].rstrip() == State_ANSI['abbr'])[0][0]\n",
    "        emi_state_ent_animal[6,match_state,iyear] = temp_hor.loc[istate,'head']*18/1e6 #(kt) #/(25*1e-3) #covert from MMT CO2e to kt\n",
    "    for istate in np.arange(0, len(temp_mul)):\n",
    "        match_state = np.where(temp_mul['state'][istate].rstrip() == State_ANSI['abbr'])[0][0]\n",
    "        emi_state_ent_animal[7,match_state,iyear] = temp_mul.loc[istate,'head']*10/1e6 #(kt) #/(25*1e-3) #covert from MMT CO2e to kt\n",
    "    for istate in np.arange(0, len(temp_she)):\n",
    "        match_state = np.where(temp_she['state'][istate].rstrip() == State_ANSI['abbr'])[0][0]\n",
    "        emi_state_ent_animal[8,match_state,iyear] = temp_she.loc[istate,'head']*8/1e6 #(kt) #/(25*1e-3) #covert from MMT CO2e to kt\n",
    "    for istate in np.arange(0, len(temp_swi)):\n",
    "        #print(temp_swi['state'][istate])\n",
    "        match_state = np.where(temp_swi['state'][istate].rstrip() == State_ANSI['abbr'])[0][0]\n",
    "        emi_state_ent_animal[9,match_state,iyear] += temp_swi.loc[istate,'head']*1.5/1e6 #(kt) #/(25*1e-3) #covert from MMT CO2e to kt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2.2.1.4 Compare against national totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QA: Check the enteric emissions (summed across all animal types and states) compared to reported \n",
    "# national-level enteric emissions (kt/year) in the US GHGI. \n",
    "\n",
    "DEBUG=1\n",
    "\n",
    "#Read in total EPA emissions from public report table 5.2 (in kt)\n",
    "EPA_emi_agr_CH4 = pd.read_csv(EPA_AGR_inputfile, thousands=',', header=2,nrows = 10)\n",
    "EPA_emi_agr_CH4 = EPA_emi_agr_CH4.drop(['Unnamed: 0'], axis=1)\n",
    "EPA_emi_agr_CH4.rename(columns={EPA_emi_agr_CH4.columns[0]:'Source'}, inplace=True)\n",
    "EPA_emi_agr_CH4 = EPA_emi_agr_CH4.drop(columns = [str(n) for n in range(1990, start_year,1)])\n",
    "EPA_emi_ent_CH4 = EPA_emi_agr_CH4.loc[EPA_emi_agr_CH4['Source']==\"Enteric Fermentation\"]\n",
    "EPA_emi_ent_CH4.reset_index(inplace=True, drop=True)\n",
    "\n",
    "sum_emi = np.zeros([num_years])\n",
    "    \n",
    "print('QA/QC #1: Check State Emission Sum against GHGI Summary Emissions')\n",
    "for iyear in np.arange(0,num_years): \n",
    "    #for igroup in np.arange(0,len(ghgi_rice_groups)):\n",
    "    sum_emi[iyear] = np.sum(emi_state_ent_animal[:,:,iyear])\n",
    "        \n",
    "    summary_emi = EPA_emi_ent_CH4.iloc[0,iyear+1]  \n",
    "    diff1 = abs(sum_emi[iyear] - summary_emi)/((sum_emi[iyear] + summary_emi)/2)\n",
    "    if DEBUG ==1:\n",
    "        print(summary_emi)\n",
    "        print(sum_emi[iyear])\n",
    "    if diff1 < 0.0001:\n",
    "        print('Year ', year_range[iyear],': PASS, difference < 0.01%')\n",
    "    else:\n",
    "        print('Year ', year_range[iyear],': FAIL (check): ', diff1,'%') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.3 Read and Format USDA Census Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.3.1. State-Level USDA Animal Census Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2.3.1.1 First Census Year (2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize and fill arrays that will hold the state livestock numbers per animal type for the first emissions year\n",
    "\n",
    "cen_animal_array = np.array(['Beef','Bison','Broilers','Cattle','Chickens','Dairy','Goats','Hogs','Horses',\\\n",
    "                'Layers','OnFeed','Pullets','Roosters','Sheep','Turkeys']) #these are the census categories\n",
    "\n",
    "proxy_animal_array = np.array(['Beef','Cattle','Dairy','OnFeed','Bison','Goats','Horses',\\\n",
    "                'Mules','Sheep','Swine']) #these are the categories from the state GHGI\n",
    "\n",
    "State_census_livestock_12 = np.zeros([len(cen_animal_array),len(State_ANSI)])\n",
    "State_livestock_12 = np.zeros([len(proxy_animal_array),len(State_ANSI)])\n",
    "    \n",
    "# a) Read in 2012 state census data (one file per animal type), b) pull out the state ANSI numbers and animal\n",
    "# counts data, c) for each state, reformat the state name and set the animal number to an integer, and \n",
    "# d) insert the state animal counts into the final livestock counts array as a function of state and animal type \n",
    "for ianimal in np.arange(0,len(cen_animal_array)):\n",
    "    if not (cen_animal_array[ianimal].strip('Chickens')): # No census file for chickens, skip for now\n",
    "        continue\n",
    "    #a)\n",
    "    State_file = Census_12_inputloc + cen_animal_array[ianimal] + \"_State.csv\"\n",
    "    print('Reading file: ' + State_file)\n",
    "    State_temp = pd.read_csv(State_file)\n",
    "    #b) \n",
    "    Census12_State = State_temp[['State ANSI','Value']].copy()\n",
    "    Census12_State['Value']= Census12_State['Value'].str.replace(r\"\\(D\\)\",\"0\")\n",
    "    Census12_State['Value']= Census12_State['Value'].str.replace(\",\",\"\").astype(float)\n",
    "    Census12_State['State ANSI']= Census12_State['State ANSI'].astype(int)\n",
    "    #c)\n",
    "    for istate in np.arange(0,len(Census12_State)):\n",
    "        match_state = np.where(Census12_State['State ANSI'][istate] == State_ANSI['ansi'])[0][0]\n",
    "        State_census_livestock_12[ianimal,match_state] = Census12_State['Value'][istate]\n",
    "\n",
    "\n",
    "#assign the census data to the correct animal type order (proxy animal order)\n",
    "for ianimal in np.arange(0,len(proxy_animal_array)):\n",
    "    if proxy_animal_array[ianimal] == 'Mules':\n",
    "        continue #will grid by area later (no county data)\n",
    "    elif proxy_animal_array[ianimal] == 'Chickens': \n",
    "        State_livestock_12[ianimal,:] = State_census_livestock_12[np.where(cen_animal_array=='Broilers')[0][0],:] \\\n",
    "                                    +State_census_livestock_12[np.where(cen_animal_array=='Layers')[0][0],:] \\\n",
    "                                    +State_census_livestock_12[np.where(cen_animal_array=='Pullets')[0][0],:]\\\n",
    "                                    +State_census_livestock_12[np.where(cen_animal_array=='Roosters')[0][0],:]\n",
    "    elif proxy_animal_array[ianimal] == 'Swine': \n",
    "        State_livestock_12[ianimal,:] = State_census_livestock_12[np.where(cen_animal_array=='Hogs')[0][0],:]\n",
    "    else:\n",
    "        match_ani = np.where(proxy_animal_array[ianimal] == cen_animal_array)[0][0]\n",
    "        State_livestock_12[ianimal,:] = State_census_livestock_12[match_ani,:]\n",
    "        \n",
    "display(np.shape(State_livestock_12))\n",
    "display((State_livestock_12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2.3.1.2 Last Census Year (2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize and fill arrays that will hold the state livestock numbers per animal type for the last available emissions year\n",
    "\n",
    "State_census_livestock_17 = np.zeros([len(cen_animal_array),len(State_ANSI)])\n",
    "State_livestock_17 = np.zeros([len(proxy_animal_array),len(State_ANSI)])\n",
    "\n",
    "    \n",
    "# a) Read in 2012 state census data (one file per animal type), b) pull out the state ANSI numbers and animal\n",
    "# counts data, c) for each state, reformat the state name and set the animal number to an integer, and \n",
    "# d) insert the state animal counts into the final livestock counts array as a function of state and animal type \n",
    "for ianimal in np.arange(0,len(cen_animal_array)):\n",
    "    if not (cen_animal_array[ianimal].strip('Chickens')): # No census file for chickens, skip for now\n",
    "        continue\n",
    "    #a)\n",
    "    State_file = Census_17_inputloc + cen_animal_array[ianimal] + \"_State.csv\"\n",
    "    print('Reading file: ' + State_file)\n",
    "    State_temp = pd.read_csv(State_file)\n",
    "    #b) \n",
    "    Census17_State = State_temp[['State ANSI','Value']].copy()\n",
    "    Census17_State['Value']= Census17_State['Value'].str.replace(r\"\\(D\\)\",\"0\")\n",
    "    Census17_State['Value']= Census17_State['Value'].str.replace(\",\",\"\").astype(float)\n",
    "    Census17_State['State ANSI']= Census17_State['State ANSI'].astype(int)\n",
    "    #c)\n",
    "    for istate in np.arange(0,len(Census17_State)):\n",
    "        match_state = np.where(Census17_State['State ANSI'][istate] == State_ANSI['ansi'])[0][0]\n",
    "        State_census_livestock_17[ianimal,match_state] = Census17_State['Value'][istate]\n",
    "\n",
    "\n",
    "#assign the census data to the correct animal type order (proxy animal order)\n",
    "for ianimal in np.arange(0,len(proxy_animal_array)):\n",
    "    if proxy_animal_array[ianimal] == 'Mules':\n",
    "        continue #will grid by area later (no county data)\n",
    "    elif proxy_animal_array[ianimal] == 'Chickens': \n",
    "        State_livestock_17[ianimal,:] = State_census_livestock_17[np.where(cen_animal_array=='Broilers')[0][0],:] \\\n",
    "                                    +State_census_livestock_17[np.where(cen_animal_array=='Layers')[0][0],:] \\\n",
    "                                    +State_census_livestock_17[np.where(cen_animal_array=='Pullets')[0][0],:]\\\n",
    "                                    +State_census_livestock_17[np.where(cen_animal_array=='Roosters')[0][0],:]\n",
    "    elif proxy_animal_array[ianimal] == 'Swine':\n",
    "        State_livestock_17[ianimal,:] = State_census_livestock_17[np.where(cen_animal_array=='Hogs')[0][0],:]\n",
    "\n",
    "    else:\n",
    "        match_ani = np.where(proxy_animal_array[ianimal] == cen_animal_array)[0][0]\n",
    "        State_livestock_17[ianimal,:] = State_census_livestock_17[match_ani,:]\n",
    "        \n",
    "display(np.shape(State_livestock_17))\n",
    "display((State_livestock_17))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.3.2 Read and Format County-Level USDA Animal Census Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2.3.2.1. First Census Year (2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Initialize and fill arrays that will hold the county livestock numbers per animal type for the first emissions year\n",
    "\n",
    "\n",
    "County_census_livestock_12 = np.zeros([len(cen_animal_array),len(State_ANSI),len(County_ANSI)])\n",
    "County_livestock_12 = np.zeros([len(proxy_animal_array),len(State_ANSI),len(County_ANSI)])\n",
    "\n",
    "\n",
    "# a) Read in 2012 county census data (one file per animal type), b) pull out the state and county ANSI numbers and animal\n",
    "# counts data, c) for each county, reformat the county name and set the animal number to an integer, and \n",
    "# d) insert the county animal counts into the final livestock counts array as a function of state, county, and animal type \n",
    "for ianimal in np.arange(0,len(cen_animal_array)):\n",
    "    if not (cen_animal_array[ianimal].strip('Chickens')):  # No census file for chickens, skip for now\n",
    "        continue\n",
    "    # a)\n",
    "    County_file = Census_12_inputloc + cen_animal_array[ianimal] + \"_County.csv\"\n",
    "    print('Reading file: ' + County_file)\n",
    "    County_temp = pd.read_csv(County_file)\n",
    "    # b)\n",
    "    Census12_County = County_temp[['State ANSI','County ANSI','Value']].copy()\n",
    "    Census12_County['Value']= Census12_County['Value'].str.replace(r\"\\(D\\)\",\"0\")\n",
    "    Census12_County['Value']= Census12_County['Value'].str.replace(\",\",\"\").astype(float)\n",
    "    Census12_County['State ANSI']= Census12_County['State ANSI'].astype(int)\n",
    "    Census12_County['County ANSI']= Census12_County['County ANSI'].astype(int)\n",
    "    #c)\n",
    "    for icounty in np.arange(0,len(Census12_County)):\n",
    "        match_state = np.where(Census12_County['State ANSI'][icounty] == State_ANSI['ansi'])[0][0]\n",
    "        match_county = np.where((Census12_County['County ANSI'][icounty] == County_ANSI['County'])&\\\n",
    "                               (Census12_County['State ANSI'][icounty] == County_ANSI['State']))[0][0]\n",
    "        #print(match_state, match_county)\n",
    "        County_census_livestock_12[ianimal,match_state,match_county] = Census12_County['Value'][icounty]\n",
    "\n",
    "#assign the census data to the correct animal type order (proxy animal order)\n",
    "for ianimal in np.arange(0,len(proxy_animal_array)):\n",
    "    if proxy_animal_array[ianimal] == 'Mules':\n",
    "        continue #will grid by area later (no county data)\n",
    "    elif proxy_animal_array[ianimal] == 'Chickens': \n",
    "        County_livestock_12[ianimal,:] = County_census_livestock_12[np.where(cen_animal_array=='Broilers')[0][0],:] \\\n",
    "                                    +County_census_livestock_12[np.where(cen_animal_array=='Layers')[0][0],:] \\\n",
    "                                    +County_census_livestock_12[np.where(cen_animal_array=='Pullets')[0][0],:]\\\n",
    "                                    +County_census_livestock_12[np.where(cen_animal_array=='Roosters')[0][0],:]\n",
    "    elif proxy_animal_array[ianimal] == 'Swine':\n",
    "        County_livestock_12[ianimal,:] = County_census_livestock_12[np.where(cen_animal_array=='Hogs')[0][0],:]\n",
    "\n",
    "    else:\n",
    "        match_ani = np.where(proxy_animal_array[ianimal] == cen_animal_array)[0][0]\n",
    "        County_livestock_12[ianimal,:] = County_census_livestock_12[match_ani,:]\n",
    "        \n",
    "display(np.shape(County_livestock_12))\n",
    "display((County_livestock_12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2.3.2.2. Last Census Year (2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Initialize and fill arrays that will hold the county livestock numbers per animal type for the first emissions year\n",
    "\n",
    "\n",
    "County_census_livestock_17 = np.zeros([len(cen_animal_array),len(State_ANSI),len(County_ANSI)])\n",
    "County_livestock_17 = np.zeros([len(proxy_animal_array),len(State_ANSI),len(County_ANSI)])\n",
    "\n",
    "# a) Read in 2012 county census data (one file per animal type), b) pull out the state and county ANSI numbers and animal\n",
    "# counts data, c) for each county, reformat the county name and set the animal number to an integer, and \n",
    "# d) insert the county animal counts into the final livestock counts array as a function of state, county, and animal type \n",
    "for ianimal in np.arange(0,len(cen_animal_array)):\n",
    "    if not (cen_animal_array[ianimal].strip('Chickens')):  # No census file for chickens, skip for now\n",
    "        continue\n",
    "    # a)\n",
    "    County_file = Census_17_inputloc + cen_animal_array[ianimal] + \"_County.csv\"\n",
    "    print('Reading file: ' + County_file)\n",
    "    County_temp = pd.read_csv(County_file)\n",
    "    # b)\n",
    "    Census17_County = County_temp[['State ANSI','County ANSI','Value','County']].copy()\n",
    "    Census17_County['Value']= Census17_County['Value'].str.replace(r\"\\(D\\)\",\"0\")\n",
    "    Census17_County['Value']= Census17_County['Value'].str.replace(\",\",\"\").astype(float)\n",
    "    Census17_County['County ANSI'].fillna(0, inplace=True)\n",
    "    #display(Census17_County)\n",
    "    Census17_County['State ANSI']= Census17_County['State ANSI'].astype(int)\n",
    "    Census17_County['County ANSI']= Census17_County['County ANSI'].astype(int)\n",
    "    #c)\n",
    "    for icounty in np.arange(0,len(Census17_County)):\n",
    "        if Census17_County.loc[icounty,'County'].upper()=='ALEUTIAN ISLANDS':\n",
    "            Census17_County.loc[icounty,'County ANSI']=13\n",
    "        #Map Oglala Lakota County to Shannon County (2015 name change)\n",
    "        if Census17_County.loc[icounty,'State ANSI'] == 46 and \\\n",
    "            Census17_County.loc[icounty,'County ANSI'] == 102:\n",
    "            Census17_County.loc[icounty,'County ANSI'] = 113\n",
    "        #correct county value for kenai peninsula (note that AK counties are incorrect [not correcting here since AK emissions removed])\n",
    "        if Census17_County.loc[icounty,'State ANSI'] == 2 and \\\n",
    "            Census17_County.loc[icounty,'County ANSI'] == 0:\n",
    "            Census17_County.loc[icounty,'County ANSI'] = 122\n",
    "        match_state = np.where(Census17_County['State ANSI'][icounty] == State_ANSI['ansi'])[0][0]\n",
    "        match_county = np.where((Census17_County['County ANSI'][icounty] == County_ANSI['County'])&\\\n",
    "                               (Census17_County['State ANSI'][icounty] == County_ANSI['State']))[0][0]\n",
    "        #print(match_state, match_county)\n",
    "        County_census_livestock_17[ianimal,match_state,match_county] = Census17_County['Value'][icounty]\n",
    "\n",
    "\n",
    "#assign the census data to the correct animal type order (proxy animal order)\n",
    "for ianimal in np.arange(0,len(proxy_animal_array)):\n",
    "    if proxy_animal_array[ianimal] == 'Mules':\n",
    "        continue #will grid by area later (no county data)\n",
    "    elif proxy_animal_array[ianimal] == 'Chickens': \n",
    "        County_livestock_17[ianimal,:] = County_census_livestock_17[np.where(cen_animal_array=='Broilers')[0][0],:] \\\n",
    "                                    +County_census_livestock_17[np.where(cen_animal_array=='Layers')[0][0],:] \\\n",
    "                                    +County_census_livestock_17[np.where(cen_animal_array=='Pullets')[0][0],:]\\\n",
    "                                    +County_census_livestock_17[np.where(cen_animal_array=='Roosters')[0][0],:]\n",
    "    elif proxy_animal_array[ianimal] == 'Swine':\n",
    "        County_livestock_17[ianimal,:] = County_census_livestock_17[np.where(cen_animal_array=='Hogs')[0][0],:]\n",
    "    else:\n",
    "        match_ani = np.where(proxy_animal_array[ianimal] == cen_animal_array)[0][0]\n",
    "        County_livestock_17[ianimal,:] = County_census_livestock_17[match_ani,:]\n",
    "        \n",
    "display(np.shape(County_livestock_17))\n",
    "display((County_livestock_17))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.3.3. Calculate Total State-Level Animal Counts from the County-Level Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2.3.3.1 First Census Year (2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "            \n",
    "Census_summary_State_12  = np.zeros([len(proxy_animal_array),len(State_ANSI)])\n",
    "Census_summary_County_12  = np.zeros([len(proxy_animal_array),len(State_ANSI)])\n",
    "Census_summary_Missing_Area_12  = np.zeros([len(proxy_animal_array),len(State_ANSI)])\n",
    "Census_summary_per_area_12  = np.zeros([len(proxy_animal_array),len(State_ANSI)])\n",
    "\n",
    "#save the state sum, the state sum (calc'd from counties), and for a county that has zero livestock data, save area for later\n",
    "#the arrays were created to follow the index values of 'State_ANSI' and 'County_ANSI' arrays, so can just loop through these here\n",
    "for ianimal in np.arange(0, len(proxy_animal_array)):\n",
    "    for istate in np.arange(0, len(State_ANSI)):\n",
    "        Census_summary_State_12[ianimal,istate] = State_livestock_12[ianimal,istate]\n",
    "        Census_summary_County_12[ianimal,istate] = np.sum(County_livestock_12[ianimal,istate,:])\n",
    "    \n",
    "    for icounty in np.arange(0,len(County_ANSI)):\n",
    "        match_state = np.where(State_ANSI['ansi']==County_ANSI['State'][icounty])[0][0]\n",
    "        if County_livestock_12[ianimal,match_state,icounty] ==0:\n",
    "            Census_summary_Missing_Area_12[ianimal,match_state] += County_ANSI['Area'][icounty]\n",
    "        \n",
    "\n",
    "#if a state has some counties with no livestock data, then calculate missing animals per area in that state\n",
    "# missing animals in state = (state animal sum - county animal sum)/ total area of counties with no data\n",
    "\n",
    "for ianimal in np.arange(0,len(proxy_animal_array)):\n",
    "    for istate in np.arange(0,len(State_ANSI)):\n",
    "        if Census_summary_Missing_Area_12[ianimal,istate] > 0:\n",
    "            Census_summary_per_area_12[ianimal,istate] = (Census_summary_State_12[ianimal,istate] - \\\n",
    "                                                          Census_summary_County_12[ianimal,istate]) / \\\n",
    "                                                            Census_summary_Missing_Area_12[ianimal,istate]\n",
    "        if Census_summary_per_area_12[ianimal,istate] < 0:\n",
    "            Census_summary_per_area_12[ianimal,istate] = 0.0\n",
    "\n",
    "\n",
    "#Now that animals per area have been calculated for counties with missing data, fill in these\n",
    "#zeros in the county data using the (animal counts / area) X county area relationship\n",
    "#average animal per area on the state level times the area of the county\n",
    "\n",
    "\n",
    "#For each county, if it does not have livestock data, estimate the 'counts of animals per area' (in the given state) * area of that county\n",
    "#note that this places livestock emissions in all counties (is this a good assumption?)\n",
    "for ianimal in np.arange(0,len(proxy_animal_array)):\n",
    "    #for istate in np.arange(0, len(State_ANSI)):\n",
    "    for icounty in np.arange(0,len(County_ANSI)):\n",
    "        match_state = np.where(State_ANSI['ansi']==County_ANSI['State'][icounty])[0][0]\n",
    "        if County_livestock_12[ianimal,match_state,icounty] == 0.0:\n",
    "            County_livestock_12[ianimal,match_state,icounty] = Census_summary_per_area_12[ianimal,match_state] * \\\n",
    "                                                                County_ANSI['Area'][icounty]\n",
    "\n",
    "#Next, calculate the total number of animals in each state based on the number of animal in each county\n",
    "#Calculate the total number of animals in each state based on the number of animals\n",
    "\n",
    "#Calculate the area of each state from the sum of the county area data\n",
    "State_total_Area_12 = np.zeros(len(State_ANSI))\n",
    "for icounty in np.arange(0,len(County_ANSI)):\n",
    "    match_state = np.where(State_ANSI['ansi']==County_ANSI['State'][icounty])[0][0]\n",
    "    State_total_Area_12[match_state] += County_ANSI['Area'][icounty]\n",
    "    \n",
    "#Recalculate the state animal counts from the corrected county data\n",
    "State_total_animals_12 = np.zeros([len(proxy_animal_array),len(State_ANSI)])\n",
    "for ianimal in np.arange(0,len(proxy_animal_array)):\n",
    "    for icounty in np.arange(0,len(County_ANSI)):\n",
    "        match_state = np.where(State_ANSI['ansi']==County_ANSI['State'][icounty])[0][0]\n",
    "        State_total_animals_12[ianimal,match_state] += County_livestock_12[ianimal,match_state,icounty]\n",
    "\n",
    "for ianimal in np.arange(0, len(proxy_animal_array)):\n",
    "    print('Orig. Sum',np.sum(Census_summary_County_12[ianimal,:]))\n",
    "    print('Corrected Sum',np.sum(State_total_animals_12[ianimal,:]))\n",
    "    print('State Sum',np.sum(Census_summary_State_12[ianimal,:]))\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2.3.3.2 Last Census Year (2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize and calculate state-level animal count arrays from the county-level animal count data\n",
    "\n",
    "Census_summary_State_17  = np.zeros([len(proxy_animal_array),len(State_ANSI)])\n",
    "Census_summary_County_17  = np.zeros([len(proxy_animal_array),len(State_ANSI)])\n",
    "Census_summary_Missing_Area_17  = np.zeros([len(proxy_animal_array),len(State_ANSI)])\n",
    "Census_summary_per_area_17  = np.zeros([len(proxy_animal_array),len(State_ANSI)])\n",
    "\n",
    "#save the state sum, the state sum (calc'd from counties), and for a county that has zero livestock data, save area for later\n",
    "#the arrays were created to follow the index values of 'State_ANSI' and 'County_ANSI' arrays, so can just loop through these here\n",
    "for ianimal in np.arange(0, len(proxy_animal_array)):\n",
    "    for istate in np.arange(0, len(State_ANSI)):\n",
    "        Census_summary_State_17[ianimal,istate] = State_livestock_17[ianimal,istate]\n",
    "        Census_summary_County_17[ianimal,istate] = np.sum(County_livestock_17[ianimal,istate,:])\n",
    "    \n",
    "    for icounty in np.arange(0,len(County_ANSI)):\n",
    "        match_state = np.where(State_ANSI['ansi']==County_ANSI['State'][icounty])[0][0]\n",
    "        if County_livestock_17[ianimal,match_state,icounty] ==0:\n",
    "            Census_summary_Missing_Area_17[ianimal,match_state] += County_ANSI['Area'][icounty]\n",
    "\n",
    "#if a state has some counties with no livestock data, then calculate missing animals per area in that state\n",
    "# missing animals in state = (state animal sum - county animal sum)/ total area of counties with no data\n",
    "\n",
    "for ianimal in np.arange(0,len(proxy_animal_array)):\n",
    "    for istate in np.arange(0,len(State_ANSI)):\n",
    "        if Census_summary_Missing_Area_17[ianimal,istate] > 0:\n",
    "            Census_summary_per_area_17[ianimal,istate] = (Census_summary_State_17[ianimal,istate] - \\\n",
    "                                                          Census_summary_County_17[ianimal,istate]) / \\\n",
    "                                                            Census_summary_Missing_Area_17[ianimal,istate]\n",
    "        if Census_summary_per_area_17[ianimal,istate] < 0:\n",
    "            Census_summary_per_area_17[ianimal,istate] = 0.0\n",
    "\n",
    "\n",
    "#For each county, if it does not have livestock data, estimate the 'counts of animals per area' (in the given state) * area of that county\n",
    "#note that this places livestock emissions in all counties (is this a good assumption?)\n",
    "for ianimal in np.arange(0,len(proxy_animal_array)):\n",
    "    for icounty in np.arange(0,len(County_ANSI)):\n",
    "        match_state = np.where(State_ANSI['ansi']==County_ANSI['State'][icounty])[0][0]\n",
    "        if County_livestock_17[ianimal,match_state,icounty] == 0.0:\n",
    "            County_livestock_17[ianimal,match_state,icounty] = Census_summary_per_area_17[ianimal,match_state] * \\\n",
    "                                                                County_ANSI['Area'][icounty]\n",
    "\n",
    "#Next, calculate the total number of animals in each state based on the number of animal in each county\n",
    "#Calculate the total number of animals in each state based on the number of animals\n",
    "\n",
    "#Calculate the area of each state from the sum of the county area data\n",
    "State_total_Area_17 = np.zeros(len(State_ANSI))\n",
    "for icounty in np.arange(0,len(County_ANSI)):\n",
    "    match_state = np.where(State_ANSI['ansi']==County_ANSI['State'][icounty])[0][0]\n",
    "    State_total_Area_17[match_state] += County_ANSI['Area'][icounty]\n",
    "    \n",
    "#Recalculate the state animal counts from the corrected county data\n",
    "State_total_animals_17 = np.zeros([len(proxy_animal_array),len(State_ANSI)])\n",
    "for ianimal in np.arange(0,len(proxy_animal_array)):\n",
    "    for icounty in np.arange(0,len(County_ANSI)):\n",
    "        match_state = np.where(State_ANSI['ansi']==County_ANSI['State'][icounty])[0][0]\n",
    "        State_total_animals_17[ianimal,match_state] += County_livestock_17[ianimal,match_state,icounty]\n",
    "\n",
    "for ianimal in np.arange(0, len(proxy_animal_array)):\n",
    "    print('Orig. Sum',np.sum(Census_summary_County_17[ianimal,:]))\n",
    "    print('Corrected Sum',np.sum(State_total_animals_17[ianimal,:]))\n",
    "    print('State Sum',np.sum(Census_summary_State_17[ianimal,:]))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.3.4. Calculate State and County-Level Animal Counts Across Entire Timeseries (e.g., 2012-2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the previous first and latest available state-level census animal counts data, find the\n",
    "# change in the number of animals in each state for each animal type between the first\n",
    "# and last avaible census years (e.g., 2012 and 2017). Then use this relationship to \n",
    "# calculate the animal counts at the state-level across all inventory years (e.g., 2012-2018)\n",
    "\n",
    "animal_state_trend = (State_total_animals_17-State_total_animals_12)/5\n",
    "\n",
    "state_animal_counts = np.zeros([len(proxy_animal_array),len(State_ANSI),num_years])\n",
    "#Use slope (e.g., animal number / year) and year to calculate the animal counts for each year in the inventory\n",
    "for iyear in np.arange(0,num_years):\n",
    "    for ianimal in np.arange(0,len(proxy_animal_array)):\n",
    "        state_animal_counts[ianimal,:,iyear] = animal_state_trend[ianimal,:]*iyear + State_total_animals_12[ianimal,:]\n",
    "\n",
    "#Make any negative animal counts zero\n",
    "state_animal_counts[state_animal_counts < 0] = 0\n",
    "\n",
    "animal_county_trend = (County_livestock_17-County_livestock_12)/5\n",
    "\n",
    "#Use slope (e.g., animal number / year) and year to calculate the animal counts for each year in the inventory\n",
    "county_animal_counts = np.zeros([len(proxy_animal_array),len(State_ANSI),len(County_ANSI),num_years])\n",
    "for iyear in np.arange(0,num_years):\n",
    "    for ianimal in np.arange(0,len(proxy_animal_array)):\n",
    "        county_animal_counts[ianimal,:,:,iyear] = animal_county_trend[ianimal,:,:]*iyear+County_livestock_12[ianimal,:,:]\n",
    "county_animal_counts[county_animal_counts < 0] = 0\n",
    "        \n",
    "# Print time\n",
    "ct = datetime.datetime.now() \n",
    "print(\"current time:\", ct) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.4 Read in and Format Grid-level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in and format the gridded maps of land use data, also covert from rank into a probability\n",
    "# These data are held constant over all years\n",
    "\n",
    "#Generate a vector with the 9 animal types used to grid county-level emissions:\n",
    "#Census data to LUC data mapping:\n",
    "#Uniform --> animal\n",
    "#Broilers + Turkeys --> brltrk\n",
    "#On Feed --> ctlfed\n",
    "#Beef + Bison +Cattle --> ctlinv\n",
    "#Goats --> goat\n",
    "#Hogs --> hogpig\n",
    "#Horses --> hrspny\n",
    "#Chickens + Layers + Pullets + Roosters --> lyrplt\n",
    "#Dairy --> mlkcow\n",
    "#Sheep --> shplmb\n",
    "luc_animal_array = np.array(['animal','ctlfed','ctlinv','goat','hogpig','hrspny','mlkcow','shplmb'])\n",
    "\n",
    "map_luc_rank = np.zeros([len(luc_animal_array),len(lat001),len(lon001)])\n",
    "\n",
    "for ianimal in np.arange(len(luc_animal_array)):\n",
    "    file_temp = Dataset(USDA_LUC_inputloc+luc_animal_array[ianimal]+'_001x001.nc')\n",
    "    temp_data = np.array(file_temp.variables['rank_'+luc_animal_array[ianimal]])\n",
    "    map_luc_rank[ianimal,:,:] = np.flipud(temp_data)\n",
    "    map_luc_rank[ianimal,:,:] = map_luc_rank[ianimal,:,:].astype(float)\n",
    "    file_temp.close()\n",
    "    \n",
    "map_luc_rank[map_luc_rank >  6.5]=   0.0\n",
    "map_luc_rank[map_luc_rank == 1]  =   0.0001\n",
    "map_luc_rank[map_luc_rank == 2]  =   0.0200\n",
    "map_luc_rank[map_luc_rank == 3]  =   0.0500\n",
    "map_luc_rank[map_luc_rank == 4]  =   0.1000\n",
    "map_luc_rank[map_luc_rank == 5]  =   0.3300\n",
    "map_luc_rank[map_luc_rank == 6]  =   0.4999\n",
    "   \n",
    "\n",
    "\n",
    "#Calculate the total product of the land area and animal rankings (probability * area) for each county and state\n",
    "map_cm_rank_temp = np.zeros([len(luc_animal_array),len(lat001),len(lon001)])\n",
    "for ianimal in np.arange(0, len(luc_animal_array)):\n",
    "    map_cm_rank_temp[ianimal,:,:] = map_luc_rank[ianimal,:,:]*area_map[:,:]\n",
    "    \n",
    "#create re-order and create proxy with correct number of animal types (ctlinv applied to beef, cattle, bison)\n",
    "#assign the census data to the correct animal type order (proxy animal order)\n",
    "#data are the same for each year\n",
    "map_cm_rank = np.zeros([len(proxy_animal_array),len(lat001),len(lon001)])\n",
    "\n",
    "#for iyear in np.arange(0, num_years):\n",
    "for ianimal in np.arange(0,len(proxy_animal_array)):\n",
    "    if proxy_animal_array[ianimal] == 'Mules':\n",
    "        map_cm_rank[ianimal,:,:] = map_cm_rank_temp[np.where(luc_animal_array=='animal')[0][0],:,:]\n",
    "    elif proxy_animal_array[ianimal] == 'Beef':\n",
    "        map_cm_rank[ianimal,:,:] = map_cm_rank_temp[np.where(luc_animal_array=='ctlinv')[0][0],:,:]\n",
    "    elif proxy_animal_array[ianimal] == 'Cattle':\n",
    "        map_cm_rank[ianimal,:,:] = map_cm_rank_temp[np.where(luc_animal_array=='ctlinv')[0][0],:,:]\n",
    "    elif proxy_animal_array[ianimal] == 'Bison':\n",
    "        map_cm_rank[ianimal,:,:] = map_cm_rank_temp[np.where(luc_animal_array=='ctlinv')[0][0],:,:]\n",
    "    elif proxy_animal_array[ianimal] == 'Dairy':\n",
    "        map_cm_rank[ianimal,:,:] = map_cm_rank_temp[np.where(luc_animal_array=='mlkcow')[0][0],:,:]\n",
    "    elif proxy_animal_array[ianimal] == 'OnFeed':\n",
    "        map_cm_rank[ianimal,:,:] = map_cm_rank_temp[np.where(luc_animal_array=='ctlfed')[0][0],:,:]\n",
    "    elif proxy_animal_array[ianimal] == 'Goats':\n",
    "        map_cm_rank[ianimal,:,:] = map_cm_rank_temp[np.where(luc_animal_array=='goat')[0][0],:,:]\n",
    "    elif proxy_animal_array[ianimal] == 'Horses':\n",
    "        map_cm_rank[ianimal,:,:] = map_cm_rank_temp[np.where(luc_animal_array=='hrspny')[0][0],:,:]\n",
    "    elif proxy_animal_array[ianimal] == 'Sheep':\n",
    "        map_cm_rank[ianimal,:,:] = map_cm_rank_temp[np.where(luc_animal_array=='shplmb')[0][0],:,:]\n",
    "    elif proxy_animal_array[ianimal] == 'Swine':\n",
    "        map_cm_rank[ianimal,:,:] = map_cm_rank_temp[np.where(luc_animal_array=='hogpig')[0][0],:,:]\n",
    "    \n",
    "del map_luc_rank, temp_data, map_cm_rank_temp\n",
    "\n",
    "display(np.shape(map_cm_rank))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------\n",
    "## Step 3. Read in and Format US EPA GHGI Data\n",
    "-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in total EPA emissions from public report table 5.2 (in kt)\n",
    "EPA_emi_agr_CH4 = pd.read_csv(EPA_AGR_inputfile, thousands=',', header=2,nrows = 10)\n",
    "EPA_emi_agr_CH4 = EPA_emi_agr_CH4.drop(['Unnamed: 0'], axis=1)\n",
    "EPA_emi_agr_CH4.rename(columns={EPA_emi_agr_CH4.columns[0]:'Source'}, inplace=True)\n",
    "EPA_emi_agr_CH4 = EPA_emi_agr_CH4.drop(columns = [str(n) for n in range(1990, start_year,1)])\n",
    "EPA_emi_ent_CH4 = EPA_emi_agr_CH4.loc[EPA_emi_agr_CH4['Source']==\"Enteric Fermentation\"]\n",
    "EPA_emi_man_CH4 = EPA_emi_agr_CH4.loc[EPA_emi_agr_CH4['Source']==\"Manure Management\"]\n",
    "EPA_emi_ent_CH4.reset_index(inplace=True, drop=True)\n",
    "EPA_emi_man_CH4.reset_index(inplace=True, drop=True)\n",
    "print('EPA GHGI National Enteric CH4 Emissions (kt):')\n",
    "display(EPA_emi_ent_CH4)\n",
    "print('EPA GHGI National Manure CH4 Emissions (kt):')\n",
    "display(EPA_emi_man_CH4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Split Emissions into Gridding Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split GHG emissions into gridding groups, based on Coal Proxy Mapping file\n",
    "\n",
    "DEBUG =1\n",
    "start_year_idx = EPA_emi_ent_CH4.columns.get_loc(str(start_year))\n",
    "end_year_idx = EPA_emi_ent_CH4.columns.get_loc(str(end_year))+1\n",
    "ghgi_livestock_groups = ghgi_livestock_map['GHGI_Emi_Group'].unique()\n",
    "sum_emi = np.zeros([num_years])\n",
    "\n",
    "for igroup in np.arange(0,len(EPA_emi_ent_CH4)): #loop through all groups, finding the GHGI sources in that group and summing emissions for that region, year        vars()[ghgi_prod_groups[igroup]] = np.zeros([num_regions-1,num_years])\n",
    "    ##DEBUG## print(ghgi_stat_groups[igroup])\n",
    "    vars()[ghgi_livestock_groups[igroup]] = np.zeros([num_years])\n",
    "    source_temp = ghgi_livestock_map.loc[ghgi_livestock_map['GHGI_Emi_Group'] == ghgi_livestock_groups[igroup], 'GHGI_Source']\n",
    "    pattern_temp  = '|'.join(source_temp) \n",
    "    #print(pattern_temp) \n",
    "    emi_temp =EPA_emi_ent_CH4[EPA_emi_ent_CH4['Source'].str.contains(pattern_temp)]\n",
    "    #display(emi_temp)\n",
    "    vars()[ghgi_livestock_groups[igroup]][:] = emi_temp.iloc[:,start_year_idx:].sum()\n",
    "        \n",
    "        \n",
    "#Check against total summary emissions \n",
    "print('QA/QC #1: Check Processing Emission Sum against GHGI Summary Emissions')\n",
    "for iyear in np.arange(0,num_years): \n",
    "    for igroup in np.arange(0,len(EPA_emi_ent_CH4)):\n",
    "        if iyear ==0:\n",
    "            vars()[ghgi_livestock_groups[igroup]][iyear] -= 0.5  ##NOTE: correct rounding error so sum of emissions = reported total emissions\n",
    "        sum_emi[iyear] += vars()[ghgi_livestock_groups[igroup]][iyear]\n",
    "        \n",
    "    summary_emi = EPA_emi_ent_CH4.iloc[0,iyear+1]  \n",
    "    #Check 1 - make sure that the sums from all the regions equal the totals reported\n",
    "    diff1 = abs(sum_emi[iyear] - summary_emi)/((sum_emi[iyear] + summary_emi)/2)\n",
    "    if DEBUG==1:\n",
    "        print(summary_emi)\n",
    "        print(sum_emi[iyear])\n",
    "    if diff1 < 0.0001:\n",
    "        print('Year ', year_range[iyear],': PASS, difference < 0.01%')\n",
    "    else:\n",
    "        print('Year ', year_range[iyear],': FAIL (check Production & summary tabs): ', diff1,'%') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "## Step 4. Grid Data\n",
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4.1. Allocate emissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 4.1.1 Assign the Appropriate Proxy Variable Names (state & grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The names on the *left* need to match the 'Stationary_ProxyMapping' 'State_Proxy_Group' names \n",
    "# (these are initialized in Step 2). \n",
    "# The names on the *right* are the variable names used to caluclate the proxies in this code.\n",
    "# Names on the right need to match those from the code in Step 2\n",
    "\n",
    "#national --> state proxies (animal x state x year [X month])\n",
    "State_ent_emi_animal = emi_state_ent_animal\n",
    "\n",
    "#state --> county proxies (animal x state x county x year [x month])?\n",
    "County_animal_counts = county_animal_counts\n",
    "\n",
    "#county --> grid proxies (animal x0.01x0.01)\n",
    "Map_animal_area_rank = map_cm_rank\n",
    "Map_animal_area_rank_nongrid = 0 #rank does not include non-CONUS\n",
    "\n",
    "# remove variables to clear space for larger arrays \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 4.1.2 Allocate National EPA Emissions to the State-Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate state-level emissions \n",
    "# Emissions in kt\n",
    "# State data = national GHGI emissions * state proxy/national total\n",
    "\n",
    "DEBUG = 1\n",
    "\n",
    "# Note that national emissions are retained for groups that do not have state proxies (identified in the mapping file)\n",
    "# and are gridded in the next step\n",
    "\n",
    "# Make placeholder emission arrays for each group\n",
    "for igroup in np.arange(0,len(proxy_livestock_map)):\n",
    "    vars()['State_'+proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']] = np.zeros([len(proxy_animal_array),len(State_ANSI),num_years])\n",
    "    vars()['NonState_'+proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']] = np.zeros([len(proxy_animal_array),num_years])\n",
    "        \n",
    "#Loop over years\n",
    "for iyear in np.arange(num_years):\n",
    "    #Loop over states\n",
    "    for istate in np.arange(len(State_ANSI)):\n",
    "        for igroup in np.arange(0,len(proxy_livestock_map)):    \n",
    "            if proxy_livestock_map.loc[igroup,'State_Proxy_Group'] != '-' and proxy_livestock_map.loc[igroup,'GHGI_Emi_Group'] != 'Emi_not_mapped':\n",
    "                for ianimal in np.arange(0,len(proxy_animal_array)):\n",
    "                    vars()['State_'+proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']][ianimal,istate,iyear] = \\\n",
    "                        vars()[proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']][iyear]* \\\n",
    "                        data_fn.safe_div(vars()[proxy_livestock_map.loc[igroup,'State_Proxy_Group']][ianimal,istate,iyear], \\\n",
    "                                     np.sum(vars()[proxy_livestock_map.loc[igroup,'State_Proxy_Group']][:,:,iyear]))   \n",
    "            else:\n",
    "                vars()['NonState_'+proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']][iyear] = vars()[proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']][iyear]\n",
    "                \n",
    "# Check sum of all gridded emissions + emissions not included in state allocation\n",
    "print('QA/QC #1: Check weighted emissions against GHGI')   \n",
    "for iyear in np.arange(0,num_years):\n",
    "    summary_emi = EPA_emi_ent_CH4.iloc[0,iyear+1] \n",
    "    calc_emi = 0\n",
    "    for igroup in np.arange(0,len(proxy_livestock_map)):\n",
    "        calc_emi +=  np.sum(vars()['State_'+proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']][:,:,iyear])+\\\n",
    "            np.sum(vars()['NonState_'+proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']][:,iyear]) #np.sum(Emissions[:,iyear]) + Emissions_nongrid[iyear] + Emissions_nonstate[iyear]\n",
    "    if DEBUG ==1:\n",
    "        print(summary_emi)\n",
    "        print(calc_emi)\n",
    "    diff = abs(summary_emi-calc_emi)/((summary_emi+calc_emi)/2)\n",
    "    if diff < 0.0001:\n",
    "        print('Year ', year_range[iyear], ': PASS, difference < 0.01%')\n",
    "    else:\n",
    "        print('Year ', year_range[iyear], ': FAIL -- Difference = ', diff*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.3 Allocate emissions to the county level (need to make sure Mules are allocated to area - no census data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate county-level emissions (kt)\n",
    "# Emissions in kt\n",
    "# County data (by animal) = state emissions (by animal) * county proxy (by animal)/state total (by animal)\n",
    "\n",
    "# If there are emissions in a state but no proxy data available in the entire state, \n",
    "# emissions are allocated within that state by relative county areas (this will be true for mules)\n",
    "\n",
    "# If there are \n",
    "DEBUG = 1\n",
    "\n",
    "# Note that national emissions are retained for groups that do not have state proxies (identified in the mapping file)\n",
    "# and are gridded in the next step\n",
    "\n",
    "# Make placeholder emission arrays for each group\n",
    "for igroup in np.arange(0,len(proxy_livestock_map)):\n",
    "    vars()['County_'+proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']] = \\\n",
    "            np.zeros([len(proxy_animal_array),len(State_ANSI),len(County_ANSI),num_years])\n",
    "    vars()['NonCounty_'+proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']] = np.zeros([len(proxy_animal_array),num_years])\n",
    "        \n",
    "#Loop over years\n",
    "for iyear in np.arange(0,num_years):\n",
    "    for icounty in np.arange(0,len(County_ANSI)):\n",
    "        istate = np.where(State_ANSI['ansi']==County_ANSI['State'][icounty])[0][0]\n",
    "        state_ansi = State_ANSI['ansi'][istate]\n",
    "        #print(icounty, istate)\n",
    "        for igroup in np.arange(0,len(proxy_livestock_map)): \n",
    "            for ianimal in np.arange(0,len(proxy_animal_array)):\n",
    "                emi_temp = vars()['State_'+proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']][ianimal,istate,iyear]\n",
    "                frac_temp = data_fn.safe_div(vars()[proxy_livestock_map.loc[igroup,'County_Proxy_Group']][ianimal,istate,icounty,iyear], \\\n",
    "                            np.sum(vars()[proxy_livestock_map.loc[igroup,'County_Proxy_Group']][ianimal,istate,:,iyear]))\n",
    "                if emi_temp > 0 and frac_temp > 0:\n",
    "                    vars()['County_'+proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']][ianimal,istate,icounty,iyear] = emi_temp * frac_temp\n",
    "                elif emi_temp > 0 and np.sum(vars()[proxy_livestock_map.loc[igroup,'County_Proxy_Group']][ianimal,istate,:,iyear]) == 0:                \n",
    "                    #if state emissions >0 and no proxy data in that state, allocate based on relative county areas\n",
    "                    frac_temp = data_fn.safe_div(County_ANSI.loc[icounty,'Area'],np.sum(County_ANSI['Area'][County_ANSI['State'] == state_ansi]))\n",
    "                    vars()['County_'+proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']][ianimal,istate,icounty,iyear] = emi_temp * frac_temp  \n",
    "                else: \n",
    "                    # if there are no state emissions OR if there are state emissions, \n",
    "                    # there is proxy data in the state, but no proxy data in that county, skip that county and move to next\n",
    "                    continue\n",
    "\n",
    "# Check sum of all gridded emissions + emissions not included in state allocation\n",
    "print('QA/QC #2: Check weighted emissions against GHGI')   \n",
    "for iyear in np.arange(0,num_years):\n",
    "    summary_emi = EPA_emi_ent_CH4.iloc[0,iyear+1] \n",
    "    calc_emi = 0\n",
    "    for igroup in np.arange(0,len(proxy_livestock_map)):\n",
    "        calc_emi +=  np.sum(vars()['County_'+proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']][:,:,:,iyear])+\\\n",
    "            np.sum(vars()['NonCounty_'+proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']][:,iyear])\n",
    "    if DEBUG ==1:\n",
    "        print(summary_emi)\n",
    "        print(calc_emi)\n",
    "    diff = abs(summary_emi-calc_emi)/((summary_emi+calc_emi)/2)\n",
    "    if diff < 0.0001:\n",
    "        print('Year ', year_range[iyear], ': PASS, difference < 0.01%')\n",
    "    else:\n",
    "        print('Year ', year_range[iyear], ': FAIL -- Difference = ', diff*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.4 Allocate emissions to the CONUS region (0.1x0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To speed up the code, this notebook does not loop through each county, but instead loops through\n",
    "# each lat/lon value in the CONUS region. Emissions are allocated based on the fraction of \n",
    "# the proxy that is in each grid cell relative to the total in that county. \n",
    "# Since the code is not using county masks, the sum of each proxy for each county/state pair\n",
    "# must first be calcualted. \n",
    "# This chunk calculates the county totals for each animal for the area-weighted probability\n",
    "# map and the county area map. \n",
    "\n",
    "\n",
    "Map_animal_area_rank_sum = np.zeros([len(proxy_animal_array),len(State_ANSI),len(County_ANSI)])\n",
    "Area_sum = np.zeros([len(State_ANSI),len(County_ANSI)])\n",
    "\n",
    "#For each grid box that falls within the continental US geographic bounds, keep a running sum to calculate \n",
    "# the total cm_rank for each animal type within each state and county. \n",
    "# Also keep a running sum of the total area within each state and county.\n",
    "for ilat in np.arange(0, len(lat001)):\n",
    "    for ilon in np.arange(0, len(lon001)):\n",
    "        if state_ANSI_map[ilat,ilon] > 0: #only includes CONUS region\n",
    "            istate = np.where(State_ANSI['ansi']==state_ANSI_map[ilat,ilon])[0][0]\n",
    "            icounty = np.where((County_ANSI['State']==state_ANSI_map[ilat,ilon]) & \\\n",
    "                                    (County_ANSI['County']==county_ANSI_map[ilat,ilon]))[0][0]\n",
    "            Area_sum[istate,icounty] += area_map[ilat,ilon]\n",
    "            for ianimal in np.arange(0, len(proxy_animal_array)):                                          \n",
    "                Map_animal_area_rank_sum[ianimal,istate,icounty] += Map_animal_area_rank[ianimal,ilat,ilon]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#will need to save yearly emissions as intermediate output and read back in due to memory limits\n",
    "data_IO_fn.initialize_netCDF001(enteric_int_out, netCDF_description, 0, year_range, loc_dimensions, lat001, lon001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Enteric Gridding\n",
    "# Loop through each lat/lon value on the CONUS grid. County emissions are allocated based on the\n",
    "# fraction of proxy data in each grid cell relative to the sum of all proxy data in the gridcells\n",
    "# within the relevant county. \n",
    "# If the county does not have animal probability data, then the county emissions are allocated by area\n",
    "# Because this code takes a long time to run, the data are saved to a netCDF file after each calculated year\n",
    "# Current computational speed is ~ 2.5-3 hours computation time per year of emissions processing\n",
    "\n",
    "Emissions_array_01 = np.zeros([len(Lat_01),len(Lon_01),num_years])\n",
    "Emissions_array_001 = np.zeros([len(lat001),len(lon001),num_years])\n",
    "Emissions_nongrid = np.zeros([num_years])\n",
    "\n",
    "print('**QA/QC Check: Sum of national gridded emissions vs. GHGI national emissions')\n",
    "running_sum = np.zeros([len(proxy_livestock_map),num_years])\n",
    "running_sum2 = np.zeros([len(proxy_livestock_map),num_years])\n",
    "\n",
    "#for iyear in np.arange(0,num_years):\n",
    "for igroup in np.arange(0,len(proxy_livestock_map)):\n",
    "    #define the proxy and area arrays (there is only one gridding group)\n",
    "    # this code needs to be manually changed if more gridding groups are added in the future\n",
    "    proxy_temp = Map_animal_area_rank\n",
    "    proxy_temp_nongrid = Map_animal_area_rank_nongrid\n",
    "    proxy_temp_sum = Map_animal_area_rank_sum\n",
    "    area_map_sum = Area_sum\n",
    "    vars()['Ext_'+proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']+'_01'] = np.zeros([len(lat001),len(lon001),num_years])\n",
    "            \n",
    "    for ilat in np.arange(0,len(lat001)):\n",
    "        for ilon in np.arange(0,len(lon001)):\n",
    "            if state_ANSI_map[ilat,ilon] > 0:\n",
    "                istate = np.where(State_ANSI['ansi']==state_ANSI_map[ilat,ilon])[0][0]\n",
    "                icounty = np.where((County_ANSI['State']==state_ANSI_map[ilat,ilon]) & \\\n",
    "                                    (County_ANSI['County']==county_ANSI_map[ilat,ilon]))[0][0]\n",
    "\n",
    "                for ianimal in np.arange(0,len(proxy_animal_array)):\n",
    "                    county_temp = vars()['County_'+proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']][ianimal,istate,icounty,:]\n",
    "                    if np.sum(county_temp) > 0:\n",
    "                        if proxy_temp_sum[ianimal,istate,icounty] >0: # if there is animal count data in the county, allocate by animal counts in grid cell relative to county sum\n",
    "                            weighted_array = data_fn.safe_div(proxy_temp[ianimal,ilat,ilon],\\\n",
    "                                                      proxy_temp_sum[ianimal,istate,icounty]) #counts at grid cell/counts in county\n",
    "                            for iyear in np.arange(0, num_years):\n",
    "                                Emissions_array_001[ilat,ilon,iyear] += county_temp[iyear]*weighted_array\n",
    "                                running_sum[igroup,iyear] += weighted_array*county_temp[iyear]\n",
    "                                vars()['Ext_'+proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']+'_01'][ilat,ilon,iyear] += county_temp[iyear]*weighted_array\n",
    "                        elif proxy_temp_sum[ianimal,istate,icounty] == 0: # if no animal county data in county, use relative area as proxy\n",
    "                            #weight by county area\n",
    "                            weighted_array = data_fn.safe_div(area_map[ilat,ilon],\\\n",
    "                                                          area_map_sum[istate,icounty]) #counts at grid cell/counts in county\n",
    "                            for iyear in np.arange(0, num_years):\n",
    "                                Emissions_array_001[ilat,ilon,iyear] += county_temp[iyear]*weighted_array\n",
    "                                running_sum2[igroup,iyear] += weighted_array*county_temp[iyear]\n",
    "                                vars()['Ext_'+proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']+'_01'][ilat,ilon,iyear] += county_temp[iyear]*weighted_array\n",
    "\n",
    "        print(ilat,running_sum[igroup,0])\n",
    "        print(ilat,running_sum2[igroup,0])\n",
    "    \n",
    "#non-CONUS regions already filtered from the state_ANSI_map. Therefore, non-grid emissions\n",
    "# have to be calcuated as the differences between national and CONUS emissions (not ideal as \n",
    "# this is not an independent calcualtion of non-grid emissions)\n",
    "for iyear in np.arange(0, num_years):\n",
    "    county_sum = 0\n",
    "    for igroup in np.arange(0,len(proxy_livestock_map)):\n",
    "        county_sum += np.sum(vars()['County_'+proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']][:,:,:,iyear])\n",
    "    Emissions_nongrid[iyear] = county_sum -np.sum(Emissions_array_001[:,:,iyear])\n",
    "    print(Emissions_nongrid[0])\n",
    "    \n",
    "for igroup in np.arange(0, len(proxy_livestock_map)):\n",
    "    vars()['Ext_'+proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']] = np.zeros([len(Lat_01),len(Lon_01),num_years])\n",
    "    \n",
    "for iyear in np.arange(0, num_years):  \n",
    "    Emissions_array_01[:,:,iyear] = data_fn.regrid001_to_01(Emissions_array_001[:,:,iyear], Lat_01, Lon_01)\n",
    "    \n",
    "    calc_emi = np.sum(Emissions_array_01[:,:,iyear]) + np.sum(Emissions_nongrid[iyear]) \n",
    "    calc_emi2 = 0\n",
    "    for igroup in np.arange(0, len(proxy_livestock_map)):\n",
    "        vars()['Ext_'+proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']][:,:,iyear] = data_fn.regrid001_to_01(vars()['Ext_'+proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']+'_01'][:,:,iyear], Lat_01, Lon_01)\n",
    "        calc_emi2 += np.sum(vars()['Ext_'+proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']][:,:,iyear])\n",
    "    calc_emi2 += np.sum(Emissions_nongrid[iyear]) \n",
    "    summary_emi = EPA_emi_ent_CH4.iloc[0,iyear+1] \n",
    "    emi_diff = abs(summary_emi-calc_emi)/((summary_emi+calc_emi)/2)\n",
    "    if DEBUG ==1:\n",
    "        print(summary_emi)\n",
    "        print(calc_emi)\n",
    "        print(calc_emi2)\n",
    "    diff = abs(summary_emi-calc_emi)/((summary_emi+calc_emi)/2)\n",
    "    if diff < 0.0001:\n",
    "        print('Year ', year_range[iyear], ': PASS, difference < 0.01%')\n",
    "    else:\n",
    "        print('Year ', year_range[iyear], ': FAIL -- Difference = ', diff*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4.1.4 Save gridded emissions (kt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save gridded emissions for each gridding group - for extension\n",
    "\n",
    "#Initialize file\n",
    "data_IO_fn.initialize_netCDF(grid_emi_outputfile, netCDF_description, 0, year_range, loc_dimensions, Lat_01, Lon_01)\n",
    "\n",
    "unique_groups = np.unique(proxy_livestock_map['GHGI_Emi_Group'])\n",
    "unique_groups = unique_groups[unique_groups != 'Emi_not_mapped']\n",
    "\n",
    "nc_out = Dataset(grid_emi_outputfile, 'r+', format='NETCDF4')\n",
    "\n",
    "for igroup in np.arange(0,len(unique_groups)):\n",
    "    print('Ext_'+unique_groups[igroup])\n",
    "    if len(np.shape(vars()['Ext_'+unique_groups[igroup]])) ==4:\n",
    "        ghgi_temp = np.sum(vars()[unique_groups[igroup]],axis=3) #sum month data if data is monthly\n",
    "    else:\n",
    "        ghgi_temp = vars()['Ext_'+unique_groups[igroup]]\n",
    "\n",
    "    # Write data to netCDF\n",
    "    data_out = nc_out.createVariable('Ext_'+unique_groups[igroup], 'f8', ('lat', 'lon','year'), zlib=True)\n",
    "    data_out[:,:,:] = ghgi_temp[:,:,:]\n",
    "\n",
    "#save nongrid data to calculate non-grid fraction extension\n",
    "data_out = nc_out.createVariable('Emissions_nongrid', 'f8', ('year'), zlib=True)  \n",
    "data_out[:] = Emissions_nongrid[:]\n",
    "nc_out.close()\n",
    "\n",
    "#Confirm file location\n",
    "print('** SUCCESS **')\n",
    "print(\"Gridded emissions (kt) written to file: {}\" .format(os.getcwd())+grid_emi_outputfile)\n",
    "print(' ')\n",
    "\n",
    "del data_out, ghgi_temp, nc_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2. Calculate Gridded Emission Fluxes (molec./cm2/s) (0.1x0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert emissions to emission flux\n",
    "# conversion: kt emissions to molec/cm2/s flux\n",
    "\n",
    "DEBUG = 1\n",
    "\n",
    "\n",
    "Flux_array_01_annual = np.zeros([len(Lat_01),len(Lon_01),num_years])\n",
    "print('**QA/QC Check: Sum of national gridded emissions vs. GHGI national emissions')\n",
    "  \n",
    "for iyear in np.arange(0,num_years):\n",
    "    if year_range[iyear]==2012 or year_range[iyear]==2016:\n",
    "        year_days = np.sum(month_day_leap)\n",
    "        #month_days = month_day_leap\n",
    "    else:\n",
    "        year_days = np.sum(month_day_nonleap)\n",
    "        #month_days = month_day_nonleap\n",
    "        \n",
    "    #for imonth in np.arange(0,num_months):\n",
    "    conversion_factor_01 = 10**9 * Avogadro / float(Molarch4 *year_days * 24 * 60 *60) / area_matrix_01\n",
    "    Flux_array_01_annual[:,:,iyear] += Emissions_array_01[:,:,iyear]*conversion_factor_01\n",
    "    \n",
    "    #convert back to mass to check\n",
    "    #conversion_factor_annual = 10**9 * Avogadro / float(Molarch4 *year_days * 24 * 60 *60) / area_matrix_01\n",
    "    calc_emi = np.sum(Flux_array_01_annual[:,:,iyear]/conversion_factor_01)+np.sum(Emissions_nongrid[iyear])\n",
    "    summary_emi = EPA_emi_ent_CH4.iloc[0,iyear+1] \n",
    "    emi_diff = abs(summary_emi-calc_emi)/((summary_emi+calc_emi)/2)\n",
    "    if DEBUG ==1:\n",
    "        print(calc_emi)\n",
    "        print(summary_emi)\n",
    "    if abs(emi_diff) < 0.0001:\n",
    "        print('Year '+ year_range_str[iyear]+': Difference < 0.01%: PASS')\n",
    "    else: \n",
    "        print('Year '+ year_range_str[iyear]+': Difference > 0.01%: FAIL, diff: '+str(emi_diff))\n",
    "        \n",
    "Flux_Emissions_Total_annual = Flux_array_01_annual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "## Step 5. Write netCDF\n",
    "------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yearly data\n",
    "#Initialize file\n",
    "data_IO_fn.initialize_netCDF(gridded_outputfile, netCDF_description, 0, year_range, loc_dimensions, Lat_01, Lon_01)\n",
    "\n",
    "# Write data to netCDF\n",
    "nc_out = Dataset(gridded_outputfile, 'r+', format='NETCDF4')\n",
    "nc_out.variables['emi_ch4'][:,:,:] = Flux_Emissions_Total_annual\n",
    "nc_out.close()\n",
    "#Confirm file location\n",
    "print('** SUCCESS **')\n",
    "print(\"Gridded stationary combustion fluxes written to file: {}\" .format(os.getcwd())+gridded_outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "## Step 6. Plot Gridded Data\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6.1. Plot Annual Emission Fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plot Annual Data\n",
    "scale_max = 10\n",
    "save_flag =0\n",
    "save_outfile = ''\n",
    "data_plot_fn.plot_annual_emission_flux_map(Flux_Emissions_Total_annual, Lat_01, Lon_01, year_range, title_str,scale_max,save_flag,save_outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6.2 Plot Difference between first and last inventory year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot difference between last and first year\n",
    "save_flag =0\n",
    "save_outfile = ''\n",
    "data_plot_fn.plot_diff_emission_flux_map(Flux_Emissions_Total_annual, Lat_01, Lon_01, year_range, title_diff_str,save_flag, save_outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = datetime.datetime.now() \n",
    "ft = ct.timestamp() \n",
    "time_elapsed = (ft-it)/(60*60)\n",
    "print('Time to run: '+str(time_elapsed)+' hours')\n",
    "print('** GEPA_3A_Livestock_Enteric: COMPLETE **')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
