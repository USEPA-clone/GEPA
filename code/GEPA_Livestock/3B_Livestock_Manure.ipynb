{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridded EPA Methane Inventory\n",
    "## Category: 3B Livestock Sector - Manure Management Emissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### Authors: \n",
    "Joannes D. Maasakkers, Candice F. Z. Chen, Erin E. McDuffie\n",
    "#### Date Last Updated: \n",
    "see Step 0\n",
    "#### Notebook Purpose\n",
    "This notebook calculates gridded (0.1⁰x0.1⁰) annual emission fluxes of methane (molecules CH4/cm2/s) from manure management activities in the CONUS region for the years 2012 - 2018. Emission fluxes are reported at a monthly and annual time resolution. \n",
    "#### Summary & Notes \n",
    "The national EPA GHGI emissions data are read in from table 5-2 from the public GHGI report. First, national emissions are allocated to each state and animal type using monthly state EPA GHGI emissions from manure management from the GHGI Inventory Manure Management data (from sector lead). State-level emissions (as a function of animal type) are then allocated to the county level using USDA animal counts from the 2012 and 2017 Census. Animal counts for additional years are estimated through interpolation of census data. Resulting county-level emissions are then distributed onto a 0.1⁰x0.1⁰ grid (as a function of animal type) using a map of grid-level landcover probabilities from the USDA. Emissions as a function of animal type are then aggregated to gridded total manure management emissions. Total emissions are converted to annual and monthly emision fluxes (molec./cm2/s) and are written to final netCDFs in the '/code/Final_Gridded_Data/' folder. \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "## Step 0. Set-Up Notebook Modules, Functions, and Local Parameters and Constants\n",
    "_____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirm working directory\n",
    "import os\n",
    "import time\n",
    "modtime = os.path.getmtime('./3B_Livestock_Manure.ipynb')\n",
    "modificationTime = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(modtime))\n",
    "print(\"This file was last modified on: \", modificationTime)\n",
    "print('')\n",
    "print(\"The directory we are working in is {}\" .format(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include plots within notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import base modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import datetime\n",
    "from copy import copy\n",
    "\n",
    "# Import additional modules\n",
    "# Load plotting package Basemap \n",
    "# Must also specify project library path [unique to each user])\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "# Load netCDF (for manipulating netCDF file types)\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "# Set up ticker\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "#add path for the global function module (file)\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../Global_Functions/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# Load user-defined global functions (modules)\n",
    "import data_load_functions as data_load_fn\n",
    "import data_functions as data_fn\n",
    "import data_IO_functions as data_IO_fn\n",
    "import data_plot_functions as data_plot_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INPUT Files\n",
    "# Assign global file names\n",
    "global_filenames = data_load_fn.load_global_file_names()\n",
    "State_ANSI_inputfile = global_filenames[0]\n",
    "County_ANSI_inputfile = global_filenames[1]\n",
    "pop_map_inputfile = global_filenames[2]\n",
    "Grid_area01_inputfile = global_filenames[3]\n",
    "Grid_area001_inputfile = global_filenames[4]\n",
    "Grid_state001_ansi_inputfile = global_filenames[5]\n",
    "Grid_county001_ansi_inputfile = global_filenames[6]\n",
    "\n",
    "# Specify names of inputs files used in this notebook\n",
    "EPA_manure_inputfile = \"./InputData/Monthly_Manure_Output.csv\"\n",
    "Census_12_inputloc =  \"./InputData/USDA_Census/Census_12_\"\n",
    "Census_17_inputloc =  \"./InputData/USDA_Census/Census_17_\"\n",
    "USDA_LUC_inputloc = \"./InputData/Data_map/usda_luc_rank_\"\n",
    "EPA_AGR_inputfile = \"../Global_InputData/GHGI/Ch5_Agriculture/Table 5-2.csv\"\n",
    "\n",
    "#Proxy Data file\n",
    "Livestock_Mapping_inputfile = \"./InputData/Livestock_Manure_ProxyMapping.xlsx\"\n",
    "\n",
    "#Specify names of gridded output files\n",
    "manure_int_out = './IntermediateOutputs/Intermediate_EPA_v2_3B_Manure_Management.nc'\n",
    "\n",
    "gridded_outputfile = '../Final_Gridded_Data/EPA_v2_3B_Manure_Management.nc'\n",
    "gridded_month_outputfile = '../Final_Gridded_Data/EPA_v2_3B_Manure_Management_Monthly.nc'\n",
    "netCDF_description = 'Gridded EPA Inventory - Manure Management Emissions - IPCC Source Category 3B'\n",
    "netCDF_description_m = 'Gridded EPA Inventory - Monthly Manure Management Emissions - IPCC Source Category 3B'\n",
    "title_str = \"EPA methane emissions from manure management\"\n",
    "title_diff_str = \"Emissions from manure management difference: 2018-2012\"\n",
    "\n",
    "#output gridded proxy data\n",
    "grid_emi_outputfile = '../Final_Gridded_Data/Extension/v2_input_data/Livestock_Manure_Grid_Emi.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define local variables\n",
    "start_year = 2012  #First year in emission timeseries\n",
    "end_year = 2018    #Last year in emission timeseries\n",
    "year_range = [*range(start_year, end_year+1,1)] #List of emission years\n",
    "year_range_str=[str(i) for i in year_range]\n",
    "num_years = len(year_range)\n",
    "\n",
    "# Define constants\n",
    "Avogadro   = 6.02214129 * 10**(23)  #molecules/mol\n",
    "Molarch4   = 16.04                  #g/mol\n",
    "Res01      = 0.1                    # degrees\n",
    "\n",
    "# Continental US Lat/Lon Limits (for netCDF files)\n",
    "Lon_left = -130       #deg\n",
    "Lon_right = -60       #deg\n",
    "Lat_low  = 20         #deg\n",
    "Lat_up  = 55          #deg\n",
    "\n",
    "loc_dimensions = [Lat_low, Lat_up, Lon_left, Lon_right]\n",
    "ilat_start = int((90+Lat_low)/Res01) #1100:1450 (continental US range)\n",
    "ilat_end = int((90+Lat_up)/Res01)\n",
    "ilon_start = abs(int((-180-Lon_left)/Res01)) #500:1200 (continental US range)\n",
    "ilon_end = abs(int((-180-Lon_right)/Res01))\n",
    "\n",
    "# Number of days in each month\n",
    "month_day_leap  = [  31,  29,  31,  30,  31,  30,  31,  31,  30,  31,  30,  31]\n",
    "month_day_nonleap = [  31,  28,  31,  30,  31,  30,  31,  31,  30,  31,  30,  31]\n",
    "\n",
    "# Month arrays\n",
    "month_range_str = ['January','February','March','April','May','June','July','August','September','October','November','December']\n",
    "num_months = len(month_range_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.auto_scroll_threshold = 9999;\n",
    "//prevent auto-scrolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track run time\n",
    "ct = datetime.datetime.now() \n",
    "it = ct.timestamp() \n",
    "print(\"current time:\", ct) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "## Step 1. Load in State and County ANSI data and Area Maps\n",
    "_____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State-level ANSI Data\n",
    "#Read the state ANSI file array\n",
    "State_ANSI, name_dict, abbr_dict = data_load_fn.load_state_ansi(State_ANSI_inputfile)[0:3]\n",
    "#QA: number of states\n",
    "print('Read input file: '+ f\"{State_ANSI_inputfile}\")\n",
    "print('Total \"States\" found: ' + '%.0f' % len(State_ANSI))\n",
    "print(' ')\n",
    "\n",
    "# 0.01 x0.01 degree Data\n",
    "# State ANSI IDs and grid cell area (m2) maps\n",
    "state_ANSI_map = data_load_fn.load_state_ansi_map(Grid_state001_ansi_inputfile)\n",
    "area_map, lat001, lon001 = data_load_fn.load_area_map_001(Grid_area001_inputfile)\n",
    "\n",
    "\n",
    "#County ANSI Data\n",
    "#Includes State ANSI number, county ANSI number, county name, and country area (square miles)\n",
    "County_ANSI = pd.read_csv(County_ANSI_inputfile,encoding='latin-1')\n",
    "\n",
    "#QA: number of counties\n",
    "print ('Read input file: ' + f\"{County_ANSI_inputfile}\")\n",
    "print('Total \"Counties\" found (include PR): ' + '%.0f' % len(County_ANSI))\n",
    "print(' ')\n",
    "\n",
    "#Create a placeholder array for county data\n",
    "county_array = np.zeros([len(County_ANSI),3])\n",
    "\n",
    "#Populate array with State ANSI number (0), county ANSI number (1), and county area (2)\n",
    "for icounty in np.arange(0,len(County_ANSI)):\n",
    "    county_array[icounty,0] = int(County_ANSI.values[icounty,0])\n",
    "    county_array[icounty,1] = int(County_ANSI.values[icounty,1])\n",
    "    county_array[icounty,2] = County_ANSI.values[icounty,3]\n",
    "\n",
    "# 0.01 x0.01 degree Data\n",
    "# State ANSI IDs and grid cell area (m2) maps\n",
    "state_ANSI_map = data_load_fn.load_state_ansi_map(Grid_state001_ansi_inputfile)\n",
    "state_ANSI_map = state_ANSI_map.astype('int32')\n",
    "county_ANSI_map = data_load_fn.load_county_ansi_map(Grid_county001_ansi_inputfile)\n",
    "county_ANSI_map = county_ANSI_map.astype('int32')\n",
    "area_map, lat001, lon001 = data_load_fn.load_area_map_001(Grid_area001_inputfile)\n",
    "\n",
    "# 0.1 x0.1 degree data\n",
    "# grid cell area and state and county ANSI maps\n",
    "area_map01, Lat01, Lon01 = data_load_fn.load_area_map_01(Grid_area01_inputfile)[0:3]\n",
    "#Select relevant Continental 0.1 x0.1 domain\n",
    "Lat_01 = Lat01[ilat_start:ilat_end]\n",
    "Lon_01 = Lon01[ilon_start:ilon_end]\n",
    "area_matrix_01 = data_fn.regrid001_to_01(area_map, Lat_01, Lon_01)\n",
    "area_matrix_01 *= 10000  #convert from m2 to cm2\n",
    "\n",
    "state_ANSI_map_01 = data_fn.regrid001_to_01(state_ANSI_map, Lat_01, Lon_01)\n",
    "\n",
    "# Print time\n",
    "ct = datetime.datetime.now() \n",
    "print(\"current time:\", ct) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------\n",
    "## Step 2. Read in and Format Proxy Data\n",
    "--------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.1 Read In Proxy Mapping File & Make Proxy Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load GHGI Mapping Groups\n",
    "names = pd.read_excel(Livestock_Mapping_inputfile, sheet_name = \"GHGI Map - Livestock\", usecols = \"A:B\",skiprows = 1, header = 0)\n",
    "colnames = names.columns.values\n",
    "ghgi_livestock_map = pd.read_excel(Livestock_Mapping_inputfile, sheet_name = \"GHGI Map - Livestock\", usecols = \"A:B\", skiprows = 1, names = colnames)\n",
    "#drop rows with no data, remove the parentheses and \"\"\n",
    "ghgi_livestock_map = ghgi_livestock_map[ghgi_livestock_map['GHGI_Emi_Group'] != 'na']\n",
    "ghgi_livestock_map = ghgi_livestock_map[ghgi_livestock_map['GHGI_Emi_Group'].notna()]\n",
    "ghgi_livestock_map['GHGI_Source']= ghgi_livestock_map['GHGI_Source'].str.replace(r\"\\(\",\"\")\n",
    "ghgi_livestock_map['GHGI_Source']= ghgi_livestock_map['GHGI_Source'].str.replace(r\"\\)\",\"\")\n",
    "ghgi_livestock_map.reset_index(inplace=True, drop=True)\n",
    "display(ghgi_livestock_map)\n",
    "\n",
    "#load emission group - proxy map\n",
    "names = pd.read_excel(Livestock_Mapping_inputfile, sheet_name = \"Proxy Map - Livestock\", usecols = \"A:G\",skiprows = 1, header = 0)\n",
    "colnames = names.columns.values\n",
    "proxy_livestock_map = pd.read_excel(Livestock_Mapping_inputfile, sheet_name = \"Proxy Map - Livestock\", usecols = \"A:G\", skiprows = 1, names = colnames)\n",
    "display((proxy_livestock_map))\n",
    "\n",
    "#create empty proxy and emission group arrays (add months for proxy variables that have monthly data)\n",
    "for igroup in np.arange(0,len(proxy_livestock_map)):\n",
    "    if proxy_livestock_map.loc[igroup, 'Grid_Month_Flag'] ==0:\n",
    "        vars()[proxy_livestock_map.loc[igroup,'Proxy_Group']] = np.zeros([len(Lat_01),len(Lon_01),num_years])\n",
    "        vars()[proxy_livestock_map.loc[igroup,'Proxy_Group']+'_nongrid'] = np.zeros([num_years])\n",
    "    else:\n",
    "        vars()[proxy_livestock_map.loc[igroup,'Proxy_Group']] = np.zeros([len(Lat_01),len(Lon_01),num_years,num_months])\n",
    "        vars()[proxy_livestock_map.loc[igroup,'Proxy_Group']+'_nongrid'] = np.zeros([num_years,num_months])\n",
    "        \n",
    "    vars()[proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']] = np.zeros([num_years])\n",
    "    \n",
    "    if proxy_livestock_map.loc[igroup,'State_Proxy_Group'] != '-':\n",
    "        if proxy_livestock_map.loc[igroup,'State_Month_Flag'] == 0:\n",
    "            vars()[proxy_livestock_map.loc[igroup,'State_Proxy_Group']] = np.zeros([len(State_ANSI),num_years])\n",
    "        else:\n",
    "            vars()[proxy_livestock_map.loc[igroup,'State_Proxy_Group']] = np.zeros([len(State_ANSI),num_years,num_months])\n",
    "    else:\n",
    "        continue # do not make state proxy variable if no variable assigned in mapping file\n",
    "        \n",
    "    if proxy_livestock_map.loc[igroup,'County_Proxy_Group'] != '-':\n",
    "        if proxy_livestock_map.loc[igroup,'County_Month_Flag'] == 0:\n",
    "            vars()[proxy_livestock_map.loc[igroup,'County_Proxy_Group']] = np.zeros([len(State_ANSI),len(County_ANSI),num_years])\n",
    "        else:\n",
    "            vars()[proxy_livestock_map.loc[igroup,'County_Proxy_Group']] = np.zeros([len(State_ANSI),len(County_ANSI),num_years,num_months])\n",
    "    else:\n",
    "        continue # do not make state proxy variable if no variable assigned in mapping file\n",
    "\n",
    "        \n",
    "emi_group_names = np.unique(ghgi_livestock_map['GHGI_Emi_Group'])\n",
    "\n",
    "print('QA/QC: Is the number of emission groups the same for the proxy and emissions tabs?')\n",
    "if (len(emi_group_names) == len(np.unique(proxy_livestock_map['GHGI_Emi_Group']))):\n",
    "    print('PASS')\n",
    "else:\n",
    "    print('FAIL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.2 Read in the GHGI State Emissions Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2.2.1 Read in 2012-2017 state emissions for beef, cattle, diary, and onfeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Read in and format EPA monthly manure methane emissions (Tg/yr) by state and animal type\n",
    "# This inlcude all data from 2012-2017 (state levels by animal types were not re-calculated\n",
    "# for the year 2018 in the GHGI)\n",
    "\n",
    "# Array dimensions:\n",
    "# 13 animal types x state x year x month\n",
    "emi_state_man_animal = np.zeros([13,len(State_ANSI),num_years,12])\n",
    "\n",
    "#Note: no county data for mules (set to 'uniform')\n",
    "\n",
    "# Read in monthly emissions\n",
    "EPA_Man = pd.read_csv(EPA_manure_inputfile,header=1)\n",
    "# Rename table columns\n",
    "EPA_Man.rename( columns={'Unnamed: 0':'animal'}, inplace=True )\n",
    "EPA_Man.rename( columns={'Unnamed: 1':'state'}, inplace=True )\n",
    "EPA_Man.rename( columns={'Unnamed: 2':'wms_system'}, inplace=True )\n",
    "EPA_Man.rename( columns={'Unnamed: 3':'Month'}, inplace=True )\n",
    "\n",
    "# Manure Order\n",
    "#beef, bison, diary, goats, horses, mules (uniform), broilers, chickens, layers, pullets, turkeys, sheep, swine \n",
    "\n",
    "#Fill in the final arrays with the manure emissions for each corresponding animal type.\n",
    "# Make sure to fill data based on the order of states in the State_emi_ent_ansi array\n",
    "\n",
    "for irow in np.arange(0,len(EPA_Man)):\n",
    "    match_state = np.where(EPA_Man['state'][irow].rstrip() == State_ANSI['abbr'])[0][0]\n",
    "    imonth = month_range_str.index(EPA_Man.Month[irow])\n",
    "    for iyear in np.arange(0,num_years):\n",
    "        if re.search('beef',EPA_Man.animal[irow].lower()) != None:\n",
    "            emi_state_man_animal[0,match_state,iyear,imonth] += EPA_Man[year_range_str[iyear]][irow]*1e3 # Tg -> kt\n",
    "        elif re.search('bison',EPA_Man.animal[irow].lower()) != None:\n",
    "            emi_state_man_animal[1,match_state,iyear,imonth] += EPA_Man[year_range_str[iyear]][irow]*1e3 # Tg -> kt\n",
    "        elif re.search('dairy',EPA_Man.animal[irow].lower()) != None:\n",
    "            emi_state_man_animal[2,match_state,iyear,imonth] += EPA_Man[year_range_str[iyear]][irow]*1e3 # Tg -> kt\n",
    "        elif re.search('goats',EPA_Man.animal[irow].lower()) != None:\n",
    "             emi_state_man_animal[3,match_state,iyear,imonth] += EPA_Man[year_range_str[iyear]][irow]*1e3 # Tg -> kt\n",
    "        elif re.search('horses',EPA_Man.animal[irow].lower()) != None:\n",
    "             emi_state_man_animal[4,match_state,iyear,imonth] += EPA_Man[year_range_str[iyear]][irow]*1e3 # Tg -> kt\n",
    "        elif re.search('mules',EPA_Man.animal[irow].lower()) != None:\n",
    "             emi_state_man_animal[5,match_state,iyear,imonth] += EPA_Man[year_range_str[iyear]][irow]*1e3 # Tg -> kt\n",
    "        elif re.search('broilers',EPA_Man.animal[irow].lower()) != None:\n",
    "             emi_state_man_animal[6,match_state,iyear,imonth] += EPA_Man[year_range_str[iyear]][irow]*1e3 # Tg -> kt      \n",
    "        elif re.search('chickens',EPA_Man.animal[irow].lower()) != None:\n",
    "             emi_state_man_animal[7,match_state,iyear,imonth] += EPA_Man[year_range_str[iyear]][irow]*1e3 # Tg -> kt\n",
    "        elif re.search('layers',EPA_Man.animal[irow].lower()) != None:\n",
    "             emi_state_man_animal[8,match_state,iyear,imonth] += EPA_Man[year_range_str[iyear]][irow]*1e3 # Tg -> kt\n",
    "        elif re.search('pullets',EPA_Man.animal[irow].lower()) != None:\n",
    "             emi_state_man_animal[9,match_state,iyear,imonth] += EPA_Man[year_range_str[iyear]][irow]*1e3 # Tg -> kt\n",
    "        elif re.search('turkeys',EPA_Man.animal[irow].lower()) != None:\n",
    "             emi_state_man_animal[10,match_state,iyear,imonth] += EPA_Man[year_range_str[iyear]][irow]*1e3 # Tg -> kt\n",
    "        elif re.search('sheep',EPA_Man.animal[irow].lower()) != None:\n",
    "             emi_state_man_animal[11,match_state,iyear,imonth] += EPA_Man[year_range_str[iyear]][irow]*1e3 # Tg -> kt\n",
    "        elif re.search('swine',EPA_Man.animal[irow].lower()) != None:               # hogs<=>swine\n",
    "             emi_state_man_animal[12,match_state,iyear,imonth] += EPA_Man[year_range_str[iyear]][irow]*1e3 # Tg -> kt\n",
    "        else:\n",
    "            print('Something went horribly wrong!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2.2.2 Compare against national totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QA: Check the enteric emissions (summed across all animal types and states) compared to reported \n",
    "# national-level enteric emissions (kt/year) in the US GHGI. \n",
    "\n",
    "DEBUG=1\n",
    "\n",
    "#Read in total EPA emissions from public report table 5.2 (in kt)\n",
    "EPA_emi_agr_CH4 = pd.read_csv(EPA_AGR_inputfile, thousands=',', header=2,nrows = 10)\n",
    "EPA_emi_agr_CH4 = EPA_emi_agr_CH4.drop(['Unnamed: 0'], axis=1)\n",
    "EPA_emi_agr_CH4.rename(columns={EPA_emi_agr_CH4.columns[0]:'Source'}, inplace=True)\n",
    "EPA_emi_agr_CH4 = EPA_emi_agr_CH4.drop(columns = [str(n) for n in range(1990, start_year,1)])\n",
    "EPA_emi_man_CH4 = EPA_emi_agr_CH4.loc[EPA_emi_agr_CH4['Source']==\"Manure Management\"]\n",
    "EPA_emi_man_CH4.reset_index(inplace=True, drop=True)\n",
    "\n",
    "sum_emi = np.zeros([num_years])\n",
    "    \n",
    "print('QA/QC #1: Check State Emission Sum against GHGI Summary Emissions')\n",
    "for iyear in np.arange(0,num_years): \n",
    "    sum_emi[iyear] = np.sum(emi_state_man_animal[:,:,iyear,:])\n",
    "        \n",
    "    summary_emi = EPA_emi_man_CH4.iloc[0,iyear+1]  \n",
    "    diff1 = abs(sum_emi[iyear] - summary_emi)/((sum_emi[iyear] + summary_emi)/2)\n",
    "    if DEBUG ==1:\n",
    "        print(summary_emi)\n",
    "        print(sum_emi[iyear])\n",
    "    if diff1 < 0.0001:\n",
    "        print('Year ', year_range[iyear],': PASS, difference < 0.01%')\n",
    "    else:\n",
    "        print('Year ', year_range[iyear],': FAIL (check): ', diff1,'%') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.3 Read and Format USDA Census Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.3.1. State-Level USDA Animal Census Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2.3.1.1 First Census Year (2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Initialize and fill arrays that will hold the state livestock numbers per animal type for the first emissions year\n",
    "\n",
    "cen_animal_array = np.array(['Beef','Bison','Broilers','Cattle','Chickens','Dairy','Goats','Hogs','Horses',\\\n",
    "                'Layers','OnFeed','Pullets','Roosters','Sheep','Turkeys']) #these are the census categories\n",
    "\n",
    "proxy_animal_array = np.array(['Beef','Bison','Dairy','Goats','Horses',\\\n",
    "                'Mules','Broilers','Chickens','Layers','Pullets','Turkeys','Sheep','Swine']) #these are the categories from the state GHGI\n",
    "\n",
    "State_census_livestock_12 = np.zeros([len(cen_animal_array),len(State_ANSI)])\n",
    "State_livestock_12 = np.zeros([len(proxy_animal_array),len(State_ANSI)])\n",
    "    \n",
    "# a) Read in 2012 state census data (one file per animal type), b) pull out the state ANSI numbers and animal\n",
    "# counts data, c) for each state, reformat the state name and set the animal number to an integer, and \n",
    "# d) insert the state animal counts into the final livestock counts array as a function of state and animal type \n",
    "for ianimal in np.arange(0,len(cen_animal_array)):\n",
    "    if not (cen_animal_array[ianimal].strip('Chickens')): # No census file for chickens, skip for now\n",
    "        continue\n",
    "    #a)\n",
    "    State_file = Census_12_inputloc + cen_animal_array[ianimal] + \"_State.csv\"\n",
    "    print('Reading file: ' + State_file)\n",
    "    State_temp = pd.read_csv(State_file)\n",
    "    #b) \n",
    "    Census12_State = State_temp[['State ANSI','Value']].copy()\n",
    "    Census12_State['Value']= Census12_State['Value'].str.replace(r\"\\(D\\)\",\"0\")\n",
    "    Census12_State['Value']= Census12_State['Value'].str.replace(\",\",\"\").astype(float)\n",
    "    Census12_State['State ANSI']= Census12_State['State ANSI'].astype(int)\n",
    "    #c)\n",
    "    for istate in np.arange(0,len(Census12_State)):\n",
    "        match_state = np.where(Census12_State['State ANSI'][istate] == State_ANSI['ansi'])[0][0]\n",
    "        State_census_livestock_12[ianimal,match_state] = Census12_State['Value'][istate]\n",
    "\n",
    "#assign the census data to the correct animal type order (proxy animal order)\n",
    "for ianimal in np.arange(0,len(proxy_animal_array)):\n",
    "    if proxy_animal_array[ianimal] == 'Mules':\n",
    "        continue #will grid by area later (no county data)\n",
    "    elif proxy_animal_array[ianimal] == 'Chickens': \n",
    "        State_livestock_12[ianimal,:] = State_census_livestock_12[np.where(cen_animal_array=='Broilers')[0][0],:] \\\n",
    "                                    +State_census_livestock_12[np.where(cen_animal_array=='Layers')[0][0],:] \\\n",
    "                                    +State_census_livestock_12[np.where(cen_animal_array=='Pullets')[0][0],:]\\\n",
    "                                    +State_census_livestock_12[np.where(cen_animal_array=='Roosters')[0][0],:]\n",
    "    \n",
    "    elif proxy_animal_array[ianimal] == 'Swine':\n",
    "        State_livestock_12[ianimal,:] = State_census_livestock_12[np.where(cen_animal_array=='Hogs')[0][0],:]\n",
    "    else:\n",
    "        match_ani = np.where(proxy_animal_array[ianimal] == cen_animal_array)[0][0]\n",
    "        State_livestock_12[ianimal,:] = State_census_livestock_12[match_ani,:]\n",
    "        \n",
    "display(np.shape(State_livestock_12))\n",
    "display((State_livestock_12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2.3.1.2 Last Census Year (2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Initialize and fill arrays that will hold the state livestock numbers per animal type for the last available emissions year\n",
    "\n",
    "State_census_livestock_17 = np.zeros([len(cen_animal_array),len(State_ANSI)])\n",
    "State_livestock_17 = np.zeros([len(proxy_animal_array),len(State_ANSI)])\n",
    "    \n",
    "# a) Read in 2012 state census data (one file per animal type), b) pull out the state ANSI numbers and animal\n",
    "# counts data, c) for each state, reformat the state name and set the animal number to an integer, and \n",
    "# d) insert the state animal counts into the final livestock counts array as a function of state and animal type \n",
    "for ianimal in np.arange(0,len(cen_animal_array)):\n",
    "    if not (cen_animal_array[ianimal].strip('Chickens')): # No census file for chickens, skip for now\n",
    "        continue\n",
    "    #a)\n",
    "    State_file = Census_17_inputloc + cen_animal_array[ianimal] + \"_State.csv\"\n",
    "    print('Reading file: ' + State_file)\n",
    "    State_temp = pd.read_csv(State_file)\n",
    "    #b) \n",
    "    Census17_State = State_temp[['State ANSI','Value']].copy()\n",
    "    Census17_State['Value']= Census17_State['Value'].str.replace(r\"\\(D\\)\",\"0\")\n",
    "    Census17_State['Value']= Census17_State['Value'].str.replace(\",\",\"\").astype(float)\n",
    "    Census17_State['State ANSI']= Census17_State['State ANSI'].astype(int)\n",
    "    #c)\n",
    "    for istate in np.arange(0,len(Census17_State)):\n",
    "        match_state = np.where(Census17_State['State ANSI'][istate] == State_ANSI['ansi'])[0][0]\n",
    "        State_census_livestock_17[ianimal,match_state] = Census17_State['Value'][istate]\n",
    "\n",
    "\n",
    "#assign the census data to the correct animal type order (proxy animal order)\n",
    "for ianimal in np.arange(0,len(proxy_animal_array)):\n",
    "    if proxy_animal_array[ianimal] == 'Mules':\n",
    "        continue #will grid by area later (no county data)\n",
    "    elif proxy_animal_array[ianimal] == 'Chickens': \n",
    "        State_livestock_17[ianimal,:] = State_census_livestock_17[np.where(cen_animal_array=='Broilers')[0][0],:] \\\n",
    "                                    +State_census_livestock_17[np.where(cen_animal_array=='Layers')[0][0],:] \\\n",
    "                                    +State_census_livestock_17[np.where(cen_animal_array=='Pullets')[0][0],:]\\\n",
    "                                    +State_census_livestock_17[np.where(cen_animal_array=='Roosters')[0][0],:]\n",
    "    elif proxy_animal_array[ianimal] == 'Swine':\n",
    "        State_livestock_17[ianimal,:] = State_census_livestock_17[np.where(cen_animal_array=='Hogs')[0][0],:]\n",
    "\n",
    "    else:\n",
    "        match_ani = np.where(proxy_animal_array[ianimal] == cen_animal_array)[0][0]\n",
    "        State_livestock_17[ianimal,:] = State_census_livestock_17[match_ani,:]\n",
    "        \n",
    "display(np.shape(State_livestock_17))\n",
    "display((State_livestock_17))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.3.2 Read and Format County-Level USDA Animal Census Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2.3.2.1. First Census Year (2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Initialize and fill arrays that will hold the county livestock numbers per animal type for the first emissions year\n",
    "\n",
    "\n",
    "County_census_livestock_12 = np.zeros([len(cen_animal_array),len(State_ANSI),len(County_ANSI)])\n",
    "County_livestock_12 = np.zeros([len(proxy_animal_array),len(State_ANSI),len(County_ANSI)])\n",
    "\n",
    "\n",
    "# a) Read in 2012 county census data (one file per animal type), b) pull out the state and county ANSI numbers and animal\n",
    "# counts data, c) for each county, reformat the county name and set the animal number to an integer, and \n",
    "# d) insert the county animal counts into the final livestock counts array as a function of state, county, and animal type \n",
    "for ianimal in np.arange(0,len(cen_animal_array)):\n",
    "    if not (cen_animal_array[ianimal].strip('Chickens')):  # No census file for chickens, skip for now\n",
    "        continue\n",
    "    # a)\n",
    "    County_file = Census_12_inputloc + cen_animal_array[ianimal] + \"_County.csv\"\n",
    "    print('Reading file: ' + County_file)\n",
    "    County_temp = pd.read_csv(County_file)\n",
    "    # b)\n",
    "    Census12_County = County_temp[['State ANSI','County ANSI','Value']].copy()\n",
    "    Census12_County['Value']= Census12_County['Value'].str.replace(r\"\\(D\\)\",\"0\")\n",
    "    Census12_County['Value']= Census12_County['Value'].str.replace(\",\",\"\").astype(float)\n",
    "    Census12_County['State ANSI']= Census12_County['State ANSI'].astype(int)\n",
    "    Census12_County['County ANSI']= Census12_County['County ANSI'].astype(int)\n",
    "    #c)\n",
    "    for icounty in np.arange(0,len(Census12_County)):\n",
    "        #print(Census12_County.iloc[icounty,:])\n",
    "        match_state = np.where(Census12_County['State ANSI'][icounty] == State_ANSI['ansi'])[0][0]\n",
    "        match_county = np.where((Census12_County['County ANSI'][icounty] == County_ANSI['County'])&\\\n",
    "                               (Census12_County['State ANSI'][icounty] == County_ANSI['State']))[0][0]\n",
    "        #print(match_state, match_county)\n",
    "        County_census_livestock_12[ianimal,match_state,match_county] = Census12_County['Value'][icounty]\n",
    "\n",
    "#assign the census data to the correct animal type order (proxy animal order)\n",
    "for ianimal in np.arange(0,len(proxy_animal_array)):\n",
    "    if proxy_animal_array[ianimal] == 'Mules':\n",
    "        continue #will grid by area later (no county data)\n",
    "    elif proxy_animal_array[ianimal] == 'Chickens': \n",
    "        County_livestock_12[ianimal,:] = County_census_livestock_12[np.where(cen_animal_array=='Broilers')[0][0],:] \\\n",
    "                                    +County_census_livestock_12[np.where(cen_animal_array=='Layers')[0][0],:] \\\n",
    "                                    +County_census_livestock_12[np.where(cen_animal_array=='Pullets')[0][0],:]\\\n",
    "                                    +County_census_livestock_12[np.where(cen_animal_array=='Roosters')[0][0],:]\n",
    "    elif proxy_animal_array[ianimal] == 'Swine':\n",
    "        County_livestock_12[ianimal,:] = County_census_livestock_12[np.where(cen_animal_array=='Hogs')[0][0],:]\n",
    "\n",
    "    else:\n",
    "        match_ani = np.where(proxy_animal_array[ianimal] == cen_animal_array)[0][0]\n",
    "        County_livestock_12[ianimal,:] = County_census_livestock_12[match_ani,:]\n",
    "        \n",
    "display(np.shape(County_livestock_12))\n",
    "display((County_livestock_12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2.3.2.2. Last Census Year (2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Initialize and fill arrays that will hold the county livestock numbers per animal type for the first emissions year\n",
    "\n",
    "\n",
    "County_census_livestock_17 = np.zeros([len(cen_animal_array),len(State_ANSI),len(County_ANSI)])\n",
    "County_livestock_17 = np.zeros([len(proxy_animal_array),len(State_ANSI),len(County_ANSI)])\n",
    "\n",
    "\n",
    "# a) Read in 2012 county census data (one file per animal type), b) pull out the state and county ANSI numbers and animal\n",
    "# counts data, c) for each county, reformat the county name and set the animal number to an integer, and \n",
    "# d) insert the county animal counts into the final livestock counts array as a function of state, county, and animal type \n",
    "for ianimal in np.arange(0,len(cen_animal_array)):\n",
    "    if not (cen_animal_array[ianimal].strip('Chickens')):  # No census file for chickens, skip for now\n",
    "        continue\n",
    "    # a)\n",
    "    County_file = Census_17_inputloc + cen_animal_array[ianimal] + \"_County.csv\"\n",
    "    print('Reading file: ' + County_file)\n",
    "    County_temp = pd.read_csv(County_file)\n",
    "    # b)\n",
    "    Census17_County = County_temp[['State ANSI','County ANSI','Value','County']].copy()\n",
    "    Census17_County['Value']= Census17_County['Value'].str.replace(r\"\\(D\\)\",\"0\")\n",
    "    Census17_County['Value']= Census17_County['Value'].str.replace(\",\",\"\").astype(float)\n",
    "    Census17_County['County ANSI'].fillna(0, inplace=True)\n",
    "    #display(Census17_County)\n",
    "    Census17_County['State ANSI']= Census17_County['State ANSI'].astype(int)\n",
    "    Census17_County['County ANSI']= Census17_County['County ANSI'].astype(int)\n",
    "    #c)\n",
    "    for icounty in np.arange(0,len(Census17_County)):\n",
    "        #print(Census12_County.iloc[icounty,:])\n",
    "        if Census17_County.loc[icounty,'County'].upper()=='ALEUTIAN ISLANDS':\n",
    "            Census17_County.loc[icounty,'County ANSI']=13\n",
    "        #Map Oglala Lakota County to Shannon County (2015 name change)\n",
    "        if Census17_County.loc[icounty,'State ANSI'] == 46 and \\\n",
    "            Census17_County.loc[icounty,'County ANSI'] == 102:\n",
    "            Census17_County.loc[icounty,'County ANSI'] = 113\n",
    "        #correct county value for kenai peninsula (note that AK counties are incorrect [not correcting here since AK emissions removed])\n",
    "        if Census17_County.loc[icounty,'State ANSI'] == 2 and \\\n",
    "            Census17_County.loc[icounty,'County ANSI'] == 0:\n",
    "            Census17_County.loc[icounty,'County ANSI'] = 122\n",
    "        match_state = np.where(Census17_County['State ANSI'][icounty] == State_ANSI['ansi'])[0][0]\n",
    "        #print(Census17_County.loc[icounty,:], match_state)\n",
    "        match_county = np.where((Census17_County['County ANSI'][icounty] == County_ANSI['County'])&\\\n",
    "                               (Census17_County['State ANSI'][icounty] == County_ANSI['State']))[0][0]\n",
    "        #print(match_state, match_county)\n",
    "        County_census_livestock_17[ianimal,match_state,match_county] = Census17_County['Value'][icounty]\n",
    "\n",
    "#assign the census data to the correct animal type order (proxy animal order)\n",
    "for ianimal in np.arange(0,len(proxy_animal_array)):\n",
    "    if proxy_animal_array[ianimal] == 'Mules':\n",
    "        continue #will grid by area later (no county data)\n",
    "    elif proxy_animal_array[ianimal] == 'Chickens': \n",
    "        County_livestock_17[ianimal,:] = County_census_livestock_17[np.where(cen_animal_array=='Broilers')[0][0],:] \\\n",
    "                                    +County_census_livestock_17[np.where(cen_animal_array=='Layers')[0][0],:] \\\n",
    "                                    +County_census_livestock_17[np.where(cen_animal_array=='Pullets')[0][0],:]\\\n",
    "                                    +County_census_livestock_17[np.where(cen_animal_array=='Roosters')[0][0],:]\n",
    "    elif proxy_animal_array[ianimal] == 'Swine':\n",
    "        County_livestock_17[ianimal,:] = County_census_livestock_17[np.where(cen_animal_array=='Hogs')[0][0],:]\n",
    "\n",
    "    else:\n",
    "        match_ani = np.where(proxy_animal_array[ianimal] == cen_animal_array)[0][0]\n",
    "        County_livestock_17[ianimal,:] = County_census_livestock_17[match_ani,:]\n",
    "        \n",
    "display(np.shape(County_livestock_17))\n",
    "display((County_livestock_17))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.3.3. Calculate Total State-Level Animal Counts from the County-Level Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2.3.3.1 First Census Year (2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "            \n",
    "Census_summary_State_12  = np.zeros([len(proxy_animal_array),len(State_ANSI)])\n",
    "Census_summary_County_12  = np.zeros([len(proxy_animal_array),len(State_ANSI)])\n",
    "Census_summary_Missing_Area_12  = np.zeros([len(proxy_animal_array),len(State_ANSI)])\n",
    "Census_summary_per_area_12  = np.zeros([len(proxy_animal_array),len(State_ANSI)])\n",
    "#in the original code, livestock area is just equivalent to total county areas. Comes from County ANSI dataset\n",
    "Census_livestock_area_12 = np.zeros([len(State_ANSI),len(County_ANSI)])\n",
    "\n",
    "\n",
    "#save the state sum, the state sum (calc'd from counties), and for a county that has zero livestock data, save area for later\n",
    "#the arrays were created to follow the index values of 'State_ANSI' and 'County_ANSI' arrays, so can just loop through these here\n",
    "for ianimal in np.arange(0, len(proxy_animal_array)):\n",
    "    for istate in np.arange(0, len(State_ANSI)):\n",
    "        Census_summary_State_12[ianimal,istate] = State_livestock_12[ianimal,istate]\n",
    "        Census_summary_County_12[ianimal,istate] = np.sum(County_livestock_12[ianimal,istate,:])\n",
    "    \n",
    "    for icounty in np.arange(0,len(County_ANSI)):\n",
    "        match_state = np.where(State_ANSI['ansi']==County_ANSI['State'][icounty])[0][0]\n",
    "        if County_livestock_12[ianimal,match_state,icounty] ==0:\n",
    "            Census_summary_Missing_Area_12[ianimal,match_state] += County_ANSI['Area'][icounty]\n",
    "        \n",
    "\n",
    "#if a state has some counties with no livestock data, then calculate missing animals per area in that state\n",
    "# missing animals in state = (state animal sum - county animal sum)/ total area of counties with no data\n",
    "\n",
    "for ianimal in np.arange(0,len(proxy_animal_array)):\n",
    "    for istate in np.arange(0,len(State_ANSI)):\n",
    "        if Census_summary_Missing_Area_12[ianimal,istate] > 0:\n",
    "            Census_summary_per_area_12[ianimal,istate] = (Census_summary_State_12[ianimal,istate] - \\\n",
    "                                                          Census_summary_County_12[ianimal,istate]) / \\\n",
    "                                                            Census_summary_Missing_Area_12[ianimal,istate]\n",
    "        if Census_summary_per_area_12[ianimal,istate] < 0:\n",
    "            Census_summary_per_area_12[ianimal,istate] = 0.0\n",
    "\n",
    "\n",
    "#Now that animals per area have been calculated for counties with missing data, fill in these\n",
    "#zeros in the county data using the (animal counts / area) X county area relationship\n",
    "#average animal per area on the state level times the area of the county\n",
    "\n",
    "\n",
    "#For each county, if it does not have livestock data, estimate the 'counts of animals per area' (in the given state) * area of that county\n",
    "#note that this places livestock emissions in all counties (is this a good assumption?)\n",
    "for ianimal in np.arange(0,len(proxy_animal_array)):\n",
    "    #for istate in np.arange(0, len(State_ANSI)):\n",
    "    for icounty in np.arange(0,len(County_ANSI)):\n",
    "        match_state = np.where(State_ANSI['ansi']==County_ANSI['State'][icounty])[0][0]\n",
    "        if County_livestock_12[ianimal,match_state,icounty] == 0.0:\n",
    "            County_livestock_12[ianimal,match_state,icounty] = Census_summary_per_area_12[ianimal,match_state] * \\\n",
    "                                                                County_ANSI['Area'][icounty]\n",
    "\n",
    "#Next, calculate the total number of animals in each state based on the number of animal in each county\n",
    "#Calculate the total number of animals in each state based on the number of animals\n",
    "    \n",
    "#Recalculate the state animal counts from the corrected county data\n",
    "State_total_animals_12 = np.zeros([len(proxy_animal_array),len(State_ANSI)])\n",
    "for ianimal in np.arange(0,len(proxy_animal_array)):\n",
    "    for icounty in np.arange(0,len(County_ANSI)):\n",
    "        match_state = np.where(State_ANSI['ansi']==County_ANSI['State'][icounty])[0][0]\n",
    "        State_total_animals_12[ianimal,match_state] += County_livestock_12[ianimal,match_state,icounty]\n",
    "\n",
    "for ianimal in np.arange(0, len(proxy_animal_array)):\n",
    "    print('Orig. Sum',np.sum(Census_summary_County_12[ianimal,:]))\n",
    "    print('Corrected Sum',np.sum(State_total_animals_12[ianimal,:]))\n",
    "    print('State Sum',np.sum(Census_summary_State_12[ianimal,:]))\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2.3.3.2 Last Census Year (2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Initialize and calculate state-level animal count arrays from the county-level animal count data\n",
    "\n",
    "Census_summary_State_17  = np.zeros([len(proxy_animal_array),len(State_ANSI)])\n",
    "Census_summary_County_17  = np.zeros([len(proxy_animal_array),len(State_ANSI)])\n",
    "Census_summary_Missing_Area_17  = np.zeros([len(proxy_animal_array),len(State_ANSI)])\n",
    "Census_summary_per_area_17  = np.zeros([len(proxy_animal_array),len(State_ANSI)])\n",
    "\n",
    "#save the state sum, the state sum (calc'd from counties), and for a county that has zero livestock data, save area for later\n",
    "#the arrays were created to follow the index values of 'State_ANSI' and 'County_ANSI' arrays, so can just loop through these here\n",
    "for ianimal in np.arange(0, len(proxy_animal_array)):\n",
    "    for istate in np.arange(0, len(State_ANSI)):\n",
    "        Census_summary_State_17[ianimal,istate] = State_livestock_17[ianimal,istate]\n",
    "        Census_summary_County_17[ianimal,istate] = np.sum(County_livestock_17[ianimal,istate,:])\n",
    "    \n",
    "    for icounty in np.arange(0,len(County_ANSI)):\n",
    "        match_state = np.where(State_ANSI['ansi']==County_ANSI['State'][icounty])[0][0]\n",
    "        if County_livestock_17[ianimal,match_state,icounty] ==0:\n",
    "            Census_summary_Missing_Area_17[ianimal,match_state] += County_ANSI['Area'][icounty]\n",
    "\n",
    "#if a state has some counties with no livestock data, then calculate missing animals per area in that state\n",
    "# missing animals in state = (state animal sum - county animal sum)/ total area of counties with no data\n",
    "\n",
    "for ianimal in np.arange(0,len(proxy_animal_array)):\n",
    "    for istate in np.arange(0,len(State_ANSI)):\n",
    "        if Census_summary_Missing_Area_17[ianimal,istate] > 0:\n",
    "            Census_summary_per_area_17[ianimal,istate] = (Census_summary_State_17[ianimal,istate] - \\\n",
    "                                                          Census_summary_County_17[ianimal,istate]) / \\\n",
    "                                                            Census_summary_Missing_Area_17[ianimal,istate]\n",
    "        if Census_summary_per_area_17[ianimal,istate] < 0:\n",
    "            Census_summary_per_area_17[ianimal,istate] = 0.0\n",
    "\n",
    "\n",
    "#For each county, if it does not have livestock data, estimate the 'counts of animals per area' (in the given state) * area of that county\n",
    "#note that this places livestock emissions in all counties (is this a good assumption?)\n",
    "for ianimal in np.arange(0,len(proxy_animal_array)):\n",
    "    #for istate in np.arange(0, len(State_ANSI)):\n",
    "    for icounty in np.arange(0,len(County_ANSI)):\n",
    "        match_state = np.where(State_ANSI['ansi']==County_ANSI['State'][icounty])[0][0]\n",
    "        if County_livestock_17[ianimal,match_state,icounty] == 0.0:\n",
    "            County_livestock_17[ianimal,match_state,icounty] = Census_summary_per_area_17[ianimal,match_state] * \\\n",
    "                                                                County_ANSI['Area'][icounty]\n",
    "\n",
    "#Next, calculate the total number of animals in each state based on the number of animal in each county\n",
    "#Calculate the total number of animals in each state based on the number of animals\n",
    "\n",
    "    \n",
    "#Recalculate the state animal counts from the corrected county data\n",
    "State_total_animals_17 = np.zeros([len(proxy_animal_array),len(State_ANSI)])\n",
    "for ianimal in np.arange(0,len(proxy_animal_array)):\n",
    "    for icounty in np.arange(0,len(County_ANSI)):\n",
    "        match_state = np.where(State_ANSI['ansi']==County_ANSI['State'][icounty])[0][0]\n",
    "        State_total_animals_17[ianimal,match_state] += County_livestock_17[ianimal,match_state,icounty]\n",
    "\n",
    "for ianimal in np.arange(0, len(proxy_animal_array)):\n",
    "    print('Orig. Sum',np.sum(Census_summary_County_17[ianimal,:]))\n",
    "    print('Corrected Sum',np.sum(State_total_animals_17[ianimal,:]))\n",
    "    print('State Sum',np.sum(Census_summary_State_17[ianimal,:]))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.3.4. Calculate State and County-Level Animal Counts Across Entire Timeseries (e.g., 2012-2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the previous first and latest available state-level census animal counts data, find the\n",
    "# change in the number of animals in each state for each animal type between the first\n",
    "# and last avaible census years (e.g., 2012 and 2017). Then use this relationship to \n",
    "# calculate the animal counts at the state-level across all inventory years (e.g., 2012-2018)\n",
    "\n",
    "animal_state_trend = (State_total_animals_17-State_total_animals_12)/5\n",
    "\n",
    "state_animal_counts = np.zeros([len(proxy_animal_array),len(State_ANSI),num_years])\n",
    "#Use slope (e.g., animal number / year) and year to calculate the animal counts for each year in the inventory\n",
    "for iyear in np.arange(0,num_years):\n",
    "    for ianimal in np.arange(0,len(proxy_animal_array)):\n",
    "        state_animal_counts[ianimal,:,iyear] = animal_state_trend[ianimal,:]*iyear + State_total_animals_12[ianimal,:]\n",
    "\n",
    "#Make any negative animal counts zero\n",
    "state_animal_counts[state_animal_counts < 0] = 0\n",
    "\n",
    "animal_county_trend = (County_livestock_17-County_livestock_12)/5\n",
    "\n",
    "#Use slope (e.g., animal number / year) and year to calculate the animal counts for each year in the inventory\n",
    "county_animal_counts = np.zeros([len(proxy_animal_array),len(State_ANSI),len(County_ANSI),num_years])\n",
    "for iyear in np.arange(0,num_years):\n",
    "    for ianimal in np.arange(0,len(proxy_animal_array)):\n",
    "        county_animal_counts[ianimal,:,:,iyear] = animal_county_trend[ianimal,:,:]*iyear+County_livestock_12[ianimal,:,:]\n",
    "county_animal_counts[county_animal_counts < 0] = 0\n",
    "        \n",
    "# Print time\n",
    "ct = datetime.datetime.now() \n",
    "print(\"current time:\", ct) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.4 Read in and Format Grid-level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in and format the gridded maps of land use data, also covert from rank into a probability\n",
    "# These data are held constant over all years\n",
    "\n",
    "#Generate a vector with the 9 animal types used to grid county-level emissions:\n",
    "#Census data to LUC data mapping:\n",
    "#Uniform --> animal\n",
    "#Broilers + Turkeys --> brltrk\n",
    "#On Feed --> ctlfed\n",
    "#Beef + Bison +Cattle --> ctlinv\n",
    "#Goats --> goat\n",
    "#Hogs --> hogpig\n",
    "#Horses --> hrspny\n",
    "#Chickens + Layers + Pullets + Roosters --> lyrplt\n",
    "#Dairy --> mlkcow\n",
    "#Sheep --> shplmb\n",
    "luc_animal_array = np.array(['animal','ctlfed','ctlinv','goat','brltrk','lyrplt','hogpig','hrspny','mlkcow','shplmb'])\n",
    "\n",
    "map_luc_rank = np.zeros([len(luc_animal_array),len(lat001),len(lon001)])\n",
    "\n",
    "for ianimal in np.arange(len(luc_animal_array)):\n",
    "    file_temp = Dataset(USDA_LUC_inputloc+luc_animal_array[ianimal]+'_001x001.nc')\n",
    "    temp_data = np.array(file_temp.variables['rank_'+luc_animal_array[ianimal]])\n",
    "    map_luc_rank[ianimal,:,:] = np.flipud(temp_data)\n",
    "    map_luc_rank[ianimal,:,:] = map_luc_rank[ianimal,:,:].astype(float)\n",
    "    file_temp.close()\n",
    "    \n",
    "map_luc_rank[map_luc_rank >  6.5]=   0.0\n",
    "map_luc_rank[map_luc_rank == 1]  =   0.0001\n",
    "map_luc_rank[map_luc_rank == 2]  =   0.0200\n",
    "map_luc_rank[map_luc_rank == 3]  =   0.0500\n",
    "map_luc_rank[map_luc_rank == 4]  =   0.1000\n",
    "map_luc_rank[map_luc_rank == 5]  =   0.3300\n",
    "map_luc_rank[map_luc_rank == 6]  =   0.4999\n",
    "   \n",
    "\n",
    "#Calculate the total product of the land area and animal rankings (probability * area) for each county and state\n",
    "map_cm_rank_temp = np.zeros([len(luc_animal_array),len(lat001),len(lon001)])\n",
    "for ianimal in np.arange(0, len(luc_animal_array)):\n",
    "    map_cm_rank_temp[ianimal,:,:] = map_luc_rank[ianimal,:,:]*area_map[:,:]\n",
    "    \n",
    "#create re-order and create proxy with correct number of animal types (ctlinv applied to beef, cattle, bison)\n",
    "#assign the census data to the correct animal type order (proxy animal order)\n",
    "#data are the same for each year\n",
    "map_cm_rank = np.zeros([len(proxy_animal_array),len(lat001),len(lon001)])\n",
    "\n",
    "#for iyear in np.arange(0, num_years):\n",
    "for ianimal in np.arange(0,len(proxy_animal_array)):\n",
    "    if proxy_animal_array[ianimal] == 'Mules':\n",
    "        map_cm_rank[ianimal,:,:] = map_cm_rank_temp[np.where(luc_animal_array=='animal')[0][0],:,:]\n",
    "    elif proxy_animal_array[ianimal] == 'Beef':\n",
    "        map_cm_rank[ianimal,:,:] = map_cm_rank_temp[np.where(luc_animal_array=='ctlinv')[0][0],:,:]\n",
    "    elif proxy_animal_array[ianimal] == 'Bison':\n",
    "        map_cm_rank[ianimal,:,:] = map_cm_rank_temp[np.where(luc_animal_array=='ctlinv')[0][0],:,:]\n",
    "    elif proxy_animal_array[ianimal] == 'Dairy':\n",
    "        map_cm_rank[ianimal,:,:] = map_cm_rank_temp[np.where(luc_animal_array=='mlkcow')[0][0],:,:]\n",
    "    elif proxy_animal_array[ianimal] == 'Goats':\n",
    "        map_cm_rank[ianimal,:,:] = map_cm_rank_temp[np.where(luc_animal_array=='goat')[0][0],:,:]\n",
    "    elif proxy_animal_array[ianimal] == 'Horses':\n",
    "        map_cm_rank[ianimal,:,:] = map_cm_rank_temp[np.where(luc_animal_array=='hrspny')[0][0],:,:]\n",
    "    elif proxy_animal_array[ianimal] == 'Sheep':\n",
    "        map_cm_rank[ianimal,:,:] = map_cm_rank_temp[np.where(luc_animal_array=='shplmb')[0][0],:,:]\n",
    "    elif proxy_animal_array[ianimal] == 'Swine':\n",
    "        map_cm_rank[ianimal,:,:] = map_cm_rank_temp[np.where(luc_animal_array=='hogpig')[0][0],:,:]\n",
    "    elif proxy_animal_array[ianimal] == 'Broilers':\n",
    "        map_cm_rank[ianimal,:,:] = map_cm_rank_temp[np.where(luc_animal_array=='brltrk')[0][0],:,:]\n",
    "    elif proxy_animal_array[ianimal] == 'Chickens':\n",
    "        map_cm_rank[ianimal,:,:] = map_cm_rank_temp[np.where(luc_animal_array=='lyrplt')[0][0],:,:]\n",
    "    elif proxy_animal_array[ianimal] == 'Layers':\n",
    "        map_cm_rank[ianimal,:,:] = map_cm_rank_temp[np.where(luc_animal_array=='lyrplt')[0][0],:,:]\n",
    "    elif proxy_animal_array[ianimal] == 'Pullets':\n",
    "        map_cm_rank[ianimal,:,:] = map_cm_rank_temp[np.where(luc_animal_array=='lyrplt')[0][0],:,:]\n",
    "    elif proxy_animal_array[ianimal] == 'Turkeys':\n",
    "        map_cm_rank[ianimal,:,:] = map_cm_rank_temp[np.where(luc_animal_array=='brltrk')[0][0],:,:]\n",
    "\n",
    "del map_luc_rank, temp_data, map_cm_rank_temp\n",
    "\n",
    "display(np.shape(map_cm_rank))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------\n",
    "## Step 3. Read in and Format US EPA GHGI Data\n",
    "-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in total EPA emissions from public report table 5.2 (in kt)\n",
    "EPA_emi_agr_CH4 = pd.read_csv(EPA_AGR_inputfile, thousands=',', header=2,nrows = 10)\n",
    "EPA_emi_agr_CH4 = EPA_emi_agr_CH4.drop(['Unnamed: 0'], axis=1)\n",
    "EPA_emi_agr_CH4.rename(columns={EPA_emi_agr_CH4.columns[0]:'Source'}, inplace=True)\n",
    "EPA_emi_agr_CH4 = EPA_emi_agr_CH4.drop(columns = [str(n) for n in range(1990, start_year,1)])\n",
    "EPA_emi_man_CH4 = EPA_emi_agr_CH4.loc[EPA_emi_agr_CH4['Source']==\"Manure Management\"]\n",
    "EPA_emi_man_CH4.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print('EPA GHGI National Manure CH4 Emissions (kt):')\n",
    "display(EPA_emi_man_CH4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Split Emissions into Gridding Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split GHG emissions into gridding groups, based on Coal Proxy Mapping file\n",
    "\n",
    "DEBUG =1\n",
    "start_year_idx = EPA_emi_man_CH4.columns.get_loc(str(start_year))\n",
    "end_year_idx = EPA_emi_man_CH4.columns.get_loc(str(end_year))+1\n",
    "ghgi_livestock_groups = ghgi_livestock_map['GHGI_Emi_Group'].unique()\n",
    "sum_emi = np.zeros([num_years])\n",
    "\n",
    "for igroup in np.arange(0,len(EPA_emi_man_CH4)): #loop through all groups, finding the GHGI sources in that group and summing emissions for that region, year        vars()[ghgi_prod_groups[igroup]] = np.zeros([num_regions-1,num_years])\n",
    "    print(ghgi_livestock_groups[igroup])\n",
    "    vars()[ghgi_livestock_groups[igroup]] = np.zeros([num_years])\n",
    "    source_temp = ghgi_livestock_map.loc[ghgi_livestock_map['GHGI_Emi_Group'] == ghgi_livestock_groups[igroup], 'GHGI_Source']\n",
    "    pattern_temp  = '|'.join(source_temp) \n",
    "    #print(pattern_temp) \n",
    "    emi_temp =EPA_emi_man_CH4[EPA_emi_man_CH4['Source'].str.contains(pattern_temp)]\n",
    "    #display(emi_temp)\n",
    "    vars()[ghgi_livestock_groups[igroup]][:] = emi_temp.iloc[:,start_year_idx:].sum()\n",
    "        \n",
    "        \n",
    "#Check against total summary emissions \n",
    "print('QA/QC #1: Check Processing Emission Sum against GHGI Summary Emissions')\n",
    "for iyear in np.arange(0,num_years): \n",
    "    for igroup in np.arange(0,len(EPA_emi_man_CH4)):\n",
    "        #if iyear ==0:\n",
    "        #    vars()[ghgi_livestock_groups[igroup]][iyear] -= 0.5  ##NOTE: correct rounding error so sum of emissions = reported total emissions\n",
    "        sum_emi[iyear] += vars()[ghgi_livestock_groups[igroup]][iyear]\n",
    "        \n",
    "    summary_emi = EPA_emi_man_CH4.iloc[0,iyear+1]  \n",
    "    #Check 1 - make sure that the sums from all the regions equal the totals reported\n",
    "    diff1 = abs(sum_emi[iyear] - summary_emi)/((sum_emi[iyear] + summary_emi)/2)\n",
    "    if DEBUG==1:\n",
    "        print(summary_emi)\n",
    "        print(sum_emi[iyear])\n",
    "    if diff1 < 0.00025:\n",
    "        print('Year ', year_range[iyear],': PASS, difference < 0.025%')\n",
    "    else:\n",
    "        print('Year ', year_range[iyear],': FAIL (check Production & summary tabs): ', diff1,'%') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "## Step 4. Grid Data\n",
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4.1. Allocate emissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 4.1.1 Assign the Appropriate Proxy Variable Names (state & grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The names on the *left* need to match the 'Stationary_ProxyMapping' 'State_Proxy_Group' names \n",
    "# (these are initialized in Step 2). \n",
    "# The names on the *right* are the variable names used to caluclate the proxies in this code.\n",
    "# Names on the right need to match those from the code in Step 2\n",
    "\n",
    "#national --> state proxies (animal x state x year [X month])\n",
    "State_man_emi_animal = emi_state_man_animal\n",
    "\n",
    "#state --> county proxies (animal x state x county x year [x month])?\n",
    "County_animal_counts = county_animal_counts\n",
    "\n",
    "#county --> grid proxies (animal x0.01x0.01)\n",
    "Map_animal_area_rank = map_cm_rank\n",
    "Map_animal_area_rank_nongrid = 0 #rank does not include non-CONUS\n",
    "\n",
    "\n",
    "\n",
    "# remove variables to clear space for larger arrays \n",
    "del emi_state_man_animal, county_animal_counts, map_cm_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 4.1.2 Allocate National EPA Emissions to the State-Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate state-level emissions \n",
    "# Emissions in kt\n",
    "# State data = national GHGI emissions * state proxy/national total\n",
    "\n",
    "DEBUG = 1\n",
    "\n",
    "# Note that national emissions are retained for groups that do not have state proxies (identified in the mapping file)\n",
    "# and are gridded in the next step\n",
    "\n",
    "# Make placeholder emission arrays for each group\n",
    "for igroup in np.arange(0,len(proxy_livestock_map)):\n",
    "    if proxy_livestock_map.loc[igroup,'State_Month_Flag'] ==1:\n",
    "        vars()['State_'+proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']] = np.zeros([len(proxy_animal_array),len(State_ANSI),num_years,num_months])\n",
    "    else:\n",
    "        vars()['State_'+proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']] = np.zeros([len(proxy_animal_array),len(State_ANSI),num_years])\n",
    "    vars()['NonState_'+proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']] = np.zeros([len(proxy_animal_array),num_years])\n",
    "        \n",
    "#Loop over years\n",
    "for iyear in np.arange(num_years):\n",
    "    #Loop over states\n",
    "    for istate in np.arange(len(State_ANSI)):\n",
    "        for igroup in np.arange(0,len(proxy_livestock_map)):    \n",
    "            if proxy_livestock_map.loc[igroup,'State_Proxy_Group'] != '-' and proxy_livestock_map.loc[igroup,'GHGI_Emi_Group'] != 'Emi_not_mapped':\n",
    "                if proxy_livestock_map.loc[igroup,'State_Month_Flag'] ==1:\n",
    "                    for imonth in np.arange(0,num_months):\n",
    "                        for ianimal in np.arange(0,len(proxy_animal_array)):\n",
    "                            vars()['State_'+proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']][ianimal,istate,iyear,imonth] += \\\n",
    "                                vars()[proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']][iyear]* \\\n",
    "                                data_fn.safe_div(vars()[proxy_livestock_map.loc[igroup,'State_Proxy_Group']][ianimal,istate,iyear,imonth], \\\n",
    "                                             np.sum(vars()[proxy_livestock_map.loc[igroup,'State_Proxy_Group']][:,:,iyear,:]))   \n",
    "                            #print(istate, imonth, ianimal, vars()[proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']][iyear])\n",
    "                else:\n",
    "                    for ianimal in np.arange(0,len(proxy_animal_array)):\n",
    "                        vars()['State_'+proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']][ianimal,istate,iyear] += \\\n",
    "                            vars()[proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']][iyear]* \\\n",
    "                            data_fn.safe_div(vars()[proxy_livestock_map.loc[igroup,'State_Proxy_Group']][ianimal,istate,iyear], \\\n",
    "                                         np.sum(vars()[proxy_livestock_map.loc[igroup,'State_Proxy_Group']][:,:,iyear]))   \n",
    "            else:\n",
    "                vars()['NonState_'+proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']][iyear] = vars()[proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']][iyear]\n",
    "                \n",
    "# Check sum of all gridded emissions + emissions not included in state allocation\n",
    "print('QA/QC #1: Check weighted emissions against GHGI')   \n",
    "for iyear in np.arange(0,num_years):\n",
    "    summary_emi = EPA_emi_man_CH4.iloc[0,iyear+1] \n",
    "    calc_emi = 0\n",
    "    for igroup in np.arange(0,len(proxy_livestock_map)):\n",
    "        if proxy_livestock_map.loc[igroup,'State_Month_Flag'] ==1:\n",
    "            calc_emi +=  np.sum(vars()['State_'+proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']][:,:,iyear,:])+\\\n",
    "                np.sum(vars()['NonState_'+proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']][:,iyear]) \n",
    "        else:\n",
    "            calc_emi +=  np.sum(vars()['State_'+proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']][:,:,iyear])+\\\n",
    "                np.sum(vars()['NonState_'+proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']][:,iyear]) #np.sum(Emissions[:,iyear]) + Emissions_nongrid[iyear] + Emissions_nonstate[iyear]\n",
    "    if DEBUG ==1:\n",
    "        print(summary_emi)\n",
    "        print(calc_emi)\n",
    "        #print(np.sum(vars()['NonState_'+proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']][:,iyear]))\n",
    "    diff = abs(summary_emi-calc_emi)/((summary_emi+calc_emi)/2)\n",
    "    if diff < 0.00025:\n",
    "        print('Year ', year_range[iyear], ': PASS, difference < 0.025%')\n",
    "    else:\n",
    "        print('Year ', year_range[iyear], ': FAIL -- Difference = ', diff*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.3 Allocate emissions to the county level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate county-level emissions (kt)\n",
    "# Emissions in kt\n",
    "# County data (by animal) = state emissions (by animal) * county proxy (by animal)/state total (by animal)\n",
    "\n",
    "# If there are emissions in a state but no proxy data available in the entire state, \n",
    "# emissions are allocated within that state by relative county areas (this will be true for mules)\n",
    "\n",
    "DEBUG = 1\n",
    "\n",
    "# Note that national emissions are retained for groups that do not have state proxies (identified in the mapping file)\n",
    "# and are gridded in the next step\n",
    "\n",
    "# Make placeholder emission arrays for each group\n",
    "for igroup in np.arange(0,len(proxy_livestock_map)):\n",
    "    if proxy_livestock_map.loc[igroup,'State_Month_Flag'] ==1:\n",
    "        vars()['County_'+proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']] = \\\n",
    "                np.zeros([len(proxy_animal_array),len(State_ANSI),len(County_ANSI),num_years,num_months])\n",
    "    else:\n",
    "        vars()['County_'+proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']] = np.zeros([len(proxy_animal_array),len(State_ANSI),len(County_ANSI),num_years])\n",
    "    vars()['NonCounty_'+proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']] = np.zeros([len(proxy_animal_array),num_years])\n",
    "        \n",
    "#Loop over years\n",
    "for iyear in np.arange(0,num_years):\n",
    "    #running_sum = np.zeros(len(State_ANSI))\n",
    "    for icounty in np.arange(0,len(County_ANSI)):\n",
    "        istate = np.where(State_ANSI['ansi']==County_ANSI['State'][icounty])[0][0]\n",
    "        state_ansi = State_ANSI['ansi'][istate]\n",
    "        #print(icounty, istate)\n",
    "        for igroup in np.arange(0,1):#len(proxy_livestock_map)): \n",
    "            for ianimal in np.arange(0,len(proxy_animal_array)):\n",
    "                if proxy_livestock_map.loc[igroup,'State_Month_Flag'] ==1: #if state data allocated bvy month...\n",
    "                    for imonth in np.arange(0,num_months):\n",
    "                        emi_temp = vars()['State_'+proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']][ianimal,istate,iyear,imonth]\n",
    "                        frac_temp = data_fn.safe_div(vars()[proxy_livestock_map.loc[igroup,'County_Proxy_Group']][ianimal,istate,icounty,iyear], \\\n",
    "                                    np.sum(vars()[proxy_livestock_map.loc[igroup,'County_Proxy_Group']][ianimal,istate,:,iyear]))\n",
    "                        if emi_temp > 0 and frac_temp > 0:\n",
    "                            vars()['County_'+proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']][ianimal,istate,icounty,iyear,imonth] = emi_temp * frac_temp\n",
    "                        elif emi_temp > 0 and np.sum(vars()[proxy_livestock_map.loc[igroup,'County_Proxy_Group']][ianimal,istate,:,iyear]) == 0:                \n",
    "                            #if state emissions >0 and no proxy data in that state, allocate based on relative county areas\n",
    "                            frac_temp = data_fn.safe_div(County_ANSI.loc[icounty,'Area'],np.sum(County_ANSI['Area'][County_ANSI['State'] == state_ansi]))\n",
    "                            vars()['County_'+proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']][ianimal,istate,icounty,iyear,imonth] = emi_temp * frac_temp  \n",
    "                        else: \n",
    "                            # if there are no state emissions OR if there are state emissions, \n",
    "                            # there is proxy data in the state, but no proxy data in that county, skip that county and move to next\n",
    "                            continue\n",
    "\n",
    "\n",
    "# Check sum of all gridded emissions + emissions not included in state allocation\n",
    "print('QA/QC #2: Check weighted emissions against GHGI')   \n",
    "for iyear in np.arange(0,num_years):\n",
    "    summary_emi = EPA_emi_man_CH4.iloc[0,iyear+1] \n",
    "    calc_emi = 0\n",
    "    for igroup in np.arange(0,len(proxy_livestock_map)):\n",
    "        if proxy_livestock_map.loc[igroup,'State_Month_Flag'] ==1:\n",
    "            calc_emi +=  np.sum(vars()['County_'+proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']][:,:,:,iyear,:])+\\\n",
    "                np.sum(vars()['NonCounty_'+proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']][:,iyear])\n",
    "        else:\n",
    "            calc_emi +=  np.sum(vars()['County_'+proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']][:,:,:,iyear])+\\\n",
    "                np.sum(vars()['NonCounty_'+proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']][:,iyear])\n",
    "\n",
    "    if DEBUG ==1:\n",
    "        print(summary_emi)\n",
    "        print(calc_emi)\n",
    "    diff = abs(summary_emi-calc_emi)/((summary_emi+calc_emi)/2)\n",
    "    if diff < 0.00025:\n",
    "        print('Year ', year_range[iyear], ': PASS, difference < 0.025%')\n",
    "    else:\n",
    "        print('Year ', year_range[iyear], ': FAIL -- Difference = ', diff*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.4 Allocate emissions to the CONUS region (0.1x0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# To speed up the code, this notebook does not loop through each county, but instead loops through\n",
    "# each lat/lon value in the CONUS region. Emissions are allocated based on the fraction of \n",
    "# the proxy that is in each grid cell relative to the total in that county. \n",
    "# Since the code is not using county masks, the sum of each proxy for each county/state pair\n",
    "# must first be calcualted. \n",
    "# This chunk calculates the county totals for each animal for the area-weighted probability\n",
    "# map and the county area map. \n",
    "\n",
    "\n",
    "Map_animal_area_rank_sum = np.zeros([len(proxy_animal_array),len(State_ANSI),len(County_ANSI)])\n",
    "Area_sum = np.zeros([len(State_ANSI),len(County_ANSI)])\n",
    "\n",
    "#For each grid box that falls within the continental US geographic bounds, keep a running sum to calculate \n",
    "# the total cm_rank for each animal type within each state and county. \n",
    "# Also keep a running sum of the total area within each state and county.\n",
    "for ilat in np.arange(0, len(lat001)):\n",
    "    print(ilat)\n",
    "    for ilon in np.arange(0, len(lon001)):\n",
    "        if state_ANSI_map[ilat,ilon] > 0: #only includes CONUS region\n",
    "            istate = np.where(State_ANSI['ansi']==state_ANSI_map[ilat,ilon])[0][0]\n",
    "            icounty = np.where((County_ANSI['State']==state_ANSI_map[ilat,ilon]) & \\\n",
    "                                    (County_ANSI['County']==county_ANSI_map[ilat,ilon]))[0][0]\n",
    "            Area_sum[istate,icounty] += area_map[ilat,ilon]\n",
    "            for ianimal in np.arange(0, len(proxy_animal_array)):                                          \n",
    "                Map_animal_area_rank_sum[ianimal,istate,icounty] += Map_animal_area_rank[ianimal,ilat,ilon]\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clear large variables\n",
    "del Census_livestock_area_12, County_animal_counts, County_census_livestock_12, County_census_livestock_12\n",
    "del County_census_livestock_17, County_livestock_12,County_livestock_17\n",
    "del area_map01, state_ANSI_map_01\n",
    "del County_census_livestock_17, County_livestock_12, County_livestock_17\n",
    "del animal_county_trend,animal_state_trend, county_array\n",
    "del State_total_animals_17, State_total_animals_12, State_temp, State_man_emi_animal, State_livestock_17, State_livestock_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#will need to save yearly emissions as intermediate output and read back in due to memory limits\n",
    "data_IO_fn.initialize_netCDF001(manure_int_out, netCDF_description, 1, year_range, loc_dimensions, lat001, lon001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Manure Gridding\n",
    "# Loop through each lat/lon value on the CONUS grid. County emissions are allocated based on the\n",
    "# fraction of proxy data in each grid cell relative to the sum of all proxy data in the gridcells\n",
    "# within the relevant county. \n",
    "# If the county does not have animal probability data, then the county emissions are allocated by area\n",
    "# Because this code takes a long time to run, the data are saved to a netCDF file after each calculated year\n",
    "\n",
    "Emissions_array_01 = np.zeros([len(Lat_01),len(Lon_01),num_years,num_months])\n",
    "Emissions_nongrid = np.zeros([num_years])\n",
    "\n",
    "print('**QA/QC Check: Sum of national gridded emissions vs. GHGI national emissions')\n",
    "running_sum = np.zeros([len(proxy_livestock_map),num_years])\n",
    "running_sum2 = np.zeros([len(proxy_livestock_map),num_years])\n",
    "\n",
    "#for iyear in np.arange(0,num_years):\n",
    "Emissions_array_001_temp = np.zeros([len(lat001),len(lon001),num_years,num_months])\n",
    "    \n",
    "for igroup in np.arange(0,len(proxy_livestock_map)):\n",
    "    #define the proxy and area arrays (there is only one gridding group)\n",
    "    # this code needs to be manually changed if more gridding groups are added in the future\n",
    "    proxy_temp = Map_animal_area_rank\n",
    "    proxy_temp_nongrid = Map_animal_area_rank_nongrid\n",
    "    proxy_temp_sum = Map_animal_area_rank_sum\n",
    "    area_map_sum = Area_sum\n",
    "   \n",
    "    for ilat in np.arange(0,len(lat001)):\n",
    "        for ilon in np.arange(0,len(lon001)):\n",
    "            if state_ANSI_map[ilat,ilon] > 0:\n",
    "                istate = np.where(State_ANSI['ansi']==state_ANSI_map[ilat,ilon])[0][0]\n",
    "                icounty = np.where((County_ANSI['State']==state_ANSI_map[ilat,ilon]) & \\\n",
    "                                    (County_ANSI['County']==county_ANSI_map[ilat,ilon]))[0][0]\n",
    "\n",
    "                for ianimal in np.arange(0,len(proxy_animal_array)):\n",
    "                        \n",
    "                    county_temp = vars()['County_'+proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']][ianimal,istate,icounty,:,:]\n",
    "                    if np.sum(county_temp) > 0:\n",
    "                        if proxy_temp_sum[ianimal,istate,icounty] >0: # if there is animal count data in the county, allocate by animal counts in grid cell relative to county sum\n",
    "                            weighted_array = data_fn.safe_div(proxy_temp[ianimal,ilat,ilon],\\\n",
    "                                                          proxy_temp_sum[ianimal,istate,icounty]) #counts at grid cell/counts in county\n",
    "                            for iyear in np.arange(0, num_years):\n",
    "                                Emissions_array_001_temp[ilat,ilon,iyear,:] += county_temp[iyear,:]*weighted_array\n",
    "                                running_sum[igroup,iyear] += np.sum(weighted_array*county_temp[iyear,:])\n",
    "                        elif proxy_temp_sum[ianimal,istate,icounty] == 0: # if no animal county data in county, use relative area as proxy\n",
    "                            #weight by county area\n",
    "                            weighted_array = data_fn.safe_div(area_map[ilat,ilon],\\\n",
    "                                                          area_map_sum[istate,icounty]) #counts at grid cell/counts in county\n",
    "                            for iyear in np.arange(0, num_years):\n",
    "                                Emissions_array_001_temp[ilat,ilon,iyear,:] += county_temp[iyear,:]*weighted_array\n",
    "                                running_sum2[igroup,iyear] += np.sum(weighted_array*county_temp[iyear,:])\n",
    "                                \n",
    "        print(ilat,running_sum[igroup,iyear])\n",
    "        print(ilat,running_sum2[igroup,iyear])\n",
    "    \n",
    "    #non-CONUS regions already filtered from the state_ANSI_map. Therefore, non-grid emissions\n",
    "    # have to be calcuated as the differences between national and CONUS emissions (not ideal as \n",
    "    # this is not an independent calcualtion of non-grid emissions)\n",
    "for iyear in np.arange(0, num_years):\n",
    "    county_sum = 0\n",
    "    for igroup in np.arange(0,len(proxy_livestock_map)):\n",
    "        county_sum += np.sum(vars()['County_'+proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']][:,:,:,iyear,:])\n",
    "    Emissions_nongrid[iyear] = county_sum-np.sum(Emissions_array_001_temp[:,:,iyear,:])\n",
    "    \n",
    "#    #Save annual data to netCDF\n",
    "#    #open netCDF to append, write data, and close\n",
    "#    nc_out = Dataset(manure_int_out, 'r+', format='NETCDF4')\n",
    "#    nc_out.variables['emi_ch4'][:,:,iyear,:] = Emissions_array_001_temp[:,:,:]\n",
    "#    nc_out.close()\n",
    "    \n",
    "#    print('Data Saved: iyear '+str(iyear+1)+' of '+str(num_years))\n",
    "#    # Print time\n",
    "#    ct = datetime.datetime.now() \n",
    "#    print(\"current time:\", ct) # Print time\n",
    "#    print(' ')\n",
    "#    print(np.sum(Emissions_array_001_temp[:,:,:]))\n",
    "\n",
    "for igroup in np.arange(0, len(proxy_livestock_map)):\n",
    "    vars()['Ext_'+proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']] = np.zeros([len(Lat_01),len(Lon_01),num_years])\n",
    "\n",
    "    \n",
    "for iyear in np.arange(0, num_years):  \n",
    "    for imonth in np.arange(0,num_months):\n",
    "        Emissions_array_01[:,:,iyear,imonth] = data_fn.regrid001_to_01(Emissions_array_001_temp[:,:,iyear,imonth], Lat_01, Lon_01)\n",
    "    calc_emi = np.sum(Emissions_array_01[:,:,iyear]) + np.sum(Emissions_nongrid[iyear]) \n",
    "    calc_emi2 = 0\n",
    "    #Note - there is only one gridding group - so to save memory space, assign group emissions to total emissions array\n",
    "    vars()['Ext_'+proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']][:,:,iyear] = np.sum(Emissions_array_01[:,:,iyear,:], axis=2)\n",
    "    calc_emi2 += np.sum(vars()['Ext_'+proxy_livestock_map.loc[igroup,'GHGI_Emi_Group']][:,:,iyear])\n",
    "    calc_emi2 += np.sum(Emissions_nongrid[iyear]) \n",
    "    summary_emi = EPA_emi_man_CH4.iloc[0,iyear+1]  \n",
    "    emi_diff = abs(summary_emi-calc_emi)/((summary_emi+calc_emi)/2)\n",
    "    if DEBUG ==1:\n",
    "        print(summary_emi)\n",
    "        print(calc_emi)\n",
    "        print(calc_emi2)\n",
    "    diff = abs(summary_emi-calc_emi)/((summary_emi+calc_emi)/2)\n",
    "    if diff < 0.0001:\n",
    "        print('Year ', year_range[iyear], ': PASS, difference < 0.01%')\n",
    "    else:\n",
    "        print('Year ', year_range[iyear], ': FAIL -- Difference = ', diff*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4.1.4 Save gridded emissions (kt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save gridded emissions for each gridding group - for extension\n",
    "\n",
    "#Initialize file\n",
    "data_IO_fn.initialize_netCDF(grid_emi_outputfile, netCDF_description, 0, year_range, loc_dimensions, Lat_01, Lon_01)\n",
    "\n",
    "unique_groups = np.unique(proxy_livestock_map['GHGI_Emi_Group'])\n",
    "unique_groups = unique_groups[unique_groups != 'Emi_not_mapped']\n",
    "\n",
    "nc_out = Dataset(grid_emi_outputfile, 'r+', format='NETCDF4')\n",
    "\n",
    "for igroup in np.arange(0,len(unique_groups)):\n",
    "    print('Ext_'+unique_groups[igroup])\n",
    "    if len(np.shape(vars()['Ext_'+unique_groups[igroup]])) ==4:\n",
    "        ghgi_temp = np.sum(vars()[unique_groups[igroup]],axis=3) #sum month data if data is monthly\n",
    "    else:\n",
    "        ghgi_temp = vars()['Ext_'+unique_groups[igroup]]\n",
    "\n",
    "    # Write data to netCDF\n",
    "    data_out = nc_out.createVariable('Ext_'+unique_groups[igroup], 'f8', ('lat', 'lon','year'), zlib=True)\n",
    "    data_out[:,:,:] = ghgi_temp[:,:,:]\n",
    "\n",
    "#save nongrid data to calculate non-grid fraction extension\n",
    "data_out = nc_out.createVariable('Emissions_nongrid', 'f8', ('year'), zlib=True)  \n",
    "data_out[:] = Emissions_nongrid[:]\n",
    "nc_out.close()\n",
    "\n",
    "#Confirm file location\n",
    "print('** SUCCESS **')\n",
    "print(\"Gridded emissions (kt) written to file: {}\" .format(os.getcwd())+grid_emi_outputfile)\n",
    "print(' ')\n",
    "\n",
    "del data_out, ghgi_temp, nc_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2. Calculate Gridded Emission Fluxes (molec./cm2/s) (0.1x0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert emissions to emission flux\n",
    "# conversion: kt emissions to molec/cm2/s flux\n",
    "\n",
    "DEBUG = 1\n",
    "\n",
    "Flux_array_01 = np.zeros([len(Lat_01),len(Lon_01),num_years,num_months])\n",
    "Flux_array_01_annual = np.zeros([len(Lat_01),len(Lon_01),num_years])\n",
    "check_sum = np.zeros([num_years])\n",
    "check_sum_annual = np.zeros([num_years])\n",
    "\n",
    "print('**QA/QC Check: Sum of national gridded emissions vs. GHGI national emissions')\n",
    "  \n",
    "for iyear in np.arange(0,num_years):\n",
    "    if year_range[iyear]==2012 or year_range[iyear]==2016:\n",
    "        year_days = np.sum(month_day_leap)\n",
    "        month_days = month_day_leap\n",
    "    else:\n",
    "        year_days = np.sum(month_day_nonleap)\n",
    "        month_days = month_day_nonleap\n",
    "        \n",
    "    # calculate fluxes for each emissions group and national sum  (=kt * grams/kt *molec/mol *mol/g *s^-1 * cm^-2)\n",
    "    conversion_factor_annual = 10**9 * Avogadro / float(Molarch4 * np.sum(month_days) * 24 * 60 *60) / area_matrix_01\n",
    "    \n",
    "    #if proxy_livestock_map.loc[igroup, 'Month_Flag'] == 1:\n",
    "    for imonth in np.arange(0,num_months):\n",
    "        conversion_factor_month = 10**9 * Avogadro / float(Molarch4 * month_days[imonth] * 24 * 60 *60) / area_matrix_01\n",
    "        conv_factor2 = month_days[imonth]/year_days\n",
    "        Flux_array_01[:,:,iyear,imonth] = Emissions_array_01[:,:,iyear,imonth] * conversion_factor_month\n",
    "        Flux_array_01_annual[:,:,iyear] += Flux_array_01[:,:,iyear,imonth]*conv_factor2        \n",
    "        #calculate the monthly running flux totals and convert from flux back to mass (also calc annual sum)    \n",
    "        check_sum[iyear] += np.sum(Flux_array_01[:,:,iyear,imonth]/conversion_factor_month)\n",
    "    check_sum_annual[iyear] += np.sum(Flux_array_01_annual[:,:,iyear]/conversion_factor_annual)\n",
    "        \n",
    "    #convert back to mass to check\n",
    "    calc_emi = check_sum_annual[iyear] +np.sum(Emissions_nongrid[iyear]) \n",
    "    calc_emi2 = check_sum[iyear] +np.sum(Emissions_nongrid[iyear]) \n",
    "    \n",
    "    summary_emi = EPA_emi_man_CH4.iloc[0,iyear+1] \n",
    "    emi_diff = abs(summary_emi-calc_emi)/((summary_emi+calc_emi)/2)\n",
    "    if DEBUG ==1:\n",
    "        print(calc_emi)\n",
    "        print(calc_emi2)\n",
    "        print(summary_emi)\n",
    "    if abs(emi_diff) < 0.00025:\n",
    "        print('Year '+ year_range_str[iyear]+': Difference < 0.025%: PASS')\n",
    "    else: \n",
    "        print('Year '+ year_range_str[iyear]+': Difference > 0.025%: FAIL, diff: '+str(emi_diff))\n",
    "        \n",
    "Flux_Emissions_Total_annual = Flux_array_01_annual\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "## Step 5. Write netCDF\n",
    "------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# monthly data\n",
    "#Initialize file\n",
    "data_IO_fn.initialize_netCDF(gridded_month_outputfile, netCDF_description_m, 1, year_range, loc_dimensions, Lat_01, Lon_01)\n",
    "\n",
    "# Write data to netCDF\n",
    "nc_out = Dataset(gridded_month_outputfile, 'r+', format='NETCDF4')\n",
    "nc_out.variables['emi_ch4'][:,:,:,:] = Flux_array_01\n",
    "nc_out.close()\n",
    "#Confirm file location\n",
    "print('** SUCCESS **')\n",
    "print(\"Gridded fluxes written to file: {}\" .format(os.getcwd())+gridded_month_outputfile)\n",
    "\n",
    "# yearly data\n",
    "#Initialize file\n",
    "data_IO_fn.initialize_netCDF(gridded_outputfile, netCDF_description, 0, year_range, loc_dimensions, Lat_01, Lon_01)\n",
    "\n",
    "# Write data to netCDF\n",
    "nc_out = Dataset(gridded_outputfile, 'r+', format='NETCDF4')\n",
    "nc_out.variables['emi_ch4'][:,:,:] = Flux_Emissions_Total_annual\n",
    "nc_out.close()\n",
    "#Confirm file location\n",
    "print('** SUCCESS **')\n",
    "print(\"Gridded fluxes written to file: {}\" .format(os.getcwd())+gridded_outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "## Step 6. Plot Gridded Data\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6.1. Plot Annual Emission Fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plot Annual Data\n",
    "scale_max = 10\n",
    "save_flag =0\n",
    "save_outfile = ''\n",
    "data_plot_fn.plot_annual_emission_flux_map(Flux_Emissions_Total_annual, Lat_01, Lon_01, year_range, title_str,scale_max,save_flag,save_outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6.2 Plot Difference between first and last inventory year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot difference between last and first year\n",
    "save_flag =0\n",
    "save_outfile = ''\n",
    "data_plot_fn.plot_diff_emission_flux_map(Flux_Emissions_Total_annual, Lat_01, Lon_01, year_range, title_diff_str,save_flag, save_outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = datetime.datetime.now() \n",
    "ft = ct.timestamp() \n",
    "time_elapsed = (ft-it)/(60*60)\n",
    "print('Time to run: '+str(time_elapsed)+' hours')\n",
    "print('** GEPA_3B_Livestock_Manure: COMPLETE **')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
