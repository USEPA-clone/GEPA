{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridded EPA Methane Inventory\n",
    "## Category: 1B2b Natural Gas Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### Authors: \n",
    "Joannes D. Maasakkers, Candice F. Z. Chen, Erin E. McDuffie\n",
    "#### Date Last Updated: \n",
    "See Step 0\n",
    "#### Notebook Purpose: \n",
    "This Notebook calculates and reports annual gridded (0.1⁰x0.1⁰) methane emission fluxes (molec./cm2/s) from natural gas systems distribution segment in the CONUS region between 2012-2018. \n",
    "#### Summary & Notes:\n",
    "EPA GHGI gas distribution emissions are read in from the GHGI Natural Gas Systems workbook at the national level. Emissions are first allocated to the state level as a function of emission group. The activity/proxy data used to allocate emissions from each group include Pipeline and Hazardous materials Safety Administration (PHMSA) distribution main pipeline mileage (by material) and service counts, as well as metering station counts from GHGRP and EIA customer meters. State-level emissions are then spatially distributed onto a 0.01x0.01 degree grid based on population density. Emissions are regridded to a 0.1x0.1 degree grid and converted to emission flux. Annual emission fluxes (molec./cm2/s) are written to final netCDFs in the ‘/code/Final_Gridded_Data/’ folder. \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "## Step 0. Set-Up Notebook Modules, Functions, and Local Parameters and Constants\n",
    "_____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirm working directory\n",
    "import os\n",
    "import time\n",
    "modtime = os.path.getmtime('./1B2b_Distribution.ipynb')\n",
    "modificationTime = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(modtime))\n",
    "print(\"This file was last modified on: \", modificationTime)\n",
    "print('')\n",
    "print(\"The directory we are working in is {}\" .format(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Include plots within notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import base modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import datetime\n",
    "from copy import copy\n",
    "\n",
    "# Import additional modules\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "# Load netCDF (for manipulating netCDF file types)\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "# Set up ticker\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "#add path for the global function module (file)\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../Global_Functions/'))\n",
    "#print(module_path)\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# Load functions\n",
    "import data_load_functions as data_load_fn\n",
    "import data_functions as data_fn\n",
    "import data_IO_functions as data_IO_fn\n",
    "import data_plot_functions as data_plot_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INPUT Files\n",
    "# Assign global file names\n",
    "global_filenames = data_load_fn.load_global_file_names()\n",
    "State_ANSI_inputfile = global_filenames[0]\n",
    "#County_ANSI_inputfile = global_filenames[1]\n",
    "pop_map_inputfile = global_filenames[2]\n",
    "Grid_area01_inputfile = global_filenames[3]\n",
    "Grid_area001_inputfile = global_filenames[4]\n",
    "Grid_state001_ansi_inputfile = global_filenames[5]\n",
    "#Grid_county001_ansi_inputfile = global_filenames[6]\n",
    "globalinputlocation = global_filenames[0][0:20]\n",
    "print(globalinputlocation)\n",
    "\n",
    "# Specify names of inputs files used in this notebook\n",
    "EPA_NG_inputfile = globalinputlocation+'GHGI/Ch3_Energy/NaturalGasSystems_1990-2018_GHGI_2020-04-11.xlsx'\n",
    "\n",
    "#proxy mapping file\n",
    "NG_Mapping_inputfile = './InputData/NaturalGas_Distribution_ProxyMapping.xlsx'\n",
    "\n",
    "#Activity Data\n",
    "PHMSA_inputfile = './InputData/annual_gas_distr.csv'\n",
    "EIA_Residential_CC_inputfile = './InputData/EIA_CustomerCounts/NG_CONS_NUM_A_EPG0_VN3_COUNT_A.xls'\n",
    "EIA_Commercial_CC_inputfile = './InputData/EIA_CustomerCounts/NG_CONS_NUM_A_EPG0_VN5_COUNT_A.xls'\n",
    "EIA_Industrial_CC_inputfile = './InputData/EIA_CustomerCounts/NG_CONS_NUM_A_EPG0_VN7_COUNT_A.xls'\n",
    "\n",
    "phmsa_gas_distr_2012_inputfile = './InputData/PHMSA_annual_gas_distribution_2012.csv'\n",
    "\n",
    "#GHGRP Data (reporting format changed in 2015)\n",
    "GHGRP_facility_inputfile = './InputData/ghgrp_facility_info.CSV'\n",
    "ghgrp_distr_2014_inputfile = './InputData/metering-2014.CSV' # pipeline mileage and above and below ground metering and serivce stations\n",
    "ghgrp_distr_meteringbelow_2018_inputfile = './InputData/metering-2018.CSV' #pipeline mileage and below-grade station equipent counts\n",
    "ghgrp_distr_meteringabove_2018_inputfile = './InputData/metering_above-2018.CSV' #above-grade station counts\n",
    "\n",
    "#OUTPUT FILES\n",
    "gridded_outputfile = '../Final_Gridded_Data/EPA_v2_1B2b_Natural_Gas_Distribution.nc'\n",
    "netCDF_description = 'Gridded EPA Inventory - Natural Gas Systems Emissions - IPCC Source Category 1B2b - Distribution'\n",
    "title_str = \"EPA methane emissions from gas distribution\"\n",
    "title_diff_str = \"Emissions from gas distribution difference: 2018-2012\"\n",
    "\n",
    "#output gridded proxy data\n",
    "grid_emi_outputfile = '../Final_Gridded_Data/Extension/v2_input_data/NG_Distribution_Grid_Emi.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define local variables\n",
    "start_year = 2012  #First year in emission timeseries\n",
    "end_year = 2018    #Last year in emission timeseries\n",
    "year_range = [*range(start_year, end_year+1,1)] #List of emission years\n",
    "year_range_str=[str(i) for i in year_range]\n",
    "num_years = len(year_range)\n",
    "\n",
    "# Define constants\n",
    "Avogadro   = 6.02214129 * 10**(23)  #molecules/mol\n",
    "Molarch4   = 16.04                  #g/mol\n",
    "Res01      = 0.1                    # degrees\n",
    "\n",
    "# Continental US Lat/Lon Limits (for netCDF files)\n",
    "Lon_left = -130       #deg\n",
    "Lon_right = -60       #deg\n",
    "Lat_low  = 20         #deg\n",
    "Lat_up  = 55          #deg\n",
    "loc_dimensions = [Lat_low, Lat_up, Lon_left, Lon_right]\n",
    "\n",
    "ilat_start = int((90+Lat_low)/Res01) #1100:1450 (continental US range)\n",
    "ilat_end = int((90+Lat_up)/Res01)\n",
    "ilon_start = abs(int((-180-Lon_left)/Res01)) #500:1200 (continental US range)\n",
    "ilon_end = abs(int((-180-Lon_right)/Res01))\n",
    "\n",
    "# Number of days in each month\n",
    "month_day_leap  = [  31,  29,  31,  30,  31,  30,  31,  31,  30,  31,  30,  31]\n",
    "month_day_nonleap = [  31,  28,  31,  30,  31,  30,  31,  31,  30,  31,  30,  31]\n",
    "month_tag = ['01','02','03','04','05','06','07','08','09','10','11','12']\n",
    "month_dict = {'January':1, 'February':2,'March':3,'April':4,'May':5,'June':6, 'July':7,'August':8,'September':9,'October':10,\\\n",
    "             'November':11,'December':12}\n",
    "\n",
    "# Month arrays\n",
    "month_range_str = ['January','February','March','April','May','June','July','August','September','October','November','December']\n",
    "num_months = len(month_range_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.auto_scroll_threshold = 9999;\n",
    "//prevent auto-scrolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track run time\n",
    "ct = datetime.datetime.now() \n",
    "it = ct.timestamp() \n",
    "print(\"current time:\", ct) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "## Step 1. Load in State ANSI data and Area\n",
    "_____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State-level ANSI Data\n",
    "#Read the state ANSI file array\n",
    "State_ANSI, name_dict = data_load_fn.load_state_ansi(State_ANSI_inputfile)[0:2]\n",
    "#QA: number of states\n",
    "print('Read input file: '+ f\"{State_ANSI_inputfile}\")\n",
    "print('Total \"States\" found: ' + '%.0f' % len(State_ANSI))\n",
    "print(' ')\n",
    "\n",
    "# 0.01 x0.01 degree Data\n",
    "# State ANSI IDs and grid cell area (m2) maps\n",
    "state_ANSI_map = data_load_fn.load_state_ansi_map(Grid_state001_ansi_inputfile)\n",
    "area_map, lat001, lon001 = data_load_fn.load_area_map_001(Grid_area001_inputfile)\n",
    "\n",
    "# 0.1 x0.1 degree data\n",
    "# grid cell area and state ANSI maps\n",
    "Lat01, Lon01 = data_load_fn.load_area_map_01(Grid_area01_inputfile)[1:3]\n",
    "#Select relevant Continental 0.1 x0.1 domain\n",
    "Lat_01 = Lat01[ilat_start:ilat_end]\n",
    "Lon_01 = Lon01[ilon_start:ilon_end]\n",
    "area_matrix_01 = data_fn.regrid001_to_01(area_map, Lat_01, Lon_01)\n",
    "area_matrix_01 *= 10000  #convert from m2 to cm2\n",
    "state_ANSI_map_01 = data_fn.regrid001_to_01(state_ANSI_map, Lat_01, Lon_01)\n",
    "del lat001, lon001\n",
    "\n",
    "# Print time\n",
    "ct = datetime.datetime.now() \n",
    "print(\"current time:\", ct) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "## Step 2: Read in and Format Proxy Data\n",
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.1 Read In Proxy Mapping File & Make Proxy Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.1.1 Format Proxy Group Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load GHGI Mapping Groups\n",
    "names = pd.read_excel(NG_Mapping_inputfile, sheet_name = \"GHGI Map - Dist\", usecols = \"A:B\",skiprows = 1, header = 0)\n",
    "colnames = names.columns.values\n",
    "ghgi_dist_map = pd.read_excel(NG_Mapping_inputfile, sheet_name = \"GHGI Map - Dist\", usecols = \"A:B\", skiprows = 2, names = colnames)\n",
    "#drop rows with no data, remove the parentheses and \"\"\n",
    "ghgi_dist_map = ghgi_dist_map[ghgi_dist_map['GHGI_Emi_Group'] != 'na']\n",
    "ghgi_dist_map = ghgi_dist_map[ghgi_dist_map['GHGI_Emi_Group'].notna()]\n",
    "ghgi_dist_map = ghgi_dist_map[ghgi_dist_map['GHGI_Emi_Group'] != '-']\n",
    "ghgi_dist_map['GHGI_Source']= ghgi_dist_map['GHGI_Source'].str.replace(r\"\\(\",\"\")\n",
    "ghgi_dist_map['GHGI_Source']= ghgi_dist_map['GHGI_Source'].str.replace(r\"\\)\",\"\")\n",
    "ghgi_dist_map.reset_index(inplace=True, drop=True)\n",
    "display(ghgi_dist_map)\n",
    "\n",
    "#load emission group - proxy map\n",
    "names = pd.read_excel(NG_Mapping_inputfile, sheet_name = \"Proxy Map - Dist\", usecols = \"A:D\",skiprows = 1, header = 0)\n",
    "colnames = names.columns.values\n",
    "proxy_dist_map = pd.read_excel(NG_Mapping_inputfile, sheet_name = \"Proxy Map - Dist\", usecols = \"A:D\", skiprows = 1, names = colnames)\n",
    "display((proxy_dist_map))\n",
    "\n",
    "#create empty proxy and emission group arrays (add months for proxy variables that have monthly data)\n",
    "for igroup in np.arange(0,len(proxy_dist_map)):\n",
    "        vars()[proxy_dist_map.loc[igroup,'Proxy_Group']] = np.zeros((len(State_ANSI),num_years))\n",
    "        vars()[proxy_dist_map.loc[igroup,'Proxy_Group']+'_nongrid'] = np.zeros([num_years])\n",
    "        vars()[proxy_dist_map.loc[igroup,'GHGI_Emi_Group']] = np.zeros([num_years])\n",
    "        if proxy_dist_map.loc[igroup,'State_Proxy_Group'] != '-':\n",
    "            vars()[proxy_dist_map.loc[igroup,'State_Proxy_Group']] = np.zeros([len(State_ANSI),num_years])\n",
    "            \n",
    "emi_group_names = np.unique(ghgi_dist_map['GHGI_Emi_Group'])\n",
    "print('QA/QC: Is the number of emission groups the same for the proxy and emissions tabs?')\n",
    "if (len(emi_group_names) == len(np.unique(proxy_dist_map['GHGI_Emi_Group']))):\n",
    "    print('PASS')\n",
    "else:\n",
    "    print('FAIL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.2 - Read in 0.01x0.01 State population data and format State_ANSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read population maps\n",
    "\n",
    "#Read population map\n",
    "pop_den_map = data_load_fn.load_pop_den_map(pop_map_inputfile)\n",
    "\n",
    "# Calculate the population totals per state (will only include continental US)\n",
    "# Population totals for each state = the sum of the grid cell product of the population density in each state * the area of each state\n",
    "\n",
    "State_ANSI['Population'] = 0.0\n",
    "\n",
    "for istate in np.arange(len(State_ANSI)):\n",
    "    State_ANSI.loc[istate, 'Population'] = np.sum(pop_den_map[state_ANSI_map == State_ANSI['ansi'][istate]]*area_map[state_ANSI_map == State_ANSI['ansi'][istate]])\n",
    "\n",
    "# Check that state-level population array is correct\n",
    "print('QA/QC: Check State-level populations are correct')\n",
    "if abs((np.sum(pop_den_map[state_ANSI_map != 0]*area_map[state_ANSI_map != 0]) - np.sum(State_ANSI['Population']))/float(np.sum(pop_den_map[state_ANSI_map != 0]*area_map[state_ANSI_map != 0]))) <1e-2:\n",
    "    print('PASS')\n",
    "else:\n",
    "    print('FAIL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.3 Read In PHMSA Pipeline Mileage and Services Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read company level PHMSA data\n",
    "PHMSA_facilities = pd.read_csv(PHMSA_inputfile, sep=',',low_memory=False)\n",
    "\n",
    "# make new array of PHMSA pipeline miles data\n",
    "PHMSA_facilities['REPORT_YEAR'] = PHMSA_facilities['REPORT_YEAR'].astype(int)\n",
    "PHMSA_facilities['MMILES_CI'] = PHMSA_facilities['MMILES_CI'].astype(float)\n",
    "PHMSA_facilities['MMILES_STEEL_UNP_BARE'] = PHMSA_facilities['MMILES_STEEL_UNP_BARE'].astype(float)\n",
    "PHMSA_facilities['MMILES_STEEL_UNP_COATED'] = PHMSA_facilities['MMILES_STEEL_UNP_COATED'].astype(float)\n",
    "PHMSA_facilities['MMILES_STEEL_CP_BARE'] = PHMSA_facilities['MMILES_STEEL_CP_BARE'].astype(float)\n",
    "PHMSA_facilities['MMILES_STEEL_CP_COATED'] = PHMSA_facilities['MMILES_STEEL_CP_COATED'].astype(float)\n",
    "PHMSA_facilities['MMILES_PLASTIC'] = PHMSA_facilities['MMILES_PLASTIC'].astype(float)\n",
    "PHMSA_facilities['NUM_SRVS_STEEL_UNP_BARE'] = PHMSA_facilities['NUM_SRVS_STEEL_UNP_BARE'].astype(float)\n",
    "PHMSA_facilities['NUM_SRVS_STEEL_UNP_COATED'] = PHMSA_facilities['NUM_SRVS_STEEL_UNP_COATED'].astype(float)\n",
    "PHMSA_facilities['NUM_SRVS_STEEL_CP_BARE'] = PHMSA_facilities['NUM_SRVS_STEEL_CP_BARE'].astype(float)\n",
    "PHMSA_facilities['NUM_SRVS_STEEL_CP_COATED'] = PHMSA_facilities['NUM_SRVS_STEEL_CP_COATED'].astype(float)\n",
    "PHMSA_facilities['NUM_SRVS_PLASTIC'] = PHMSA_facilities['NUM_SRVS_PLASTIC'].astype(float)\n",
    "PHMSA_facilities['NUM_SRVS_CU'] = PHMSA_facilities['NUM_SRVS_CU'].astype(float)\n",
    "\n",
    "# Format Pipeline Mileage Data\n",
    "# Create arrays to hold main and service mileages with dimensions (state X year)\n",
    "main_castiron = np.zeros((len(State_ANSI),num_years))\n",
    "main_usteel = np.zeros((len(State_ANSI),num_years))\n",
    "main_psteel = np.zeros((len(State_ANSI),num_years))\n",
    "main_plastic = np.zeros((len(State_ANSI),num_years))\n",
    "\n",
    "serv_usteel = np.zeros((len(State_ANSI),num_years))\n",
    "serv_psteel = np.zeros((len(State_ANSI),num_years))\n",
    "serv_plastic = np.zeros((len(State_ANSI),num_years))\n",
    "serv_copper = np.zeros((len(State_ANSI),num_years))\n",
    "\n",
    "# for each year, sum all the mileage data across all piepline and service types\n",
    "# (e.g., cast iron, unprotected steel, etc.), then group the facility level data by state\n",
    "for iyear in np.arange(num_years):\n",
    "\n",
    "    mcastiron_temp = PHMSA_facilities[PHMSA_facilities['REPORT_YEAR'] == iyear+start_year]['MMILES_CI'].values\n",
    "    musteel_temp = PHMSA_facilities[PHMSA_facilities['REPORT_YEAR'] == iyear+start_year]['MMILES_STEEL_UNP_BARE'].values + PHMSA_facilities[PHMSA_facilities['REPORT_YEAR'] == iyear+start_year]['MMILES_STEEL_UNP_COATED'].values\n",
    "    mpsteel_temp = PHMSA_facilities[PHMSA_facilities['REPORT_YEAR'] == iyear+start_year]['MMILES_STEEL_CP_BARE'].values + PHMSA_facilities[PHMSA_facilities['REPORT_YEAR'] == iyear+start_year]['MMILES_STEEL_CP_COATED'].values\n",
    "    mplastic_temp = PHMSA_facilities[PHMSA_facilities['REPORT_YEAR'] == iyear+start_year]['MMILES_PLASTIC'].values\n",
    "    \n",
    "    # Print data\n",
    "    print('Total mileage '+str(iyear+start_year)+':') \n",
    "    print('Cast Iron: ', np.sum(mcastiron_temp))\n",
    "    print('Unprotected steel: ', np.sum(musteel_temp))\n",
    "    print('Protected steel: ', np.sum(mpsteel_temp))\n",
    "    print('Plastic: ', np.sum(mplastic_temp))         \n",
    "    print(' ')\n",
    "    \n",
    "    susteel_temp = PHMSA_facilities[PHMSA_facilities['REPORT_YEAR'] == iyear+start_year]['NUM_SRVS_STEEL_UNP_BARE'].values + PHMSA_facilities[PHMSA_facilities['REPORT_YEAR'] == iyear+start_year]['NUM_SRVS_STEEL_UNP_COATED'].values\n",
    "    spsteel_temp = PHMSA_facilities[PHMSA_facilities['REPORT_YEAR'] == iyear+start_year]['NUM_SRVS_STEEL_CP_BARE'].values + PHMSA_facilities[PHMSA_facilities['REPORT_YEAR'] == iyear+start_year]['NUM_SRVS_STEEL_CP_COATED'].values\n",
    "    splastic_temp = PHMSA_facilities[PHMSA_facilities['REPORT_YEAR'] == iyear+start_year]['NUM_SRVS_PLASTIC'].values\n",
    "    scopper_temp = PHMSA_facilities[PHMSA_facilities['REPORT_YEAR'] == iyear+start_year]['NUM_SRVS_CU'].values\n",
    "          \n",
    "    # Print data\n",
    "    print('Services '+str(iyear+start_year)+':')\n",
    "    print('Unprotected steel: ', np.sum(susteel_temp))\n",
    "    print('Protected steel: ', np.sum(spsteel_temp))\n",
    "    print('Plastic: ', np.sum(splastic_temp))\n",
    "    print('Copper: ', np.sum(scopper_temp))\n",
    "    print(' ')\n",
    "        \n",
    "    # get state for each PHMSA facilities\n",
    "    PHMSA_facilities_temp = PHMSA_facilities[PHMSA_facilities['REPORT_YEAR'] == iyear+start_year]\n",
    "    PHMSA_facilities_temp.reset_index(drop=True,inplace=True)\n",
    "\n",
    "    # Calculate the mileage and services for each state\n",
    "    for ifacility in np.arange(len(PHMSA_facilities[PHMSA_facilities['REPORT_YEAR'] == iyear+start_year])):\n",
    "        match_state = np.where(State_ANSI['abbr'] == PHMSA_facilities_temp['STOP'][ifacility])[0][0]\n",
    "        #print(State_ANSI['abbr'][match_state]+', '+str(match_state))\n",
    "        \n",
    "        #Add mileage\n",
    "        main_castiron[match_state][iyear] += mcastiron_temp[ifacility]\n",
    "        main_usteel[match_state][iyear] += musteel_temp[ifacility]\n",
    "        main_psteel[match_state][iyear] += mpsteel_temp[ifacility]\n",
    "        main_plastic[match_state][iyear] += mplastic_temp[ifacility]\n",
    "\n",
    "        #Add services\n",
    "        serv_usteel[match_state][iyear] += susteel_temp[ifacility]\n",
    "        serv_psteel[match_state][iyear] += spsteel_temp[ifacility]\n",
    "        serv_plastic[match_state][iyear] += splastic_temp[ifacility]\n",
    "        serv_copper[match_state][iyear] += scopper_temp[ifacility]\n",
    "        \n",
    "# Calculate PHMSA mains total \n",
    "PHMSA_mains_total = main_castiron + main_usteel + main_psteel + main_plastic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.4 Read In State-Level EIA Customer Counts Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read company level EIA data, but only load the totals for all companies across each state\n",
    "EIA_ResCounts = pd.read_excel(EIA_Residential_CC_inputfile, sheet_name = 'Data 1', skiprows=2)\n",
    "EIA_ComCounts = pd.read_excel(EIA_Commercial_CC_inputfile, sheet_name = 'Data 1', skiprows=2)\n",
    "EIA_IndCounts = pd.read_excel(EIA_Industrial_CC_inputfile, sheet_name = 'Data 1', skiprows=2)\n",
    "\n",
    "#convert the time stamp to year\n",
    "EIA_ResCounts['Date'] = EIA_ResCounts['Date'].astype(str)\n",
    "EIA_ComCounts['Date'] = EIA_ComCounts['Date'].astype(str)\n",
    "EIA_IndCounts['Date'] = EIA_IndCounts['Date'].astype(str)\n",
    "EIA_ResCounts['Date'] = [EIA_ResCounts['Date'][i][0:4] for i in np.arange(len(EIA_ResCounts))]   #extract the year\n",
    "EIA_ComCounts['Date'] = [EIA_ComCounts['Date'][i][0:4] for i in np.arange(len(EIA_ComCounts))]   #extract the year\n",
    "EIA_IndCounts['Date'] = [EIA_IndCounts['Date'][i][0:4] for i in np.arange(len(EIA_IndCounts))]   #extract the year\n",
    "#transpose and reset the column and row indexes\n",
    "EIA_ResCounts = EIA_ResCounts.T\n",
    "EIA_ComCounts = EIA_ComCounts.T\n",
    "EIA_IndCounts = EIA_IndCounts.T\n",
    "EIA_ResCounts.columns = EIA_ResCounts.iloc[0]\n",
    "EIA_ComCounts.columns = EIA_ComCounts.iloc[0]\n",
    "EIA_IndCounts.columns = EIA_IndCounts.iloc[0]\n",
    "EIA_ResCounts = EIA_ResCounts.drop(EIA_ResCounts.index[[0,1]])\n",
    "EIA_ComCounts = EIA_ComCounts.drop(EIA_ComCounts.index[[0,1]])\n",
    "EIA_IndCounts = EIA_IndCounts.drop(EIA_IndCounts.index[[0,1]])\n",
    "#extract the state names and format as abbreviations\n",
    "Names_res = EIA_ResCounts.index.values.tolist()\n",
    "Names_com = EIA_ComCounts.index.values.tolist()\n",
    "Names_ind = EIA_IndCounts.index.values.tolist()\n",
    "EIA_ResCounts.reset_index(drop=True,inplace=True)\n",
    "EIA_ComCounts.reset_index(drop=True,inplace=True)\n",
    "EIA_IndCounts.reset_index(drop=True,inplace=True)\n",
    "EIA_ResCounts['State'] = Names_res\n",
    "EIA_ComCounts['State'] = Names_com\n",
    "EIA_IndCounts['State'] = Names_ind\n",
    "    \n",
    "for istate in np.arange(0,len(State_ANSI)-6): #### -6\n",
    "    #print(State_ANSI['name'][istate])\n",
    "    match_state = np.where(EIA_ResCounts['State'].str.contains(State_ANSI['name'][istate]))[0][0]\n",
    "    EIA_ResCounts['State'][match_state] = State_ANSI['abbr'][istate]\n",
    "    #print(match_state)\n",
    "    match_state = np.where(EIA_ComCounts['State'].str.contains(State_ANSI['name'][istate]))[0][0]\n",
    "    EIA_ComCounts['State'][match_state] = State_ANSI['abbr'][istate]\n",
    "    #print(match_state)\n",
    "    if State_ANSI['name'][istate]=='District of Columbia':\n",
    "        #print(len(EIA_IndCounts.loc[0]))\n",
    "        EIA_IndCounts.loc[-1] = np.zeros([len(EIA_IndCounts.loc[0])])\n",
    "        EIA_IndCounts.index = EIA_IndCounts.index+1\n",
    "        EIA_IndCounts = EIA_IndCounts.sort_index()\n",
    "        EIA_IndCounts['State'][0] = State_ANSI['abbr'][istate]\n",
    "        #print(EIA_IndCounts.head(20))\n",
    "    else:\n",
    "        match_state = np.where(EIA_IndCounts['State'].str.contains(State_ANSI['name'][istate]))[0][0]\n",
    "        EIA_IndCounts['State'][match_state] = State_ANSI['abbr'][istate]\n",
    "\n",
    "# Initialize state array of leak losses (State X year) \n",
    "res_counts = np.zeros((len(State_ANSI),num_years))\n",
    "indcom_counts = np.zeros((len(State_ANSI),num_years))\n",
    "#ind_counts = np.zeros((len(State_ANSI),num_years))\n",
    "\n",
    "# To this array, add ANSI value for each state, then for each year,\n",
    "# make a new leakvolume array that records the yearly state-level leak loss volume data\n",
    "# Data only extend back to 1997, so use 1997 values for years 1990-1996\n",
    "\n",
    "for ifacility in np.arange(0,len(EIA_ResCounts)):\n",
    "    match_state1 = np.where(State_ANSI['abbr'] == EIA_ResCounts['State'][ifacility])[0][0]\n",
    "    match_state2 = np.where(State_ANSI['abbr'] == EIA_ComCounts['State'][ifacility])[0][0]\n",
    "    match_state3 = np.where(State_ANSI['abbr'] == EIA_IndCounts['State'][ifacility])[0][0]\n",
    "\n",
    "    for iyear in np.arange(num_years):\n",
    "        res_counts[match_state1][iyear] += EIA_ResCounts[str(iyear+start_year)][ifacility]\n",
    "        indcom_counts[match_state2][iyear] += EIA_ComCounts[str(iyear+start_year)][ifacility]\n",
    "        indcom_counts[match_state3][iyear] += EIA_IndCounts[str(iyear+start_year)][ifacility]\n",
    "\n",
    "# Fill in data gaps (interpolate to fill zeros between years and extend most historical value back to 1990)\n",
    "res_counts = np.nan_to_num(res_counts)\n",
    "indcom_counts = np.nan_to_num(indcom_counts)\n",
    "\n",
    "\n",
    "for iyear in np.arange(0,num_years):\n",
    "    print(year_range_str[iyear]+' Total Counts: ')\n",
    "    print(' Residential Customers: '+str(res_counts.sum(axis=0)[iyear]))\n",
    "    print(' Commercial Customers: '+str(indcom_counts.sum(axis=0)[iyear]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 Read in and Format GHGRP Metering Station Counts and Pipeline Mileage Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2.5.1 Read in and Format GHGRP Facility Level Data\n",
    "Note: GHGRP reporting format changed in 2015. Current code uses data from the most recent year (2018) and the year before the reporting change (2014). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in and Format GHGRP facility-level information by State\n",
    "\n",
    "#a) Read in the GHGRP data\n",
    "facility_info = pd.read_csv(GHGRP_facility_inputfile)\n",
    "facility_2014 = pd.read_csv(ghgrp_distr_2014_inputfile)\n",
    "facility_2018 = pd.read_csv(ghgrp_distr_meteringbelow_2018_inputfile) #pipeline mileage and below-grade stations\n",
    "facility_above_2018 = pd.read_csv(ghgrp_distr_meteringabove_2018_inputfile) #above-grade stations\n",
    "\n",
    "\n",
    "#b) Add state column to metering stations\n",
    "# record the state abbreviation for each facility ID (for all three files)\n",
    "facility_2014_state = []\n",
    "facility_2018_state = []\n",
    "facility_above_2018_state = []\n",
    "\n",
    "# for each entry in the data file (each facility each year), match the facility ID in the 2014 data to the ID in the\n",
    "# GHGRP facility info file, then append the corresponding state abbreviation to the facility_[year]_state array\n",
    "for index in np.arange(len(facility_2014)):\n",
    "    ilocation = np.where(facility_info['V_GHG_EMITTER_FACILITIES.FACILITY_ID'] == facility_2014['W_LOCAL_DIST_COMPANIES_DETAILS.FACILITY_ID'][index])[0][0]\n",
    "    facility_2014_state.append(facility_info['V_GHG_EMITTER_FACILITIES.STATE'][ilocation])\n",
    "\n",
    "for index in np.arange(len(facility_2018)):\n",
    "    ilocation = np.where(facility_info['V_GHG_EMITTER_FACILITIES.FACILITY_ID'] == facility_2018['EF_W_EQUIP_LEAKS_POP_COUNT.FACILITY_ID'][index])[0][0]\n",
    "    facility_2018_state.append(facility_info['V_GHG_EMITTER_FACILITIES.STATE'][ilocation])\n",
    "    \n",
    "for index in np.arange(len(facility_above_2018)):\n",
    "    ilocation = np.where(facility_info['V_GHG_EMITTER_FACILITIES.FACILITY_ID'] == facility_above_2018['EF_W_EQUIP_LEAKS_NGDIST_LEAKS.FACILITY_ID'][index])[0][0]\n",
    "    facility_above_2018_state.append(facility_info['V_GHG_EMITTER_FACILITIES.STATE'][ilocation])\n",
    "    \n",
    "# add the the state abbreviations to the main arrays\n",
    "facility_2014['state'] = facility_2014_state\n",
    "facility_2018['state'] = facility_2018_state\n",
    "facility_above_2018['state'] = facility_above_2018_state\n",
    "\n",
    "\n",
    "#c) Format GHGRP data\n",
    "# Replace nan counts with zero\n",
    "facility_2018['EF_W_EQUIP_LEAKS_POP_COUNT.SOURCE_TYPE_COUNT'] = facility_2018['EF_W_EQUIP_LEAKS_POP_COUNT.SOURCE_TYPE_COUNT'].fillna(0)\n",
    "facility_above_2018['EF_W_EQUIP_LEAKS_NGDIST_LEAKS.TOTAL_TD_FACILITY_STATIONS'] = facility_above_2018['EF_W_EQUIP_LEAKS_NGDIST_LEAKS.TOTAL_TD_FACILITY_STATIONS'].fillna(0)\n",
    "facility_above_2018['EF_W_EQUIP_LEAKS_NGDIST_LEAKS.TOTAL_NON_TD_FACILITY_STATIONS'] = facility_above_2018['EF_W_EQUIP_LEAKS_NGDIST_LEAKS.TOTAL_NON_TD_FACILITY_STATIONS'].fillna(0)\n",
    "\n",
    "facility_2014['W_LOCAL_DIST_COMPANIES_DETAILS.MILES_OF_CAST_IRON_DIST_MAINS'] = facility_2014['W_LOCAL_DIST_COMPANIES_DETAILS.MILES_OF_CAST_IRON_DIST_MAINS'].fillna(0)\n",
    "facility_2014['W_LOCAL_DIST_COMPANIES_DETAILS.MILES_OF_PLSTIC_DIST_MAINS'] = facility_2014['W_LOCAL_DIST_COMPANIES_DETAILS.MILES_OF_PLSTIC_DIST_MAINS'].fillna(0)\n",
    "facility_2014['W_LOCAL_DIST_COMPANIES_DETAILS.MILES_OF_PROT_STEEL_DIST_MAINS'] = facility_2014['W_LOCAL_DIST_COMPANIES_DETAILS.MILES_OF_PROT_STEEL_DIST_MAINS'].fillna(0)\n",
    "facility_2014['W_LOCAL_DIST_COMPANIES_DETAILS.MILES_OF_UNPR_STEEL_DIST_MAINS'] = facility_2014['W_LOCAL_DIST_COMPANIES_DETAILS.MILES_OF_UNPR_STEEL_DIST_MAINS'].fillna(0)\n",
    "\n",
    "# Filter out null rows\n",
    "facility_2014.dropna(subset=['W_LOCAL_DIST_COMPANIES_DETAILS.REPORTING_YEAR'],inplace=True)\n",
    "facility_2014.reset_index(drop=True,inplace=True)\n",
    "facility_2018.dropna(subset=['EF_W_EQUIP_LEAKS_POP_COUNT.REPORTING_YEAR'],inplace=True)\n",
    "facility_2018.reset_index(drop=True,inplace=True)\n",
    "facility_above_2018.dropna(subset=['EF_W_EQUIP_LEAKS_NGDIST_LEAKS.REPORTING_YEAR'],inplace=True) \n",
    "facility_above_2018.reset_index(drop=True,inplace=True)\n",
    "\n",
    "\n",
    "#d) Filter out GHGRP IDs that don't report in all 7 years (for consistency)\n",
    "# Check within 2011-2014\n",
    "for index in np.arange(len(facility_2014)):\n",
    "    ID = facility_2014['W_LOCAL_DIST_COMPANIES_DETAILS.FACILITY_ID'][index]\n",
    "    if len(facility_2014[facility_2014['W_LOCAL_DIST_COMPANIES_DETAILS.FACILITY_ID'] == ID]) < 4:\n",
    "        facility_2014.drop([index],axis=0,inplace=True)\n",
    "facility_2014.reset_index(drop=True,inplace=True)\n",
    "\n",
    "# Check within 2015-2018 (above-grade)\n",
    "for index in np.arange(len(facility_above_2018)):\n",
    "    ID = facility_above_2018['EF_W_EQUIP_LEAKS_NGDIST_LEAKS.FACILITY_ID'][index]\n",
    "    if len(facility_above_2018[facility_above_2018['EF_W_EQUIP_LEAKS_NGDIST_LEAKS.FACILITY_ID'] == ID]) < 4:\n",
    "        facility_above_2018.drop([index],axis=0,inplace=True)\n",
    "facility_above_2018.reset_index(drop=True,inplace=True)\n",
    "\n",
    "# Check within 2015-2018 (below-grade)\n",
    "facility_filtered = facility_2018[facility_2018['EF_W_EQUIP_LEAKS_POP_COUNT.EMISSION_SRC_TYPE'] == 'Below Grade T-D Station  Gas Service  Inlet Pressure > 300 psig']\n",
    "for index in np.arange(len(facility_2018)):\n",
    "    ID = facility_2018['EF_W_EQUIP_LEAKS_POP_COUNT.FACILITY_ID'][index]\n",
    "    if len(facility_filtered[facility_filtered['EF_W_EQUIP_LEAKS_POP_COUNT.FACILITY_ID'] == ID]) < 4:\n",
    "        facility_2018.drop([index],axis=0,inplace=True)\n",
    "facility_2018.reset_index(drop=True,inplace=True)\n",
    "\n",
    "# Checking between datasets (i.e, drop facilities that are not reported both before and after 2015)\n",
    "# Direction: Old to new\n",
    "for index in np.arange(len(facility_2014)):\n",
    "    ID = facility_2014['W_LOCAL_DIST_COMPANIES_DETAILS.FACILITY_ID'][index]\n",
    "    if len(facility_above_2018[facility_above_2018['EF_W_EQUIP_LEAKS_NGDIST_LEAKS.FACILITY_ID']==ID])==0:\n",
    "        facility_2014.drop([index],axis=0,inplace=True)\n",
    "facility_2014.reset_index(drop=True,inplace=True)\n",
    "\n",
    "# Direction: New to old, above ground\n",
    "for index in np.arange(len(facility_above_2018)):\n",
    "    ID = facility_above_2018['EF_W_EQUIP_LEAKS_NGDIST_LEAKS.FACILITY_ID'][index]\n",
    "    if len(facility_2014[facility_2014['W_LOCAL_DIST_COMPANIES_DETAILS.FACILITY_ID']==ID])==0:\n",
    "        facility_above_2018.drop([index],axis=0,inplace=True)\n",
    "facility_above_2018.reset_index(drop=True,inplace=True)        \n",
    "\n",
    "# Direction: New to old, below \n",
    "for index in np.arange(len(facility_2018)):\n",
    "    ID = facility_2018['EF_W_EQUIP_LEAKS_POP_COUNT.FACILITY_ID'][index]\n",
    "    if len(facility_2014[facility_2014['W_LOCAL_DIST_COMPANIES_DETAILS.FACILITY_ID']==ID])==0:\n",
    "        facility_2018.drop([index],axis=0,inplace=True)\n",
    "facility_2018.reset_index(drop=True,inplace=True)\n",
    "\n",
    "# Print time\n",
    "ct = datetime.datetime.now() \n",
    "print(\"current time:\", ct) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.5.2 Fixing GHGRP Data Inconsistencies in Stations Reporting\n",
    "There are a few reporting inconsistencies in the GHGRP data. \n",
    "Below are 7 known problems, the causes, EPA's proposed solutions, and their implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 1: \n",
    "# AL has anomalous drop in stations in 2013 and 2014. \n",
    "# Cause: \n",
    "# facility 1005967 didn't report below-grade metering stations in 2013-2014 but picked back up 2015-2018.\n",
    "# EPA Solution:\n",
    "# Interpolation is likely the best approach. The facility appears to have omitted the count of below \n",
    "# grade stations (both T-D and M/R all together from their Reporting Year (RY) 2013 and RY 2014 annual reports). \n",
    "# We note the report includes emissions from these sources, so only the station count is missing.\n",
    "\n",
    "# Get linear fit using the start year (2012), and 2015 to end year (2018) points, then interpolate 2013-2014\n",
    "# Create array to hold annual stations count\n",
    "\n",
    "stations = np.zeros(num_years)\n",
    "\n",
    "# 2012\n",
    "facility_temp = facility_2014[facility_2014['W_LOCAL_DIST_COMPANIES_DETAILS.REPORTING_YEAR']==2012]\n",
    "facility_temp = facility_temp[facility_temp['W_LOCAL_DIST_COMPANIES_DETAILS.FACILITY_ID']==1005967]\n",
    "stations[0] = facility_temp['W_LOCAL_DIST_COMPANIES_DETAILS.ABOVE_GRADE_METERING_STATIONS'].iloc[0] + \\\n",
    "    facility_temp['W_LOCAL_DIST_COMPANIES_DETAILS.ABOVE_GRADE_TRANSFER_STATIONS'].iloc[0] + \\\n",
    "    facility_temp['W_LOCAL_DIST_COMPANIES_DETAILS.BELOW_GRADE_METERING_STATIONS'].iloc[0] + \\\n",
    "    facility_temp['W_LOCAL_DIST_COMPANIES_DETAILS.BELOW_GRADE_TRANSFER_STATIONS'].iloc[0]\n",
    "\n",
    "# Below-grade 2015-2018 (end year)\n",
    "for iyear in np.arange((2015-start_year),num_years):\n",
    "    facility_temp = facility_2018[facility_2018['EF_W_EQUIP_LEAKS_POP_COUNT.REPORTING_YEAR'] == iyear+start_year]\n",
    "    facility_temp = facility_temp[facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.FACILITY_ID']==1005967]\n",
    "    facility_temp.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    for index in np.arange(len(facility_temp)):\n",
    "        if facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.EMISSION_SRC_TYPE'][index] == 'Below Grade T-D Station  Gas Service  Inlet Pressure > 300 psig':   \n",
    "            stations[iyear] += facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.SOURCE_TYPE_COUNT'][index]\n",
    "        elif facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.EMISSION_SRC_TYPE'][index] == 'Below Grade T-D Station  Gas Service  Inlet Pressure 100 to 300 psig':   \n",
    "            stations[iyear] += facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.SOURCE_TYPE_COUNT'][index] \n",
    "        elif facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.EMISSION_SRC_TYPE'][index] == 'Below Grade T-D Station  Gas Service  Inlet Pressure < 100 psig':   \n",
    "            stations[iyear] += facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.SOURCE_TYPE_COUNT'][index]\n",
    "        elif facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.EMISSION_SRC_TYPE'][index] == 'Below Grade M-R Station  Gas Service  Inlet Pressure > 300 psig':   \n",
    "            stations[iyear] += facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.SOURCE_TYPE_COUNT'][index]\n",
    "        elif facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.EMISSION_SRC_TYPE'][index] == 'Below Grade M-R Station  Gas Service  Inlet Pressure 100 to 300 psig':   \n",
    "            stations[iyear] += facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.SOURCE_TYPE_COUNT'][index]\n",
    "        elif facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.EMISSION_SRC_TYPE'][index] == 'Below Grade M-R Station  Gas Service  Inlet Pressure < 100 psig':   \n",
    "            stations[iyear] += facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.SOURCE_TYPE_COUNT'][index]\n",
    "\n",
    "# Above-grade 2015-end year(2018)\n",
    "for iyear in np.arange((2015-start_year),num_years):\n",
    "    facility_temp = facility_above_2018[facility_above_2018['EF_W_EQUIP_LEAKS_NGDIST_LEAKS.REPORTING_YEAR'] == iyear+start_year]\n",
    "    facility_temp = facility_temp[facility_temp['EF_W_EQUIP_LEAKS_NGDIST_LEAKS.FACILITY_ID']==1005967]\n",
    "    facility_temp.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    for index in np.arange(len(facility_temp)):\n",
    "        stations[iyear] += facility_temp['EF_W_EQUIP_LEAKS_NGDIST_LEAKS.TOTAL_TD_FACILITY_STATIONS'][index]\n",
    "        stations[iyear] += facility_temp['EF_W_EQUIP_LEAKS_NGDIST_LEAKS.TOTAL_NON_TD_FACILITY_STATIONS'][index]\n",
    "\n",
    "# Linear fit\n",
    "x = [start_year]\n",
    "x.extend(list(range(2015,end_year+1))) #x=years\n",
    "match_years = [year_range.index(i) for i in x] # find which years these include (out of the entire range)\n",
    "y = [stations[i] for i in match_years] # find the station data for those given years\n",
    "coef = np.polyfit(x, y, 1)\n",
    "\n",
    "# Calculate missing years: 2013, 2014\n",
    "stations[1] = round(2013*coef[0] + coef[1]) #2013\n",
    "stations[2] = round(2014*coef[0] + coef[1]) #2014\n",
    "\n",
    "# Subtract above-grade stations in 2013/2014 to get only below-grade\n",
    "facility_temp = facility_2014[facility_2014['W_LOCAL_DIST_COMPANIES_DETAILS.REPORTING_YEAR']==2013]\n",
    "facility_temp = facility_temp[facility_temp['W_LOCAL_DIST_COMPANIES_DETAILS.FACILITY_ID']==1005967]\n",
    "above_13 = facility_temp['W_LOCAL_DIST_COMPANIES_DETAILS.ABOVE_GRADE_METERING_STATIONS'].iloc[0] + \\\n",
    "    facility_temp['W_LOCAL_DIST_COMPANIES_DETAILS.ABOVE_GRADE_TRANSFER_STATIONS'].iloc[0]\n",
    "below_13 = stations[1] - above_13\n",
    "facility_temp = facility_2014[facility_2014['W_LOCAL_DIST_COMPANIES_DETAILS.REPORTING_YEAR']==2014]\n",
    "facility_temp = facility_temp[facility_temp['W_LOCAL_DIST_COMPANIES_DETAILS.FACILITY_ID']==1005967]\n",
    "above_14 = facility_temp['W_LOCAL_DIST_COMPANIES_DETAILS.ABOVE_GRADE_METERING_STATIONS'].iloc[0] + \\\n",
    "    facility_temp['W_LOCAL_DIST_COMPANIES_DETAILS.ABOVE_GRADE_TRANSFER_STATIONS'].iloc[0]\n",
    "below_14 = stations[2] - above_14\n",
    "\n",
    "# Find indices of 2013/2014 rows for company 1005967\n",
    "facility_temp = facility_2014[facility_2014['W_LOCAL_DIST_COMPANIES_DETAILS.FACILITY_ID']==1005967]\n",
    "index_2013 = facility_temp[facility_temp['W_LOCAL_DIST_COMPANIES_DETAILS.REPORTING_YEAR']==2013].index.values.astype(int)[0]\n",
    "index_2014 = facility_temp[facility_temp['W_LOCAL_DIST_COMPANIES_DETAILS.REPORTING_YEAR']==2014].index.values.astype(int)[0]\n",
    "\n",
    "# Put new 2013/2014 below-grade values into facility_14\n",
    "facility_2014.at[index_2013,'W_LOCAL_DIST_COMPANIES_DETAILS.BELOW_GRADE_METERING_STATIONS']= below_13\n",
    "facility_2014.at[index_2014,'W_LOCAL_DIST_COMPANIES_DETAILS.BELOW_GRADE_METERING_STATIONS']= below_14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 2: \n",
    "# AK had low station counts in 2015-2018; \n",
    "# Cause: \n",
    "# facility 1006604 stopped reporting metering stations 2015-2018 (but still reported transfer stations).\n",
    "# EPA Solution:\n",
    "# Estimate metering station counts after 2015 using 2012 (start year)-2014 data.\n",
    "\n",
    "# Get linear fit using 2012 (start year)-2014 to extrapolate 2015-2018 (end year) stations.\n",
    "\n",
    "# Create array to hold annual stations count\n",
    "stations = np.zeros(num_years)\n",
    "\n",
    "# 2012-2014 stations\n",
    "for iyear in np.arange(2015-start_year):\n",
    "    facility_temp = facility_2014[facility_2014['W_LOCAL_DIST_COMPANIES_DETAILS.REPORTING_YEAR']==iyear+start_year]\n",
    "    facility_temp = facility_temp[facility_temp['W_LOCAL_DIST_COMPANIES_DETAILS.FACILITY_ID']==1006604]\n",
    "    stations[iyear] = facility_temp['W_LOCAL_DIST_COMPANIES_DETAILS.ABOVE_GRADE_METERING_STATIONS'].iloc[0] + \\\n",
    "        facility_temp['W_LOCAL_DIST_COMPANIES_DETAILS.ABOVE_GRADE_TRANSFER_STATIONS'].iloc[0] + \\\n",
    "        facility_temp['W_LOCAL_DIST_COMPANIES_DETAILS.BELOW_GRADE_METERING_STATIONS'].iloc[0] + \\\n",
    "        facility_temp['W_LOCAL_DIST_COMPANIES_DETAILS.BELOW_GRADE_TRANSFER_STATIONS'].iloc[0]\n",
    "\n",
    "# Linear fit\n",
    "x = list(range(start_year, 2015)) #x = years (start year to 2014)\n",
    "match_years = [year_range.index(i) for i in x] # find which years these include (out of the entire range)\n",
    "y = [stations[i] for i in match_years] # find the station data for those given years\n",
    "coef = np.polyfit(x, y, 1)\n",
    "\n",
    "# Calculate station counts for 2015-2018 using previous relationship\n",
    "index_2015 = year_range.index(2015)\n",
    "for iyear in np.arange(end_year-2014):\n",
    "    stations[index_2015+iyear] = round((2015+iyear)*coef[0] + coef[1])\n",
    "\n",
    "# Count stations company reported 2015-2018\n",
    "stations_before = np.zeros(num_years)\n",
    "for iyear in np.arange(2015-start_year,num_years): # Below-grade 2015-2018\n",
    "    facility_temp = facility_2018[facility_2018['EF_W_EQUIP_LEAKS_POP_COUNT.REPORTING_YEAR'] == iyear+start_year]\n",
    "    facility_temp = facility_temp[facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.FACILITY_ID']==1006604]\n",
    "    facility_temp.reset_index(drop=True,inplace=True)\n",
    "    for index in np.arange(len(facility_temp)):\n",
    "        if facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.EMISSION_SRC_TYPE'][index] == 'Below Grade T-D Station  Gas Service  Inlet Pressure > 300 psig':   \n",
    "            stations_before[iyear] += facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.SOURCE_TYPE_COUNT'][index]\n",
    "        elif facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.EMISSION_SRC_TYPE'][index] == 'Below Grade T-D Station  Gas Service  Inlet Pressure 100 to 300 psig':   \n",
    "            stations_before[iyear] += facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.SOURCE_TYPE_COUNT'][index] \n",
    "        elif facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.EMISSION_SRC_TYPE'][index] == 'Below Grade T-D Station  Gas Service  Inlet Pressure < 100 psig':   \n",
    "            stations_before[iyear] += facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.SOURCE_TYPE_COUNT'][index]\n",
    "        elif facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.EMISSION_SRC_TYPE'][index] == 'Below Grade M-R Station  Gas Service  Inlet Pressure > 300 psig':   \n",
    "            stations_before[iyear] += facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.SOURCE_TYPE_COUNT'][index]\n",
    "        elif facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.EMISSION_SRC_TYPE'][index] == 'Below Grade M-R Station  Gas Service  Inlet Pressure 100 to 300 psig':   \n",
    "            stations_before[iyear] += facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.SOURCE_TYPE_COUNT'][index]\n",
    "        elif facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.EMISSION_SRC_TYPE'][index] == 'Below Grade M-R Station  Gas Service  Inlet Pressure < 100 psig':   \n",
    "            stations_before[iyear] += facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.SOURCE_TYPE_COUNT'][index]\n",
    "for iyear in np.arange(2015-start_year,num_years): # Above-grade 2015-2018\n",
    "    facility_temp = facility_above_2018[facility_above_2018['EF_W_EQUIP_LEAKS_NGDIST_LEAKS.REPORTING_YEAR'] == iyear+start_year]\n",
    "    facility_temp = facility_temp[facility_temp['EF_W_EQUIP_LEAKS_NGDIST_LEAKS.FACILITY_ID']==1006604]\n",
    "    facility_temp.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    for index in np.arange(len(facility_temp)):\n",
    "        stations_before[iyear] += facility_temp['EF_W_EQUIP_LEAKS_NGDIST_LEAKS.TOTAL_TD_FACILITY_STATIONS'][index]\n",
    "        stations_before[iyear] += facility_temp['EF_W_EQUIP_LEAKS_NGDIST_LEAKS.TOTAL_NON_TD_FACILITY_STATIONS'][index]\n",
    "\n",
    "# Subtract stations_before from stations to get how many stations need to be added in 2015-2018\n",
    "stations_add = stations - stations_before\n",
    "\n",
    "# Find 2015-2018 indices for company 1006604 to add additional stations (adding to above-grade metering stations)\n",
    "facility_temp = facility_above_2018[facility_above_2018['EF_W_EQUIP_LEAKS_NGDIST_LEAKS.FACILITY_ID']==1006604]\n",
    "\n",
    "for iyear in np.arange(end_year-2014):\n",
    "    index = facility_temp[facility_temp['EF_W_EQUIP_LEAKS_NGDIST_LEAKS.REPORTING_YEAR']==2015+iyear].index.values.astype(int)[0]\n",
    "    facility_above_2018.at[index,'EF_W_EQUIP_LEAKS_NGDIST_LEAKS.TOTAL_NON_TD_FACILITY_STATIONS']= stations_add[index_2015+iyear]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 3:\n",
    "# MS has implausible rise in reported stations in 2018 without additional mileage in 2018;\n",
    "# Cause: \n",
    "# facility 1001688 reported 1552 more stations from 2017-2018.\n",
    "# EPA Solution:\n",
    "# Use 2017 value for 2018\n",
    "\n",
    "# This problem is in facility_above_2018. We will change metering and transfer stations in 2018 to values in 2017\n",
    "\n",
    "# Retrieve 2017 values\n",
    "facility_temp = facility_above_2018[facility_above_2018['EF_W_EQUIP_LEAKS_NGDIST_LEAKS.FACILITY_ID']==1001688]\n",
    "facility_17 = facility_temp[facility_temp['EF_W_EQUIP_LEAKS_NGDIST_LEAKS.REPORTING_YEAR']==2017]\n",
    "metering_17 = facility_17['EF_W_EQUIP_LEAKS_NGDIST_LEAKS.TOTAL_NON_TD_FACILITY_STATIONS']\n",
    "transfer_17 = facility_17['EF_W_EQUIP_LEAKS_NGDIST_LEAKS.TOTAL_TD_FACILITY_STATIONS']\n",
    "\n",
    "# Retrieve 2018 index\n",
    "facility_temp = facility_above_2018[facility_above_2018['EF_W_EQUIP_LEAKS_NGDIST_LEAKS.FACILITY_ID']==1001688]\n",
    "facility_18 = facility_temp[facility_temp['EF_W_EQUIP_LEAKS_NGDIST_LEAKS.REPORTING_YEAR']==2018]\n",
    "index_18 = facility_18.index.values.astype(int)[0]\n",
    "\n",
    "# Replace 2018 values with 2017 values\n",
    "facility_above_2018.at[index_18,'EF_W_EQUIP_LEAKS_NGDIST_LEAKS.TOTAL_NON_TD_FACILITY_STATIONS'] = metering_17\n",
    "facility_above_2018.at[index_18,'EF_W_EQUIP_LEAKS_NGDIST_LEAKS.TOTAL_TD_FACILITY_STATIONS'] = transfer_17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 4:\n",
    "# NJ below-grade metering stations are too low in 2014\n",
    "# Cuase: \n",
    "# NJ facility 1002812 didn’t report below-grade metering stations in 2014.\n",
    "# EPA Solution:\n",
    "# Interpolation between 2013 and 2015.\n",
    "\n",
    "# 2014 value is average of 2013 and 2015 below-grade stations.\n",
    "\n",
    "# 2015 below-grade metering value\n",
    "facility_temp = facility_2018[facility_2018['EF_W_EQUIP_LEAKS_POP_COUNT.REPORTING_YEAR'] == 2015]\n",
    "facility_temp = facility_temp[facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.FACILITY_ID']==1002812]\n",
    "facility_temp.reset_index(drop=True,inplace=True)\n",
    "metering_15 = 0\n",
    "for index in np.arange(len(facility_temp)):\n",
    "    if facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.EMISSION_SRC_TYPE'][index] == 'Below Grade M-R Station  Gas Service  Inlet Pressure > 300 psig':   \n",
    "        metering_15 += facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.SOURCE_TYPE_COUNT'][index]\n",
    "    elif facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.EMISSION_SRC_TYPE'][index] == 'Below Grade M-R Station  Gas Service  Inlet Pressure 100 to 300 psig':   \n",
    "        metering_15 += facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.SOURCE_TYPE_COUNT'][index]\n",
    "    elif facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.EMISSION_SRC_TYPE'][index] == 'Below Grade M-R Station  Gas Service  Inlet Pressure < 100 psig':   \n",
    "        metering_15 += facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.SOURCE_TYPE_COUNT'][index]\n",
    "# 2013 value and average to get 2014\n",
    "facility_temp = facility_2014[facility_2014['W_LOCAL_DIST_COMPANIES_DETAILS.FACILITY_ID']==1002812]\n",
    "index_13 = facility_temp[facility_temp['W_LOCAL_DIST_COMPANIES_DETAILS.REPORTING_YEAR']==2013].index[0]\n",
    "index_14 = facility_temp[facility_temp['W_LOCAL_DIST_COMPANIES_DETAILS.REPORTING_YEAR']==2014].index[0]\n",
    "metering_13 = facility_2014['W_LOCAL_DIST_COMPANIES_DETAILS.BELOW_GRADE_METERING_STATIONS'].iloc[index_13]\n",
    "metering_14 = round((metering_13+metering_15)/2)\n",
    "\n",
    "# Replace 2014 below-grade metering value\n",
    "facility_2014.at[index_14,'W_LOCAL_DIST_COMPANIES_DETAILS.BELOW_GRADE_METERING_STATIONS'] = metering_14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 5:\n",
    "# NY abrupt drop in stations from 2015 onwards. \n",
    "# Cause:\n",
    "# Facility 1003642: below metering dropped from 823 to 48 2014-2015. Facility 1003576: below metering \n",
    "# dropped from 457 to 14 2014-2015. Corresponding huge drop in stations/mileage ratio. \n",
    "# EPA Solution:\n",
    "# Use 2015 counts for 2012 (start_year)-2014.\n",
    "\n",
    "# Replace above/below grade metering/transfer stations (4 categories total) with 2015 values\n",
    "\n",
    "# 1) Facility 1003642\n",
    "\n",
    "# Initialize counts for each category\n",
    "above_metering_15 = 0\n",
    "above_transfer_15 = 0\n",
    "below_metering_15 = 0\n",
    "below_transfer_15 = 0\n",
    "\n",
    "# Count stations company reported in 2015\n",
    "# Below-grade 2015\n",
    "facility_temp = facility_2018[facility_2018['EF_W_EQUIP_LEAKS_POP_COUNT.REPORTING_YEAR'] == 2015]\n",
    "facility_temp = facility_temp[facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.FACILITY_ID']==1003642]\n",
    "facility_temp.reset_index(drop=True,inplace=True)\n",
    "for index in np.arange(len(facility_temp)):\n",
    "    if facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.EMISSION_SRC_TYPE'][index] == 'Below Grade T-D Station  Gas Service  Inlet Pressure > 300 psig':   \n",
    "        below_transfer_15 += facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.SOURCE_TYPE_COUNT'][index]\n",
    "    elif facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.EMISSION_SRC_TYPE'][index] == 'Below Grade T-D Station  Gas Service  Inlet Pressure 100 to 300 psig':   \n",
    "        below_transfer_15 += facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.SOURCE_TYPE_COUNT'][index] \n",
    "    elif facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.EMISSION_SRC_TYPE'][index] == 'Below Grade T-D Station  Gas Service  Inlet Pressure < 100 psig':   \n",
    "        below_transfer_15 += facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.SOURCE_TYPE_COUNT'][index]\n",
    "    elif facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.EMISSION_SRC_TYPE'][index] == 'Below Grade M-R Station  Gas Service  Inlet Pressure > 300 psig':   \n",
    "        below_metering_15 += facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.SOURCE_TYPE_COUNT'][index]\n",
    "    elif facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.EMISSION_SRC_TYPE'][index] == 'Below Grade M-R Station  Gas Service  Inlet Pressure 100 to 300 psig':   \n",
    "        below_metering_15 += facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.SOURCE_TYPE_COUNT'][index]\n",
    "    elif facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.EMISSION_SRC_TYPE'][index] == 'Below Grade M-R Station  Gas Service  Inlet Pressure < 100 psig':   \n",
    "        below_metering_15 += facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.SOURCE_TYPE_COUNT'][index]\n",
    "# Above-grade 2015\n",
    "facility_temp = facility_above_2018[facility_above_2018['EF_W_EQUIP_LEAKS_NGDIST_LEAKS.REPORTING_YEAR'] == 2015]\n",
    "facility_temp = facility_temp[facility_temp['EF_W_EQUIP_LEAKS_NGDIST_LEAKS.FACILITY_ID']==1003642]\n",
    "facility_temp.reset_index(drop=True,inplace=True)\n",
    "above_transfer_15 = facility_temp['EF_W_EQUIP_LEAKS_NGDIST_LEAKS.TOTAL_TD_FACILITY_STATIONS'][0]\n",
    "above_metering_15 = facility_temp['EF_W_EQUIP_LEAKS_NGDIST_LEAKS.TOTAL_NON_TD_FACILITY_STATIONS'][0]   \n",
    "\n",
    "# Array of indices of 2012 (start year)-2014 entries for facility 1003642\n",
    "index_array = np.zeros(2015-start_year)\n",
    "facility_temp = facility_2014[facility_2014['W_LOCAL_DIST_COMPANIES_DETAILS.FACILITY_ID']==1003642]\n",
    "for iyear in np.arange(2015-start_year):\n",
    "    index_array[iyear] = facility_temp[facility_temp['W_LOCAL_DIST_COMPANIES_DETAILS.REPORTING_YEAR']==start_year+iyear].index.values.astype(int)[0]\n",
    "\n",
    "# Replace 2012-2014 with 2015 counts\n",
    "for iyear in np.arange(2015-start_year):\n",
    "    facility_2014.at[int(index_array[iyear]),'W_LOCAL_DIST_COMPANIES_DETAILS.ABOVE_GRADE_METERING_STATIONS'] = above_metering_15\n",
    "    facility_2014.at[int(index_array[iyear]),'W_LOCAL_DIST_COMPANIES_DETAILS.ABOVE_GRADE_TRANSFER_STATIONS'] = above_transfer_15\n",
    "    facility_2014.at[int(index_array[iyear]),'W_LOCAL_DIST_COMPANIES_DETAILS.BELOW_GRADE_METERING_STATIONS'] = below_metering_15\n",
    "    facility_2014.at[int(index_array[iyear]),'W_LOCAL_DIST_COMPANIES_DETAILS.BELOW_GRADE_TRANSFER_STATIONS'] = below_transfer_15\n",
    "\n",
    "    \n",
    "# 2) Facility 1003576\n",
    "\n",
    "# Initialize counts for each category\n",
    "above_metering_15 = 0\n",
    "above_transfer_15 = 0\n",
    "below_metering_15 = 0\n",
    "below_transfer_15 = 0\n",
    "\n",
    "# Count stations company reported in 2015\n",
    "# Below-grade 2015\n",
    "facility_temp = facility_2018[facility_2018['EF_W_EQUIP_LEAKS_POP_COUNT.REPORTING_YEAR'] == 2015]\n",
    "facility_temp = facility_temp[facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.FACILITY_ID']==1003576]\n",
    "facility_temp.reset_index(drop=True,inplace=True)\n",
    "for index in np.arange(len(facility_temp)):\n",
    "    if facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.EMISSION_SRC_TYPE'][index] == 'Below Grade T-D Station  Gas Service  Inlet Pressure > 300 psig':   \n",
    "        below_transfer_15 += facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.SOURCE_TYPE_COUNT'][index]\n",
    "    elif facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.EMISSION_SRC_TYPE'][index] == 'Below Grade T-D Station  Gas Service  Inlet Pressure 100 to 300 psig':   \n",
    "        below_transfer_15 += facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.SOURCE_TYPE_COUNT'][index] \n",
    "    elif facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.EMISSION_SRC_TYPE'][index] == 'Below Grade T-D Station  Gas Service  Inlet Pressure < 100 psig':   \n",
    "        below_transfer_15 += facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.SOURCE_TYPE_COUNT'][index]\n",
    "    elif facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.EMISSION_SRC_TYPE'][index] == 'Below Grade M-R Station  Gas Service  Inlet Pressure > 300 psig':   \n",
    "        below_metering_15 += facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.SOURCE_TYPE_COUNT'][index]\n",
    "    elif facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.EMISSION_SRC_TYPE'][index] == 'Below Grade M-R Station  Gas Service  Inlet Pressure 100 to 300 psig':   \n",
    "        below_metering_15 += facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.SOURCE_TYPE_COUNT'][index]\n",
    "    elif facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.EMISSION_SRC_TYPE'][index] == 'Below Grade M-R Station  Gas Service  Inlet Pressure < 100 psig':   \n",
    "        below_metering_15 += facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.SOURCE_TYPE_COUNT'][index]\n",
    "# Above-grade 2015\n",
    "facility_temp = facility_above_2018[facility_above_2018['EF_W_EQUIP_LEAKS_NGDIST_LEAKS.REPORTING_YEAR'] == 2015]\n",
    "facility_temp = facility_temp[facility_temp['EF_W_EQUIP_LEAKS_NGDIST_LEAKS.FACILITY_ID']==1003576]\n",
    "facility_temp.reset_index(drop=True,inplace=True)\n",
    "above_transfer_15 = facility_temp['EF_W_EQUIP_LEAKS_NGDIST_LEAKS.TOTAL_TD_FACILITY_STATIONS'][0]\n",
    "above_metering_15 = facility_temp['EF_W_EQUIP_LEAKS_NGDIST_LEAKS.TOTAL_NON_TD_FACILITY_STATIONS'][0]   \n",
    "\n",
    "# Array of indices of 2012 (start year)-2014 entries for facility 1003642\n",
    "index_array = np.zeros(2015-start_year)\n",
    "facility_temp = facility_2014[facility_2014['W_LOCAL_DIST_COMPANIES_DETAILS.FACILITY_ID']==1003576]\n",
    "for iyear in np.arange(2015-start_year):\n",
    "    index_array[iyear] = facility_temp[facility_temp['W_LOCAL_DIST_COMPANIES_DETAILS.REPORTING_YEAR']==start_year+iyear].index.values.astype(int)[0]\n",
    "# Replace 2012-2014 with 2015 counts\n",
    "    facility_2014.at[int(index_array[iyear]),'W_LOCAL_DIST_COMPANIES_DETAILS.ABOVE_GRADE_METERING_STATIONS'] = above_metering_15\n",
    "    facility_2014.at[int(index_array[iyear]),'W_LOCAL_DIST_COMPANIES_DETAILS.ABOVE_GRADE_TRANSFER_STATIONS'] = above_transfer_15\n",
    "    facility_2014.at[int(index_array[iyear]),'W_LOCAL_DIST_COMPANIES_DETAILS.BELOW_GRADE_METERING_STATIONS'] = below_metering_15\n",
    "    facility_2014.at[int(index_array[iyear]),'W_LOCAL_DIST_COMPANIES_DETAILS.BELOW_GRADE_TRANSFER_STATIONS'] = below_transfer_15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 6:\n",
    "# NC stations counts had huge drop in 2015. \n",
    "# Cause: \n",
    "# Company 1004567 decreased metering stations from 958 to 671, 1001583 decreased metering \n",
    "# stations from 1396 to 645. Corresponding drop in stations/mileage ratio.\n",
    "# EPA Solution:\n",
    "# Use 2016 for 2012 (start_year)-2016 counts\n",
    "\n",
    "# Initialize counts for each category\n",
    "above_metering_16 = 0\n",
    "above_transfer_16 = 0\n",
    "below_metering_16 = 0\n",
    "below_transfer_16 = 0\n",
    "\n",
    "# Count stations company reported in 2016\n",
    "# Below-grade 2016\n",
    "facility_temp = facility_2018[facility_2018['EF_W_EQUIP_LEAKS_POP_COUNT.REPORTING_YEAR'] == 2016]\n",
    "facility_temp = facility_temp[facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.FACILITY_ID']==1001583]\n",
    "facility_temp.reset_index(drop=True,inplace=True)\n",
    "for index in np.arange(len(facility_temp)):\n",
    "    if facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.EMISSION_SRC_TYPE'][index] == 'Below Grade T-D Station  Gas Service  Inlet Pressure > 300 psig':   \n",
    "        below_transfer_16 += facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.SOURCE_TYPE_COUNT'][index]\n",
    "    elif facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.EMISSION_SRC_TYPE'][index] == 'Below Grade T-D Station  Gas Service  Inlet Pressure 100 to 300 psig':   \n",
    "        below_transfer_16 += facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.SOURCE_TYPE_COUNT'][index] \n",
    "    elif facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.EMISSION_SRC_TYPE'][index] == 'Below Grade T-D Station  Gas Service  Inlet Pressure < 100 psig':   \n",
    "        below_transfer_16 += facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.SOURCE_TYPE_COUNT'][index]\n",
    "    elif facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.EMISSION_SRC_TYPE'][index] == 'Below Grade M-R Station  Gas Service  Inlet Pressure > 300 psig':   \n",
    "        below_metering_16 += facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.SOURCE_TYPE_COUNT'][index]\n",
    "    elif facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.EMISSION_SRC_TYPE'][index] == 'Below Grade M-R Station  Gas Service  Inlet Pressure 100 to 300 psig':   \n",
    "        below_metering_16 += facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.SOURCE_TYPE_COUNT'][index]\n",
    "    elif facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.EMISSION_SRC_TYPE'][index] == 'Below Grade M-R Station  Gas Service  Inlet Pressure < 100 psig':   \n",
    "        below_metering_16 += facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.SOURCE_TYPE_COUNT'][index]\n",
    "# Above-grade 2016\n",
    "facility_temp = facility_above_2018[facility_above_2018['EF_W_EQUIP_LEAKS_NGDIST_LEAKS.REPORTING_YEAR'] == 2016]\n",
    "facility_temp = facility_temp[facility_temp['EF_W_EQUIP_LEAKS_NGDIST_LEAKS.FACILITY_ID']==1001583]\n",
    "facility_temp.reset_index(drop=True,inplace=True)\n",
    "above_transfer_16 = facility_temp['EF_W_EQUIP_LEAKS_NGDIST_LEAKS.TOTAL_TD_FACILITY_STATIONS'][0]\n",
    "above_metering_16 = facility_temp['EF_W_EQUIP_LEAKS_NGDIST_LEAKS.TOTAL_NON_TD_FACILITY_STATIONS'][0]  \n",
    "\n",
    "# Array of indices of 2012 (start_year)-2014 entries for facility 1001583\n",
    "index_array = np.zeros(2015-start_year)\n",
    "facility_temp = facility_2014[facility_2014['W_LOCAL_DIST_COMPANIES_DETAILS.FACILITY_ID']==1001583]\n",
    "for iyear in np.arange(2015-start_year):\n",
    "    index_array[iyear] = facility_temp[facility_temp['W_LOCAL_DIST_COMPANIES_DETAILS.REPORTING_YEAR']==start_year+iyear].index.values.astype(int)[0]\n",
    "    # Replace 2012 (start_year)-2014 with 2016 counts\n",
    "    facility_2014.at[int(index_array[iyear]),'W_LOCAL_DIST_COMPANIES_DETAILS.ABOVE_GRADE_METERING_STATIONS'] = above_metering_16\n",
    "    facility_2014.at[int(index_array[iyear]),'W_LOCAL_DIST_COMPANIES_DETAILS.ABOVE_GRADE_TRANSFER_STATIONS'] = above_transfer_16\n",
    "    facility_2014.at[int(index_array[iyear]),'W_LOCAL_DIST_COMPANIES_DETAILS.BELOW_GRADE_METERING_STATIONS'] = below_metering_16\n",
    "    facility_2014.at[int(index_array[iyear]),'W_LOCAL_DIST_COMPANIES_DETAILS.BELOW_GRADE_TRANSFER_STATIONS'] = below_transfer_16\n",
    "\n",
    "    \n",
    "# Replace 2015 with 2016 counts, \n",
    "# below-grade - zero out metering/transfer inputs and add 2016 total to one cell so it is counted later\n",
    "for index in np.arange(len(facility_2018)):\n",
    "    if facility_2018['EF_W_EQUIP_LEAKS_POP_COUNT.REPORTING_YEAR'][index]==2015:\n",
    "        if facility_2018['EF_W_EQUIP_LEAKS_POP_COUNT.FACILITY_ID'][index]==1001583:\n",
    "            if facility_2018['EF_W_EQUIP_LEAKS_POP_COUNT.EMISSION_SRC_TYPE'][index] == 'Below Grade T-D Station  Gas Service  Inlet Pressure > 300 psig':   \n",
    "                facility_2018.at[index,'EF_W_EQUIP_LEAKS_POP_COUNT.SOURCE_TYPE_COUNT'] = 0\n",
    "            elif facility_2018['EF_W_EQUIP_LEAKS_POP_COUNT.EMISSION_SRC_TYPE'][index] == 'Below Grade T-D Station  Gas Service  Inlet Pressure 100 to 300 psig':   \n",
    "                facility_2018.at[index,'EF_W_EQUIP_LEAKS_POP_COUNT.SOURCE_TYPE_COUNT'] = 0\n",
    "            elif facility_2018['EF_W_EQUIP_LEAKS_POP_COUNT.EMISSION_SRC_TYPE'][index] == 'Below Grade T-D Station  Gas Service  Inlet Pressure < 100 psig':   \n",
    "                facility_2018.at[index,'EF_W_EQUIP_LEAKS_POP_COUNT.SOURCE_TYPE_COUNT'] = 0\n",
    "            elif facility_2018['EF_W_EQUIP_LEAKS_POP_COUNT.EMISSION_SRC_TYPE'][index] == 'Below Grade M-R Station  Gas Service  Inlet Pressure > 300 psig':   \n",
    "                facility_2018.at[index,'EF_W_EQUIP_LEAKS_POP_COUNT.SOURCE_TYPE_COUNT'] = 0\n",
    "            elif facility_2018['EF_W_EQUIP_LEAKS_POP_COUNT.EMISSION_SRC_TYPE'][index] == 'Below Grade M-R Station  Gas Service  Inlet Pressure 100 to 300 psig':   \n",
    "                facility_2018.at[index,'EF_W_EQUIP_LEAKS_POP_COUNT.SOURCE_TYPE_COUNT'] = 0\n",
    "            elif facility_2018['EF_W_EQUIP_LEAKS_POP_COUNT.EMISSION_SRC_TYPE'][index] == 'Below Grade M-R Station  Gas Service  Inlet Pressure < 100 psig':   \n",
    "                facility_2018.at[index,'EF_W_EQUIP_LEAKS_POP_COUNT.SOURCE_TYPE_COUNT'] = 0\n",
    "# Add in new below-grade\n",
    "facility_temp = facility_2018[facility_2018['EF_W_EQUIP_LEAKS_POP_COUNT.REPORTING_YEAR']==2015]\n",
    "facility_temp = facility_temp[facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.FACILITY_ID']==1001583]\n",
    "index_below_15 = facility_temp[facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.EMISSION_SRC_TYPE']=='Below Grade T-D Station  Gas Service  Inlet Pressure > 300 psig'].index.values.astype(int)[0]\n",
    "facility_2018.at[int(index_below_15),'EF_W_EQUIP_LEAKS_POP_COUNT.SOURCE_TYPE_COUNT'] = below_metering_16 + below_transfer_16\n",
    "\n",
    "# Change above-grade 2015 to 2016 values\n",
    "facility_temp = facility_above_2018[facility_above_2018['EF_W_EQUIP_LEAKS_NGDIST_LEAKS.FACILITY_ID']==1001583]\n",
    "index_15 = facility_temp[facility_temp['EF_W_EQUIP_LEAKS_NGDIST_LEAKS.REPORTING_YEAR']==2015].index.values.astype(int)[0]\n",
    "\n",
    "facility_above_2018.at[int(index_15),'EF_W_EQUIP_LEAKS_NGDIST_LEAKS.TOTAL_TD_FACILITY_STATIONS'] = above_transfer_16\n",
    "facility_above_2018.at[int(index_15),'EF_W_EQUIP_LEAKS_NGDIST_LEAKS.TOTAL_NON_TD_FACILITY_STATIONS'] = above_metering_16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 7:\n",
    "# UT huge increase in stations 2018, with corresponding increase in stations/mileage ratio; \n",
    "# Cause:\n",
    "# facility 1004977 reported about 1000 more above-grade stations 2017-2018.\n",
    "# EPA Solution:\n",
    "# Use the 2017 above-grade value for 2018.\n",
    "\n",
    "# Count stations company reported in 2017\n",
    "facility_temp = facility_above_2018[facility_above_2018['EF_W_EQUIP_LEAKS_NGDIST_LEAKS.REPORTING_YEAR'] == 2017]\n",
    "facility_temp = facility_temp[facility_temp['EF_W_EQUIP_LEAKS_NGDIST_LEAKS.FACILITY_ID']==1004977]\n",
    "facility_temp.reset_index(drop=True,inplace=True)\n",
    "above_transfer_17 = facility_temp['EF_W_EQUIP_LEAKS_NGDIST_LEAKS.TOTAL_TD_FACILITY_STATIONS'][0]\n",
    "above_metering_17 = facility_temp['EF_W_EQUIP_LEAKS_NGDIST_LEAKS.TOTAL_NON_TD_FACILITY_STATIONS'][0]\n",
    "\n",
    "# Replace 2018 values with 2017 values\n",
    "facility_temp = facility_above_2018[facility_above_2018['EF_W_EQUIP_LEAKS_NGDIST_LEAKS.FACILITY_ID']==1004977]\n",
    "index_18 = facility_temp[facility_temp['EF_W_EQUIP_LEAKS_NGDIST_LEAKS.REPORTING_YEAR']==2018].index.values.astype(int)[0]\n",
    "facility_above_2018.at[int(index_15),'EF_W_EQUIP_LEAKS_NGDIST_LEAKS.TOTAL_TD_FACILITY_STATIONS'] = above_transfer_17\n",
    "facility_above_2018.at[int(index_15),'EF_W_EQUIP_LEAKS_NGDIST_LEAKS.TOTAL_NON_TD_FACILITY_STATIONS'] = above_metering_17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.5.3 Calculating State-Level GHGRP Metering/Transfer Station Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum the metering/transfer stations for each State\n",
    "\n",
    "Stations_above = np.zeros((len(State_ANSI),num_years))\n",
    "Stations_below = np.zeros((len(State_ANSI),num_years))\n",
    "\n",
    "# for each reporting year, sum the station counts for each state\n",
    "\n",
    "# a) Stations 2012 (start_year)-2014: above and below\n",
    "for iyear in np.arange(2015-start_year):\n",
    "    facility_temp = facility_2014[facility_2014['W_LOCAL_DIST_COMPANIES_DETAILS.REPORTING_YEAR'] == iyear+start_year]\n",
    "    facility_temp.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    for index in np.arange(len(facility_temp)):\n",
    "        match_state = np.where(State_ANSI['abbr'] == facility_temp['state'][index])[0][0]\n",
    "\n",
    "        Stations_above[match_state][iyear] += facility_temp['W_LOCAL_DIST_COMPANIES_DETAILS.ABOVE_GRADE_METERING_STATIONS'][index]\n",
    "        Stations_above[match_state][iyear] += facility_temp['W_LOCAL_DIST_COMPANIES_DETAILS.ABOVE_GRADE_TRANSFER_STATIONS'][index]\n",
    "        Stations_below[match_state][iyear] += facility_temp['W_LOCAL_DIST_COMPANIES_DETAILS.BELOW_GRADE_METERING_STATIONS'][index]\n",
    "        Stations_below[match_state][iyear] += facility_temp['W_LOCAL_DIST_COMPANIES_DETAILS.BELOW_GRADE_TRANSFER_STATIONS'][index]\n",
    "\n",
    "# b) Stations 2015-2018\n",
    "# Below\n",
    "for iyear in np.arange(2015-start_year,num_years):\n",
    "    facility_temp = facility_2018[facility_2018['EF_W_EQUIP_LEAKS_POP_COUNT.REPORTING_YEAR'] == iyear+start_year]\n",
    "    facility_temp.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    for index in np.arange(len(facility_temp)):\n",
    "        match_state = np.where(State_ANSI['abbr'] == facility_temp['state'][index])[0][0]\n",
    "    \n",
    "        if facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.EMISSION_SRC_TYPE'][index] == 'Below Grade T-D Station  Gas Service  Inlet Pressure > 300 psig':   \n",
    "            Stations_below[match_state][iyear] += facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.SOURCE_TYPE_COUNT'][index]\n",
    "        elif facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.EMISSION_SRC_TYPE'][index] == 'Below Grade T-D Station  Gas Service  Inlet Pressure 100 to 300 psig':   \n",
    "            Stations_below[match_state][iyear] += facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.SOURCE_TYPE_COUNT'][index] \n",
    "        elif facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.EMISSION_SRC_TYPE'][index] == 'Below Grade T-D Station  Gas Service  Inlet Pressure < 100 psig':   \n",
    "            Stations_below[match_state][iyear] += facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.SOURCE_TYPE_COUNT'][index]\n",
    "        elif facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.EMISSION_SRC_TYPE'][index] == 'Below Grade M-R Station  Gas Service  Inlet Pressure > 300 psig':   \n",
    "            Stations_below[match_state][iyear] += facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.SOURCE_TYPE_COUNT'][index]\n",
    "        elif facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.EMISSION_SRC_TYPE'][index] == 'Below Grade M-R Station  Gas Service  Inlet Pressure 100 to 300 psig':   \n",
    "            Stations_below[match_state][iyear] += facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.SOURCE_TYPE_COUNT'][index]\n",
    "        elif facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.EMISSION_SRC_TYPE'][index] == 'Below Grade M-R Station  Gas Service  Inlet Pressure < 100 psig':   \n",
    "            Stations_below[match_state][iyear] += facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.SOURCE_TYPE_COUNT'][index]\n",
    "\n",
    "# Above\n",
    "for iyear in np.arange(2015-start_year,num_years):\n",
    "    facility_temp = facility_above_2018[facility_above_2018['EF_W_EQUIP_LEAKS_NGDIST_LEAKS.REPORTING_YEAR'] == iyear+start_year]\n",
    "    facility_temp.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    for index in np.arange(len(facility_temp)):\n",
    "        match_state = np.where(State_ANSI['abbr'] == facility_temp['state'][index])[0][0]\n",
    "\n",
    "        Stations_above[match_state][iyear] += facility_temp['EF_W_EQUIP_LEAKS_NGDIST_LEAKS.TOTAL_TD_FACILITY_STATIONS'][index]\n",
    "        Stations_above[match_state][iyear] += facility_temp['EF_W_EQUIP_LEAKS_NGDIST_LEAKS.TOTAL_NON_TD_FACILITY_STATIONS'][index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.5.4 Fixing GHGRP Data Inconsistencies in Mileage Reporting\n",
    "There are a few reporting inconsistencies in the GHGRP data.\n",
    "Below are 2 known problems, their causes, EPA's proposed solutions, and their implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 1:\n",
    "# GHGRP facility no. 1006503 didn't report mileage in 2012.\n",
    "# EPA Solution:\n",
    "# We have compared the GHGRP-reported data with the data the facility reported to the U.S. Department of Transportation\n",
    "# – Pipeline and Hazardous Material Safety Administration (PHMSA). PHMSA-reported data appear similar to GHGRP reported\n",
    "# data for 2013, but much higher (and more similar to 2013) than the GHGRP reported data for 2012. The 2012 and 2013 \n",
    "# data in PHMSA appear to be similar so it seems like a good approach to extend back with the 2013-2018 GHGRP data.\n",
    "# To do this, the the facility address has to be crosswalked with the PHMSA data. The operator ID for this particular \n",
    "# GHGRP reporter in the PHMSA dataset is 12408.\n",
    "\n",
    "# Read 2012 PHMSA data\n",
    "phmsa_2012 = pd.read_csv(phmsa_gas_distr_2012_inputfile,header=2)\n",
    "phmsa_temp = phmsa_2012[phmsa_2012['OPERATOR_ID']==12408] #access row of company\n",
    "\n",
    "# Store mileage values of unprotected steel, protected steel, plastic, and cast iron\n",
    "usteel = phmsa_temp['MMILES_STEEL_UNP_BARE'].iloc[0]+phmsa_temp['MMILES_STEEL_UNP_COATED'].iloc[0]\n",
    "psteel = phmsa_temp['MMILES_STEEL_CP_BARE'].iloc[0]+phmsa_temp['MMILES_STEEL_CP_COATED'].iloc[0]\n",
    "plastic = phmsa_temp['MMILES_PLASTIC'].iloc[0]\n",
    "castiron = phmsa_temp['MMILES_CI'].iloc[0]\n",
    "\n",
    "# Find index of 2012 row for company 1006503\n",
    "facility_temp = facility_2014[facility_2014['W_LOCAL_DIST_COMPANIES_DETAILS.FACILITY_ID']==1006503]\n",
    "index_2012 = facility_temp[facility_temp['W_LOCAL_DIST_COMPANIES_DETAILS.REPORTING_YEAR']==2012].index.values.astype(int)[0]\n",
    "\n",
    "# Change mileage values in facility_2014 to PHMSA values\n",
    "facility_2014.at[index_2012,'W_LOCAL_DIST_COMPANIES_DETAILS.MILES_OF_UNPR_STEEL_DIST_MAINS'] = usteel\n",
    "facility_2014.at[index_2012,'W_LOCAL_DIST_COMPANIES_DETAILS.MILES_OF_PROT_STEEL_DIST_MAINS'] = psteel\n",
    "facility_2014.at[index_2012,'W_LOCAL_DIST_COMPANIES_DETAILS.MILES_OF_PLSTIC_DIST_MAINS'] = plastic\n",
    "facility_2014.at[index_2012,'W_LOCAL_DIST_COMPANIES_DETAILS.MILES_OF_CAST_IRON_DIST_MAINS'] = castiron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 2:\n",
    "# Abrupt mileage jump 2012-2013 of ~3500 mi.\n",
    "# Cause: \n",
    "# GHGRP facility 1003050 didn’t report plastic/protected steel mileage in 2012, but reports consistent nonzero \n",
    "# values for all later years.\n",
    "# EPA Solution:\n",
    "# Data from the facility are also available from PHMSA. PHMSA-reported data appear similar to GHGRP reported \n",
    "# data for 2013, but much higher (and more similar to 2013) the GHGRP reported data for 2012. The best solution \n",
    "# seems to be replacing the 2012 GHGRP data with data from PHMSA. The operator ID for this GHGRP reporter in \n",
    "# the PHMSA dataset is 31232.\n",
    "\n",
    "# Read 2012 PHMSA data\n",
    "phmsa_2012 = pd.read_csv(phmsa_gas_distr_2012_inputfile,header=2)\n",
    "phmsa_temp = phmsa_2012[phmsa_2012['OPERATOR_ID']==31232] #access rows of company (there are 3 entries, last is most recent)\n",
    "phmsa_temp.reset_index(inplace=True)\n",
    "phmsa_temp.drop(labels=[0,1], axis=0, inplace=True) #isolate most recent entry\n",
    "\n",
    "# Store mileage values of protected steel and plastic\n",
    "psteel = phmsa_temp['MMILES_STEEL_CP_BARE'].iloc[0]+phmsa_temp['MMILES_STEEL_CP_COATED'].iloc[0]\n",
    "plastic = phmsa_temp['MMILES_PLASTIC'].iloc[0]\n",
    "\n",
    "# Find index of 2012 row for company 1003050\n",
    "facility_temp = facility_2014[facility_2014['W_LOCAL_DIST_COMPANIES_DETAILS.FACILITY_ID']==1003050]\n",
    "index_2012 = facility_temp[facility_temp['W_LOCAL_DIST_COMPANIES_DETAILS.REPORTING_YEAR']==2012].index.values.astype(int)[0]\n",
    "\n",
    "# Change mileage values in facility_2014 to PHMSA values\n",
    "facility_2014.at[index_2012,'W_LOCAL_DIST_COMPANIES_DETAILS.MILES_OF_PROT_STEEL_DIST_MAINS'] = psteel\n",
    "facility_2014.at[index_2012,'W_LOCAL_DIST_COMPANIES_DETAILS.MILES_OF_PLSTIC_DIST_MAINS'] = plastic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.5.5 Sum GHGRP Pipeline Mileage Totals by State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding up mileage of pipelines from GHGRP by State\n",
    "Mains_total = np.zeros((len(State_ANSI),num_years))\n",
    "\n",
    "# For each year, add up the piepline mileage of each type in each state\n",
    "\n",
    "# a) 2012 (start year)-2014: add up mains mileage total\n",
    "for iyear in np.arange(2015-start_year):\n",
    "    facility_temp = facility_2014[facility_2014['W_LOCAL_DIST_COMPANIES_DETAILS.REPORTING_YEAR'] == iyear+start_year]\n",
    "    facility_temp.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    for index in np.arange(len(facility_temp)):\n",
    "        match_state = np.where(State_ANSI['abbr'] == facility_temp['state'][index])[0][0]\n",
    "\n",
    "        Mains_total[match_state][iyear] += facility_temp['W_LOCAL_DIST_COMPANIES_DETAILS.MILES_OF_CAST_IRON_DIST_MAINS'][index]\n",
    "        Mains_total[match_state][iyear] += facility_temp['W_LOCAL_DIST_COMPANIES_DETAILS.MILES_OF_PLSTIC_DIST_MAINS'][index]\n",
    "        Mains_total[match_state][iyear] += facility_temp['W_LOCAL_DIST_COMPANIES_DETAILS.MILES_OF_PROT_STEEL_DIST_MAINS'][index]\n",
    "        Mains_total[match_state][iyear] += facility_temp['W_LOCAL_DIST_COMPANIES_DETAILS.MILES_OF_UNPR_STEEL_DIST_MAINS'][index]\n",
    "\n",
    "# b) 2015-2018 (end year): add up mains mileage total\n",
    "for iyear in np.arange(2015-start_year,num_years):\n",
    "    facility_temp = facility_2018[facility_2018['EF_W_EQUIP_LEAKS_POP_COUNT.REPORTING_YEAR'] == iyear+start_year]\n",
    "    facility_temp.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    for index in np.arange(len(facility_temp)):\n",
    "        match_state = np.where(State_ANSI['abbr'] == facility_temp['state'][index])[0][0]\n",
    "    \n",
    "        if facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.EMISSION_SRC_TYPE'][index] == 'Distribution Mains  Gas Service - Cast Iron':   \n",
    "            Mains_total[match_state][iyear] += facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.SOURCE_TYPE_COUNT'][index]\n",
    "        elif facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.EMISSION_SRC_TYPE'][index] == 'Distribution Mains  Gas Service - Unprotected Steel':   \n",
    "            Mains_total[match_state][iyear] += facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.SOURCE_TYPE_COUNT'][index]\n",
    "        elif facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.EMISSION_SRC_TYPE'][index] == 'Distribution Mains  Gas Service - Protected Steel':   \n",
    "            Mains_total[match_state][iyear] += facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.SOURCE_TYPE_COUNT'][index]\n",
    "        elif facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.EMISSION_SRC_TYPE'][index] == 'Distribution Mains  Gas Service - Plastic':   \n",
    "            Mains_total[match_state][iyear] += facility_temp['EF_W_EQUIP_LEAKS_POP_COUNT.SOURCE_TYPE_COUNT'][index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.5.6 Scaling GHGRP Station Count Data Using PHMSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some states have no reported station counts, even when reporting pipeline mileage. However, not all states\n",
    "# report pipeline mileage either (CHECK ON THIS). In addition, GHGRP-reported \n",
    "# station counts for states with data may also be underestimates (due to threshold reporting requirements). \n",
    "# For States with GHGRP reported station counts, we scale the GHGRP station counts (above/below-grade) in each \n",
    "# state using the proportion of PHMSA pipeline mileage to GHGRP reported pipeline mileage (assuming that \n",
    "# any possible station under-reporting is proportional with any possible pipeline mileage underreporting.\n",
    "# E.g., Total Station Counts = GHGRP Station counts * (PHMSA mileage/ GHGRP mileage). \n",
    "# For states with no GHGRP reported station counts, we take the average ratio of the GHGRP station counts \n",
    "# (above/below-grade) relative to the PHMSA mileage for states with GHGRP data, and then apply that ratio \n",
    "# to the other states without GHGRP station count data\n",
    "# E.g., Station Counts = PHMSA mileage * (sum GHGRP station counts for all states with data/ sum PHMSA mileage for same states)\n",
    "\n",
    "# Initialize state-level station count arrays\n",
    "stations_above_state = np.zeros([len(State_ANSI),num_years])\n",
    "stations_below_state = np.zeros([len(State_ANSI),num_years])\n",
    "stations_state = np.zeros([len(State_ANSI),num_years])\n",
    "\n",
    "# SET DIVIDE BY ZERO AND INVALID VALUE WARNING OFF\n",
    "np.seterr(divide = 'ignore') \n",
    "np.seterr(invalid='ignore')\n",
    "\n",
    "# a) States with GHGRP reported data: estimate total number of stations by scaling GHGRP reported mileage to PHMSA mileage \n",
    "for iyear in np.arange(num_years):\n",
    "    for istate in np.arange(len(State_ANSI)):\n",
    "        stations_above_state[istate,iyear] = Stations_above[istate,iyear] * \\\n",
    "                                            ( PHMSA_mains_total[istate,iyear] / Mains_total[istate,iyear])\n",
    "        stations_below_state[istate,iyear] = Stations_below[istate,iyear] * \\\n",
    "                                            ( PHMSA_mains_total[istate,iyear] / Mains_total[istate,iyear])\n",
    "    \n",
    "#TURN ALL WARNINGS BACK ON\n",
    "np.seterr('warn')\n",
    "\n",
    "# will fill NaN if divide by zero error, replace with zero                                           \n",
    "stations_above_state = np.nan_to_num(stations_above_state) \n",
    "stations_below_state = np.nan_to_num(stations_below_state) \n",
    "\n",
    "# b) States with no GHGRP reported data: estimate using the ratio of station counts to PHMSA milage for states with data\n",
    "ratio_stations_above_pipeline = np.sum(stations_above_state[stations_above_state>0]) / np.sum(PHMSA_mains_total[stations_above_state>0])\n",
    "ratio_stations_below_pipeline = np.sum(stations_below_state[stations_below_state>0]) / np.sum(PHMSA_mains_total[stations_below_state>0])\n",
    "for iyear in np.arange(num_years):\n",
    "    for istate in np.arange(len(State_ANSI)-6): #only consider states & DC, not territories\n",
    "        if stations_above_state[istate,iyear]==0:\n",
    "            stations_above_state[istate,iyear] = ratio_stations_above_pipeline * PHMSA_mains_total[istate,iyear]\n",
    "        if stations_below_state[istate,iyear]==0:\n",
    "            stations_below_state[istate,iyear] = ratio_stations_below_pipeline * PHMSA_mains_total[istate,iyear]\n",
    "            \n",
    "# Print time\n",
    "ct = datetime.datetime.now() \n",
    "print(\"current time:\", ct) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "## Step 3. Read in and Format US EPA GHGI Data\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Emissions are in units of MG (= 1x10-6 Tg, 1e-3 kt)\n",
    "\n",
    "# METHANE\n",
    "names = pd.read_excel(EPA_NG_inputfile, sheet_name = \"Inventory Emissions\", usecols = \"A:AG\", skiprows = 5, header = 0, nrows = 1)\n",
    "colnames = names.columns.values\n",
    "EPA_emi_dist_NG = pd.read_excel(EPA_NG_inputfile, sheet_name = \"Inventory Emissions\", usecols = \"A:AG\", skiprows = 205, names = colnames, nrows = 30)\n",
    "EPA_emi_dist_NG= EPA_emi_dist_NG.drop(columns = ['Unnamed: 0', 'Unnamed: 1', 'Unnamed: 3'])\n",
    "EPA_emi_dist_NG['Source']= EPA_emi_dist_NG['Source'].str.replace(r\"\\(\",\"\")\n",
    "EPA_emi_dist_NG['Source']= EPA_emi_dist_NG['Source'].str.replace(r\"\\)\",\"\")\n",
    "EPA_emi_dist_NG = EPA_emi_dist_NG.fillna('')\n",
    "EPA_emi_dist_NG = EPA_emi_dist_NG.drop(columns = [*range(1990, start_year,1)])\n",
    "EPA_emi_dist_NG.reset_index(inplace=True, drop=True)\n",
    "display(EPA_emi_dist_NG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3.1.2. Read in Total Distribution Emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in total processing emissions (with methane reductions accounted for)\n",
    "# data are in kt\n",
    "\n",
    "#CH4\n",
    "names = pd.read_excel(EPA_NG_inputfile, sheet_name = \"SUMMARY CH4\", usecols = \"A:AD\", skiprows = 10, header = 0, nrows = 1)\n",
    "colnames = names.columns.values\n",
    "EPA_emi_total_NG_CH4 = pd.read_excel(EPA_NG_inputfile, sheet_name = \"SUMMARY CH4\", usecols = \"A:AD\", skiprows = 17, names = colnames, nrows = 5)\n",
    "EPA_emi_total_NG_CH4.rename(columns={EPA_emi_total_NG_CH4.columns[0]:'Source'}, inplace=True)\n",
    "EPA_emi_total_NG_CH4 = EPA_emi_total_NG_CH4.drop(columns = [*range(1990, start_year,1)])\n",
    "EPA_emi_total_NG_CH4.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print(\"EPA GHGI Emissions with Reductions (kt)\")\n",
    "display(EPA_emi_total_NG_CH4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.3. Split Emissions into Gridding Groups (each Group will have the same proxy applied during the gridding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Emissions in Units of kt\n",
    "# Use mapping proxy and source files to split the GHGI emissions\n",
    "\n",
    "DEBUG=1\n",
    "start_year_idx = EPA_emi_dist_NG.columns.get_loc(start_year)\n",
    "end_year_idx = EPA_emi_dist_NG.columns.get_loc(end_year)+1\n",
    "sum_emi = np.zeros(num_years)\n",
    "\n",
    "for igroup in np.arange(0,len(emi_group_names)): #loop through all groups, finding the GHGI sources in that group and summing emissions for that region, year\n",
    "    vars()[emi_group_names[igroup]] = np.zeros([num_years])\n",
    "    ##DEBUG ## print('here3',ghgi_dist_groups[igroup], np.shape(vars()[ghgi_dist_groups[igroup]]))\n",
    "    source_temp = ghgi_dist_map.loc[ghgi_dist_map['GHGI_Emi_Group'] == emi_group_names[igroup], 'GHGI_Source']\n",
    "    pattern_temp  = '|'.join(source_temp)\n",
    "    ##DEBUG ## display(pattern_temp)\n",
    "    emi_temp = EPA_emi_dist_NG[EPA_emi_dist_NG['Source'].str.contains(pattern_temp)]\n",
    "    ##DEBUG ## display(emi_temp)\n",
    "    vars()[emi_group_names[igroup]][:] = np.where(emi_temp.iloc[:,start_year_idx:] =='',[0],emi_temp.iloc[:,start_year_idx:]).sum(axis=0)/float(1000) #convert Mg to kt\n",
    "\n",
    "\n",
    "#Check against total summary emissions \n",
    "print('QA/QC #1: Check Processing Emission Sum against GHGI Summary Emissions')\n",
    "for iyear in np.arange(0,num_years): \n",
    "    for igroup in np.arange(0,len(emi_group_names)):\n",
    "        sum_emi[iyear] += vars()[emi_group_names[igroup]][iyear]\n",
    "            #print(np.sum(vars()[ghgi_prod_groups[igroup]][iyear]))\n",
    "        \n",
    "    summary_emi = EPA_emi_total_NG_CH4.iloc[4,iyear+1]  \n",
    "    #Check 1 - make sure that the sums from all the regions equal the totals reported\n",
    "    diff1 = abs(sum_emi[iyear] - summary_emi)/((sum_emi[iyear] + summary_emi)/2)\n",
    "    if DEBUG==1:\n",
    "        print(summary_emi)\n",
    "        print(sum_emi[iyear])\n",
    "    if diff1 < 0.0001:\n",
    "        print('Year ', year_range[iyear],': PASS, difference < 0.01%')\n",
    "    else:\n",
    "        print('Year ', year_range[iyear],': FAIL (check Production & summary tabs): ', diff1,'%') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------\n",
    "## Step 4. Grid Emissions\n",
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step. 4.1. Calculate the monthly and regional weighted arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 4.1.1 Assign the Appropriate Proxy Variable Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The names on the *left* need to match the 'NaturalGas_Distribution_ProxyMapping' 'Proxy_Group' names \n",
    "# (these are initialized in Step 2). \n",
    "# The names on the right are the variable names used to caluclate the proxies in this code.\n",
    "# Names on the *right* need to match those from the code in Step 2.5\n",
    "\n",
    "State_Main_CastIron = main_castiron\n",
    "State_Main_Usteel = main_usteel\n",
    "State_Main_Psteel = main_psteel\n",
    "State_Main_Plastic = main_plastic\n",
    "State_Serv_Usteel = serv_usteel\n",
    "State_Serv_Psteel = serv_psteel\n",
    "State_Serv_Plastic = serv_plastic\n",
    "State_Serv_Copper = serv_copper\n",
    "State_MR_Above = stations_above_state\n",
    "State_MR_Below = stations_below_state\n",
    "State_Residential = res_counts\n",
    "State_CommIndu = indcom_counts\n",
    "State_Meter = main_castiron + main_usteel + main_psteel + main_plastic\n",
    "\n",
    "Map_population = pop_den_map*area_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.2. Allocate National EPA Emissions to the State-Level\n",
    "Allocation based on state-level pipeline mileage (PHMSA), leak volume (EIA), and station counts (PHMSA-corrected GHGRP data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate state-level emissions from all pieline types, service and metering stations, and leak losses.\n",
    "# Emissions are calculated as a running sum of the as the national emissions, weighted a) by the pipeline\n",
    "# mileage in each state relative to the national total (by type and for all types), by b) the number of service/metering \n",
    "# stations in each state relative to the national total, and by c) the leak volume in each state relative\n",
    "# to the national total. Emissions in kt\n",
    "\n",
    "DEBUG =1\n",
    "\n",
    "# Data here are from the:\n",
    "# 1) most recent EPA GHGI (emi_main_[type], emi_serv_[type], emi_mr_[above/below], emi_leak, emi_meter, )\n",
    "# 2) yearly EIA leak loss volume data (leakvolume)\n",
    "# 3) pre-2015 and more recent GHGRP data, scaled by PHMSA data (stations_[below/above]_state)\n",
    "# 4) most recent PHMSA pipeline milaege data (main_[type], serv_[type])\n",
    "# also note that national emissions are retained for groups that do not have state proxies identified in the mapping file\n",
    "# and are later gridded in the next step\n",
    "for igroup in np.arange(0,len(proxy_dist_map)):\n",
    "    vars()['State_'+proxy_dist_map.loc[igroup,'GHGI_Emi_Group']] = np.zeros([len(State_ANSI),num_years])\n",
    "    vars()['NonState_'+proxy_dist_map.loc[igroup,'GHGI_Emi_Group']] = np.zeros([num_years])\n",
    "        \n",
    "#Loop over years\n",
    "for iyear in np.arange(num_years):\n",
    "    #Loop over states\n",
    "    for istate in np.arange(len(State_ANSI)):\n",
    "        for igroup in np.arange(0,len(proxy_dist_map)):    \n",
    "            if proxy_dist_map.loc[igroup,'State_Proxy_Group'] != '-':\n",
    "                vars()['State_'+proxy_dist_map.loc[igroup,'GHGI_Emi_Group']][istate,iyear] = vars()[proxy_dist_map.loc[igroup,'GHGI_Emi_Group']][iyear] * \\\n",
    "                    data_fn.safe_div(vars()[proxy_dist_map.loc[igroup,'State_Proxy_Group']][istate,iyear], np.sum(vars()[proxy_dist_map.loc[igroup,'State_Proxy_Group']][:,iyear]))\n",
    "            else:\n",
    "                vars()['NonState_'+proxy_dist_map.loc[igroup,'GHGI_Emi_Group']][iyear] = vars()[proxy_dist_map.loc[igroup,'GHGI_Emi_Group']][iyear]\n",
    "                \n",
    "# Check sum of all gridded emissions + emissions not included in gridding (e.g., AK), and other non-gridded areas\n",
    "print('QA/QC #1: Check weighted emissions against GHGI')   \n",
    "for iyear in np.arange(0,num_years):\n",
    "    summary_emi = EPA_emi_total_NG_CH4.iloc[4,iyear+1]\n",
    "    calc_emi = 0\n",
    "    for igroup in np.arange(0,len(proxy_dist_map)):\n",
    "        calc_emi +=  np.sum(vars()['State_'+proxy_dist_map.loc[igroup,'GHGI_Emi_Group']][:,iyear])+\\\n",
    "            vars()['NonState_'+proxy_dist_map.loc[igroup,'GHGI_Emi_Group']][iyear] #np.sum(Emissions[:,iyear]) + Emissions_nongrid[iyear] + Emissions_nonstate[iyear]\n",
    "    if DEBUG==1:\n",
    "        print(summary_emi)\n",
    "        print(calc_emi)\n",
    "    diff = abs(summary_emi-calc_emi)/((summary_emi+calc_emi)/2)\n",
    "    if diff < 0.0002:\n",
    "        print('Year ', year_range[iyear], ': PASS, difference < 0.01%')\n",
    "    else:\n",
    "        print('Year ', year_range[iyear], ': FAIL -- Difference = ', diff*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4.1.3. Calculate Gridded Emissions (0.1x0.1 degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Allocate State-Level emissions (kt) onto a 0.01x0.01 grid (weighted by population in each grid cell relative to state total)\n",
    "\n",
    "#Define emission arrays\n",
    "Emissions_array = np.zeros([area_map.shape[0],area_map.shape[1],num_years])\n",
    "Emissions_array_01 = np.zeros([len(Lat_01),len(Lon_01),num_years])\n",
    "Emissions_nongrid = np.zeros(num_years)\n",
    "\n",
    "DEBUG = 1\n",
    "\n",
    "# For each year, (2a) distribute state-level emissions onto a grid using proxies defined above ....\n",
    "# To speed up the code, masks are used rather than looping individually through each lat/lon. \n",
    "# In this case, a mask of 1's is made for the grid cells that match the ANSI values for a given state\n",
    "# The masked values are set to zero, remaining values = 1. \n",
    "# AK and HI and territories are removed from the analysis at this stage. \n",
    "# The emissions allocated to each state are at 0.01x0.01 degree resolution, as required to calculate accurate 'mask'\n",
    "# arrays for each state. \n",
    "# (2b - NA here) For emission groups that were not first allocated to states, national emissions for those groups are gridded\n",
    "# based on the relevant gridded proxy arrays (0.1x0.1 resolution). These emissions are at 0.1x0.1 degrees resolution. \n",
    "# (2c - NA here) - record 'not mapped' emission groups in the 'non-grid' array\n",
    "\n",
    "print('**QA/QC Check: Sum of national gridded emissions vs. GHGI national emissions')\n",
    "for igroup in np.arange(len(proxy_dist_map)):\n",
    "    vars()['Ext_'+proxy_dist_map.loc[igroup,'GHGI_Emi_Group']] = np.zeros([len(Lat_01),len(Lon_01),num_years])\n",
    "    \n",
    "for iyear in np.arange(0,num_years):\n",
    "    if year_range[iyear]==2012 or year_range[iyear]==2016:\n",
    "        year_days = np.sum(month_day_leap)\n",
    "    else:\n",
    "        year_days = np.sum(month_day_nonleap)\n",
    "\n",
    "    #Step 1 - grid state level emissions with appropriate proxies \n",
    "    #running_count = 0\n",
    "    for istate in np.arange(0,len(State_ANSI)):\n",
    "        mask_state = np.ma.ones(np.shape(state_ANSI_map))\n",
    "        mask_state = np.ma.masked_where(state_ANSI_map != State_ANSI['ansi'][istate], mask_state)\n",
    "        mask_state = np.ma.filled(mask_state,0)   \n",
    "        #print(\"state \" + str(istate) +' of '+ str(len(State_ANSI)))\n",
    "        for igroup in np.arange(len(proxy_dist_map)):\n",
    "            proxy_temp = vars()[proxy_dist_map.loc[igroup,'Proxy_Group']]\n",
    "            \n",
    "            # 2a\n",
    "            if proxy_dist_map.loc[igroup,'State_Proxy_Group'] != '-':\n",
    "                if np.sum(mask_state*proxy_temp) > 0 and State_ANSI['abbr'][istate] not in {'AK','HI'} and istate < 51: \n",
    "                    weighted_array = data_fn.safe_div(mask_state*proxy_temp, np.sum(mask_state*proxy_temp))\n",
    "                    emi_temp = vars()['State_'+proxy_dist_map.loc[igroup,'GHGI_Emi_Group']][istate,iyear]*weighted_array\n",
    "                    Emissions_array[:,:,iyear] += emi_temp\n",
    "                    vars()['Ext_'+proxy_dist_map.loc[igroup,'GHGI_Emi_Group']][:,:,iyear] += data_fn.regrid001_to_01(emi_temp[:,:], Lat_01, Lon_01)\n",
    "                else:\n",
    "                    Emissions_nongrid[iyear] += vars()['State_'+proxy_dist_map.loc[igroup,'GHGI_Emi_Group']][istate][iyear] \n",
    "    \n",
    "    Emissions_array_01[:,:,iyear] += data_fn.regrid001_to_01(Emissions_array[:,:,iyear], Lat_01, Lon_01) #covert to 10x10km\n",
    "    calc_emi = np.sum(Emissions_array_01[:,:,iyear]) + Emissions_nongrid[iyear]\n",
    "    summary_emi = EPA_emi_total_NG_CH4.iloc[4,iyear+1]\n",
    "    emi_diff = abs(summary_emi-calc_emi)/((summary_emi+calc_emi)/2)\n",
    "    if DEBUG ==1:\n",
    "        print(calc_emi)\n",
    "        print(summary_emi)\n",
    "    if abs(emi_diff) < 0.0001:\n",
    "        print('Year '+ year_range_str[iyear]+': Difference < 0.01%: PASS')\n",
    "    else: \n",
    "        print('Year '+ year_range_str[iyear]+': Difference > 0.01%: FAIL, diff: '+str(emi_diff))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4.1.4 Save gridded emissions (kt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save gridded emissions for each gridding group - for extension\n",
    "\n",
    "#Initialize file\n",
    "data_IO_fn.initialize_netCDF(grid_emi_outputfile, netCDF_description, 0, year_range, loc_dimensions, Lat_01, Lon_01)\n",
    "\n",
    "unique_groups = np.unique(proxy_dist_map['GHGI_Emi_Group'])\n",
    "unique_groups = unique_groups[unique_groups != 'Emi_not_mapped']\n",
    "\n",
    "nc_out = Dataset(grid_emi_outputfile, 'r+', format='NETCDF4')\n",
    "\n",
    "for igroup in np.arange(0,len(unique_groups)):\n",
    "    print('Ext_'+unique_groups[igroup])\n",
    "    if len(np.shape(vars()['Ext_'+unique_groups[igroup]])) ==4:\n",
    "        ghgi_temp = np.sum(vars()[unique_groups[igroup]],axis=3) #sum month data if data is monthly\n",
    "    else:\n",
    "        ghgi_temp = vars()['Ext_'+unique_groups[igroup]]\n",
    "\n",
    "    # Write data to netCDF\n",
    "    data_out = nc_out.createVariable('Ext_'+unique_groups[igroup], 'f8', ('lat', 'lon','year'), zlib=True)\n",
    "    data_out[:,:,:] = ghgi_temp[:,:,:]\n",
    "\n",
    "#save nongrid data to calculate non-grid fraction extension\n",
    "data_out = nc_out.createVariable('Emissions_nongrid', 'f8', ('year'), zlib=True)  \n",
    "data_out[:] = Emissions_nongrid[:]\n",
    "nc_out.close()\n",
    "\n",
    "#Confirm file location\n",
    "print('** SUCCESS **')\n",
    "print(\"Gridded emissions (kt) written to file: {}\" .format(os.getcwd())+grid_emi_outputfile)\n",
    "print(' ')\n",
    "\n",
    "del data_out, ghgi_temp, nc_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Calculate Gridded Emission Fluxes (molec./cm2/s) (0.1x0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert emissions to emission flux\n",
    "# convert kt to molec/cm2/s\n",
    "\n",
    "DEBUG = 1\n",
    "\n",
    "Flux_array_01 = np.zeros([len(Lat_01), len(Lon_01),num_years])\n",
    "print('**QA/QC Check: Sum of national gridded emissions vs. GHGI national emissions')\n",
    "  \n",
    "for iyear in np.arange(0,num_years):\n",
    "    if year_range[iyear]==2012 or year_range[iyear]==2016:\n",
    "        year_days = np.sum(month_day_leap)\n",
    "    else:\n",
    "        year_days = np.sum(month_day_nonleap)\n",
    "\n",
    "    conversion_factor_01 = 10**9 * Avogadro / float(Molarch4 *year_days * 24 * 60 *60) / area_matrix_01\n",
    "    Flux_array_01[:,:,iyear] = Emissions_array_01[:,:,iyear]*conversion_factor_01\n",
    "    #convert back to mass to check\n",
    "    \n",
    "    calc_emi =  np.sum(Flux_array_01[:,:,iyear]/conversion_factor_01)+Emissions_nongrid[iyear] #+np.sum(Flux_array[:,:,iyear]/conversion_factor) \n",
    "    summary_emi = EPA_emi_total_NG_CH4.iloc[4,iyear+1]\n",
    "    emi_diff = abs(summary_emi-calc_emi)/((summary_emi+calc_emi)/2)\n",
    "    if DEBUG ==1:\n",
    "        print(calc_emi)\n",
    "        print(summary_emi)\n",
    "    if abs(emi_diff) < 0.0001:\n",
    "        print('Year '+ year_range_str[iyear]+': Difference < 0.01%: PASS')\n",
    "    else: \n",
    "        print('Year '+ year_range_str[iyear]+': Difference > 0.01%: FAIL, diff: '+str(emi_diff))\n",
    "        \n",
    "Flux_Emissions_Total_annual = Flux_array_01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "## Step 5. Write Gridded Data to File\n",
    "------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize netCDF file\n",
    "data_IO_fn.initialize_netCDF(gridded_outputfile, netCDF_description, 0, year_range, loc_dimensions, Lat_01, Lon_01)\n",
    "\n",
    "# Write data to netCDF\n",
    "nc_out = Dataset(gridded_outputfile, 'r+', format='NETCDF4')\n",
    "nc_out.variables['emi_ch4'][:,:,:] = Flux_Emissions_Total_annual\n",
    "nc_out.close()\n",
    "#Confirm file location\n",
    "print('** SUCCESS **')\n",
    "print(\"Gridded gas distribution fluxes written to file: {}\" .format(os.getcwd())+gridded_outputfile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "## Step 6. Plot Gridded Data\n",
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1 Plot Annual Emission Fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scale_max = 10\n",
    "save_flag = 0\n",
    "save_outfile = ''\n",
    "data_plot_fn.plot_annual_emission_flux_map(Flux_Emissions_Total_annual, Lat_01, Lon_01, year_range, title_str, scale_max,save_flag,save_outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2 Plot Difference Between First and Last Inventory Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot difference between last and first year\n",
    "save_flag = 0\n",
    "save_outfile = ''\n",
    "data_plot_fn.plot_diff_emission_flux_map(Flux_Emissions_Total_annual, Lat_01, Lon_01, year_range, title_diff_str,save_flag,save_outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3 Plot Activity Data Heat Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(Map_population))\n",
    "Map_population_01 = data_fn.regrid001_to_01(Map_population, Lat_01, Lon_01)\n",
    "Map_temp = np.zeros([len(Lat_01),len(Lon_01),num_years])\n",
    "for iyear in np.arange(0,num_years):\n",
    "    Map_temp[:,:,iyear] = Map_population_01\n",
    "print(np.shape(Map_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map (population) distribution mile heatmap (distribution mileage is at the state level, how to map?)\n",
    "\n",
    "# Activity_Map = 0.1x0.1 map of activity data (counts or absolute units)\n",
    "# Plot_Frac    = 0 or 1 (0= plot activity data in absolute counts, 1= plot fractional activity data)\n",
    "# Lat          = 0.1 degree Lat values (select range)\n",
    "# Lon          = 0.1 degree Lon values (select range)\n",
    "# year_range   = array of inventory years\n",
    "# title_str    = title of map\n",
    "# legend_str   = title of legend\n",
    "# scale_max    = maximum of color scale\n",
    "\n",
    "Activity_Map = Map_temp\n",
    "Plot_Frac = 1\n",
    "Lat = Lat_01\n",
    "Lon = Lon_01\n",
    "year_range = year_range\n",
    "title_str2 = \"Proxy - Population\"\n",
    "legend_str = \"Annual Fraction of National Population\"\n",
    "scale_max = 0.001\n",
    "\n",
    "for iyear in np.arange(0,1):#len(year_range)): \n",
    "    my_cmap = copy(plt.cm.get_cmap('rainbow',lut=3000))\n",
    "    my_cmap._init()\n",
    "    slopen = 200\n",
    "    alphas_slope = np.abs(np.linspace(0, 1.0, slopen))\n",
    "    alphas_stable = np.ones(3003-slopen)\n",
    "    alphas = np.concatenate((alphas_slope, alphas_stable))\n",
    "    my_cmap._lut[:,-1] = alphas\n",
    "    my_cmap.set_under('gray', alpha=0)\n",
    "    \n",
    "    Lon_cor = Lon[50:632]-0.05\n",
    "    Lat_cor = Lat[43:300]-0.05\n",
    "    \n",
    "    xpoints = Lon_cor\n",
    "    ypoints = Lat_cor\n",
    "    yp,xp = np.meshgrid(ypoints,xpoints)\n",
    "    \n",
    "    if np.shape(Activity_Map)[0] == len(year_range):\n",
    "        if Plot_Frac ==1:\n",
    "            zp = Activity_Map[iyear,43:300,50:632]/np.sum(Activity_Map[iyear,:,:])\n",
    "        else:\n",
    "            zp = Activity_Map[iyear,43:300,50:632]\n",
    "    elif np.shape(Activity_Map)[2] == len(year_range):\n",
    "        if Plot_Frac ==1:\n",
    "            zp = Activity_Map[43:300,50:632,iyear]/np.sum(Activity_Map[:,:,iyear])\n",
    "        else: \n",
    "            zp = Activity_Map[43:300,50:632,iyear]\n",
    "    #zp = zp/float(10**6 * Avogadro) * (year_days * 24 * 60 * 60) * Molarch4 * float(1e10)\n",
    "    \n",
    "    fig, ax = plt.subplots(dpi=300)\n",
    "    m = Basemap(llcrnrlon=xp.min(), llcrnrlat=yp.min(), urcrnrlon=xp.max(),\n",
    "                urcrnrlat=yp.max(), projection='merc', resolution='h', area_thresh=5000)\n",
    "    m.drawmapboundary(fill_color='Azure')\n",
    "    m.fillcontinents(color='FloralWhite', lake_color='Azure',zorder=1)\n",
    "    m.drawcoastlines(linewidth=0.5,zorder=3)\n",
    "    m.drawstates(linewidth=0.25,zorder=3)\n",
    "    m.drawcountries(linewidth=0.5,zorder=3)\n",
    "        \n",
    "        #if Plot_Frac == 1:\n",
    "        #    scale_max \n",
    "    \n",
    "    xpi,ypi = m(xp,yp)\n",
    "    plot = m.pcolor(xpi,ypi,zp.transpose(), cmap=my_cmap, vmin=10**-15, vmax=scale_max, snap=True,zorder=2)\n",
    "    #plot = m.scatter(xpi,ypi,s=20,c=zp.transpose(),cmap=my_cmap,zorder=2,vmin = 10**-15,snap = True,vmax = scale_max)\n",
    "    cb = m.colorbar(plot, location = \"bottom\", pad = \"1%\")        \n",
    "    tick_locator = ticker.MaxNLocator(nbins=5)\n",
    "    cb.locator = tick_locator\n",
    "    cb.update_ticks()\n",
    "    \n",
    "    cb.ax.set_xlabel(legend_str,fontsize=10)\n",
    "    cb.ax.tick_params(labelsize=10)\n",
    "    Titlestring = str(year_range[iyear])+' '+title_str2\n",
    "    plt.title(Titlestring, fontsize=14);\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = datetime.datetime.now() \n",
    "ft = ct.timestamp() \n",
    "time_elapsed = (ft-it)/(60*60)\n",
    "print('Time to run: '+str(time_elapsed)+' hours')\n",
    "print('** GEPA_1B2b_Distribution: COMPLETE **')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
