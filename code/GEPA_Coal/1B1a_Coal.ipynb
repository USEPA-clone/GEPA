{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridded EPA Methane Inventory\n",
    "## Category: 1B1a Coal Mines (Active)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### Authors: \n",
    "Joannes D. Maasakkers, Erin E. McDuffie\n",
    "#### Date Last Updated: \n",
    "see Step 0\n",
    "#### Notebook Purpose: \n",
    "This Notebook calculates and reports annual gridded (0.1°x0.1°) methane emission fluxes (molec./cm2/s) from active coal mining (surface and underground) in the CONUS region between 2012-2018.    \n",
    "#### Summary & Notes:\n",
    "EPA GHGI active coal mining emissions from underground (mining, post-mining, recovered and used) and surface (mining and post-mining) activities are read in at the state level from the GHGI (GHGI workbook). For all sources, national total emissions are first allocated to states based on the state-level emissions. Net underground mining emissions are taken as the sum of underground mining emissions and the amount of methane recovered and used. State-level net underground mining emissions are then allocated to a 0.01°x0.01° grid using high resolution maps of underground mine locations and emissions, from both the GHGRP (subpart FF, where available) and estimated from relative levels of coal production at each active underground mine relative to total state production (from the EIA & Mine Safety and Health Administration [MSHA]), weighted by the basin-level in situ methane content of coal in states with mine sin multiple basins. State-level emissions from all active surface mine activities are allocated to a 0.01°x0.01° grid using high resolution maps of surface mine locations and emissions, as estimated from the coal production at each active surface mine, relative to the total state production (from EIA & MSHA), also weighted by the basin-level in situ methane content of coal in states with mines in multiple basins. All emissions are re-gridded to a 0.1°x0.1° grid. Emissions are converted to emission flux. Annual emission fluxes (molec./cm2/s) are written to final netCDFs in the ‘/code/Final_Gridded_Data/’ folder. \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "## Step 0. Set-Up Notebook Modules, Functions, and Local Parameters and Constants\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirm working directory\n",
    "import os\n",
    "import time\n",
    "modtime = os.path.getmtime('./v2_1B1a_Coal.ipynb')\n",
    "modificationTime = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(modtime))\n",
    "print(\"This file was last modified on: \", modificationTime)\n",
    "print('')\n",
    "print(\"The directory we are working in is {}\" .format(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Include plots within notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import base modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import datetime\n",
    "from copy import copy\n",
    "\n",
    "# Import additional modules\n",
    "# Load plotting package Basemap \n",
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "# Load netCDF (for manipulating netCDF file types)\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "# Set up ticker\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "#add path for the global function module (file)\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../Global_Functions/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# Load Tabula (for reading tables from PDFs)\n",
    "import tabula as tb   \n",
    "    \n",
    "# Load user-defined global functions (modules)\n",
    "import data_load_functions as data_load_fn\n",
    "import data_functions as data_fn\n",
    "import data_IO_functions as data_IO_fn\n",
    "import data_plot_functions as data_plot_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INPUT Files\n",
    "# Assign global file names\n",
    "global_filenames = data_load_fn.load_global_file_names()\n",
    "State_ANSI_inputfile = global_filenames[0]\n",
    "#County_ANSI_inputfile = global_filenames[1]\n",
    "pop_map_inputfile = global_filenames[2]\n",
    "Grid_area01_inputfile = global_filenames[3]\n",
    "Grid_area001_inputfile = global_filenames[4]\n",
    "Grid_state001_ansi_inputfile = global_filenames[5]\n",
    "#Grid_county001_ansi_inputfile = global_filenames[6]\n",
    "globalinputlocation = global_filenames[0][0:20]\n",
    "print(globalinputlocation)\n",
    "\n",
    "# Specify names of inputs files used in this notebook\n",
    "#EPA Data\n",
    "EPA_coal_inputfile = '../Global_InputData/GHGI/Ch3_Energy/Coal1990-2018_022020.xlsm'\n",
    "\n",
    "#Proxy Data file\n",
    "Coal_Mapping_inputfile = \"./InputData/Coal_ProxyMapping.xlsx\"\n",
    "\n",
    "#Activity Data\n",
    "EIA_mine_inputfile = \"./InputData/EIA/coalpublic\"\n",
    "Mine_loc_inputfile = \"../Global_InputData/MSHA/Mines.txt\"\n",
    "Corrected_surf_mine_inputfile = \"./InputData/Updated_Loc.csv\"\n",
    "Corrected_ug_mine_inputfile = \"./InputData/Updated_Loc_ug.csv\"\n",
    "\n",
    "#OUTPUT FILES\n",
    "gridded_outputfile = '../Final_Gridded_Data/EPA_v2_1B1a_Coal.nc'\n",
    "gridded_surf_outputfile = '../Final_Gridded_Data/EPA_v2_1B1a_Surface_Coal.nc'\n",
    "gridded_und_outputfile = '../Final_Gridded_Data/EPA_v2_1B1a_Underground_Coal.nc'\n",
    "netCDF_description = 'Gridded EPA Inventory - Coal Mine Emissions - IPCC Source Category 1B1a'\n",
    "netCDF_surf_description = 'Gridded EPA Inventory - Surface Coal Mining Emissions - IPCC Source Category 1B1a'\n",
    "netCDF_und_description = 'Gridded EPA Inventory - Underground Coal Mining Emissions - IPCC Source Category 1B1a'\n",
    "title_str = \"EPA methane emissions from coal mines\"\n",
    "title_diff_str = \"Emissions from coal mines difference: 2018-2012\"\n",
    "\n",
    "#output gridded proxy data\n",
    "grid_emi_outputfile = '../Final_Gridded_Data/Extension/v2_input_data/Coal_Grid_Emi.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define local variables\n",
    "start_year = 2012  #First year in emission timeseries\n",
    "end_year = 2018    #Last year in emission timeseries\n",
    "year_range = [*range(start_year, end_year+1,1)] #List of emission years\n",
    "year_range_str=[str(i) for i in year_range]\n",
    "num_years = len(year_range)\n",
    "\n",
    "# Define constants\n",
    "Avogadro   = 6.02214129 * 10**(23)  #molecules/mol\n",
    "Molarch4   = 16.04                  #g/mol\n",
    "Res01      = 0.1                    # degrees\n",
    "Res_01     = 0.01\n",
    "tg_scale   = 0.001                  #Tg scale number [New file allows for the exclusion of the territories] \n",
    "\n",
    "# Million cubic ft (mmcf) to Tg conversion factor - Source: EPA spreadsheet, 'CM Emissions Summary' tab\n",
    "mmcf_to_tg = 51921\n",
    "\n",
    "# Continental US Lat/Lon Limits (for netCDF files)\n",
    "Lon_left = -130       #deg\n",
    "Lon_right = -60       #deg\n",
    "Lat_low  = 20         #deg\n",
    "Lat_up  = 55          #deg\n",
    "loc_dimensions = [Lat_low, Lat_up, Lon_left, Lon_right]\n",
    "\n",
    "ilat_start = int((90+Lat_low)/Res01) #1100:1450 (continental US range)\n",
    "ilat_end = int((90+Lat_up)/Res01)\n",
    "ilon_start = abs(int((-180-Lon_left)/Res01)) #500:1200 (continental US range)\n",
    "ilon_end = abs(int((-180-Lon_right)/Res01))\n",
    "\n",
    "# Number of days in each month\n",
    "month_day_leap  = [  31,  29,  31,  30,  31,  30,  31,  31,  30,  31,  30,  31]\n",
    "month_day_nonleap = [  31,  28,  31,  30,  31,  30,  31,  31,  30,  31,  30,  31]\n",
    "\n",
    "# Month arrays\n",
    "month_range_str = ['January','February','March','April','May','June','July','August','September','October','November','December']\n",
    "num_months = len(month_range_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.auto_scroll_threshold = 9999;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track run time\n",
    "ct = datetime.datetime.now() \n",
    "it = ct.timestamp() \n",
    "print(\"current time:\", ct) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "## Step 1. Load in State ANSI data and Area Maps\n",
    "_____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State-level ANSI Data\n",
    "#Read the state ANSI file array\n",
    "State_ANSI, name_dict = data_load_fn.load_state_ansi(State_ANSI_inputfile)[0:2]\n",
    "#QA: number of states\n",
    "print('Read input file: '+ f\"{State_ANSI_inputfile}\")\n",
    "print('Total \"States\" found: ' + '%.0f' % len(State_ANSI))\n",
    "print(' ')\n",
    "\n",
    "# 0.01 x0.01 degree Data\n",
    "# State ANSI IDs and grid cell area (m2) maps\n",
    "state_ANSI_map = data_load_fn.load_state_ansi_map(Grid_state001_ansi_inputfile)\n",
    "area_map, lat001, lon001 = data_load_fn.load_area_map_001(Grid_area001_inputfile)\n",
    "\n",
    "# 0.01 x0.01 degree Data\n",
    "# State ANSI IDs and grid cell area (m2) maps\n",
    "state_ANSI_map = data_load_fn.load_state_ansi_map(Grid_state001_ansi_inputfile)\n",
    "state_ANSI_map = state_ANSI_map.astype('int32')\n",
    "#county_ANSI_map = data_load_fn.load_county_ansi_map(Grid_county001_ansi_inputfile)\n",
    "#county_ANSI_map = county_ANSI_map.astype('int32')\n",
    "area_map, lat001, lon001 = data_load_fn.load_area_map_001(Grid_area001_inputfile)\n",
    "\n",
    "# 0.1 x0.1 degree data\n",
    "# grid cell area and state and county ANSI maps\n",
    "area_map01, Lat01, Lon01 = data_load_fn.load_area_map_01(Grid_area01_inputfile)[0:3]\n",
    "#Select relevant Continental 0.1 x0.1 domain\n",
    "Lat_01 = Lat01[ilat_start:ilat_end]\n",
    "Lon_01 = Lon01[ilon_start:ilon_end]\n",
    "area_matrix_01 = data_fn.regrid001_to_01(area_map, Lat_01, Lon_01)\n",
    "area_matrix_01 *= 10000  #convert from m2 to cm2\n",
    "\n",
    "state_ANSI_map_01 = data_fn.regrid001_to_01(state_ANSI_map, Lat_01, Lon_01)\n",
    "\n",
    "# Print time\n",
    "ct = datetime.datetime.now() \n",
    "print(\"current time:\", ct) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "## Step 2: Read-in and Format Proxy Data\n",
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.1 Read In Proxy Mapping File & Make Proxy Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load GHGI Mapping Groups\n",
    "names = pd.read_excel(Coal_Mapping_inputfile, sheet_name = \"GHGI Map - Coal\", usecols = \"A:B\",skiprows = 1, header = 0)\n",
    "colnames = names.columns.values\n",
    "ghgi_coal_map = pd.read_excel(Coal_Mapping_inputfile, sheet_name = \"GHGI Map - Coal\", usecols = \"A:B\", skiprows = 1, names = colnames)\n",
    "#drop rows with no data, remove the parentheses and \"\"\n",
    "ghgi_coal_map = ghgi_coal_map[ghgi_coal_map['GHGI_Emi_Group'] != 'na']\n",
    "ghgi_coal_map = ghgi_coal_map[ghgi_coal_map['GHGI_Emi_Group'].notna()]\n",
    "ghgi_coal_map['GHGI_Source']= ghgi_coal_map['GHGI_Source'].str.replace(r\"\\(\",\"\")\n",
    "ghgi_coal_map['GHGI_Source']= ghgi_coal_map['GHGI_Source'].str.replace(r\"\\)\",\"\")\n",
    "ghgi_coal_map.reset_index(inplace=True, drop=True)\n",
    "display(ghgi_coal_map)\n",
    "\n",
    "#load emission group - proxy map\n",
    "names = pd.read_excel(Coal_Mapping_inputfile, sheet_name = \"Proxy Map - Coal\", usecols = \"A:E\",skiprows = 1, header = 0)\n",
    "colnames = names.columns.values\n",
    "proxy_coal_map = pd.read_excel(Coal_Mapping_inputfile, sheet_name = \"Proxy Map - Coal\", usecols = \"A:E\", skiprows = 1, names = colnames)\n",
    "display((proxy_coal_map))\n",
    "\n",
    "#create empty proxy and emission group arrays (add months for proxy variables that have monthly data)\n",
    "for igroup in np.arange(0,len(proxy_coal_map)):\n",
    "    if proxy_coal_map.loc[igroup, 'Grid_Month_Flag'] ==0:\n",
    "        vars()[proxy_coal_map.loc[igroup,'Proxy_Group']] = np.zeros([len(Lat_01),len(Lon_01),num_years])\n",
    "        vars()[proxy_coal_map.loc[igroup,'Proxy_Group']+'_nongrid'] = np.zeros([num_years])\n",
    "    else:\n",
    "        vars()[proxy_coal_map.loc[igroup,'Proxy_Group']] = np.zeros([len(Lat_01),len(Lon_01),num_years,num_months])\n",
    "        vars()[proxy_coal_map.loc[igroup,'Proxy_Group']+'_nongrid'] = np.zeros([num_years,num_months])\n",
    "        \n",
    "    vars()[proxy_coal_map.loc[igroup,'GHGI_Emi_Group']] = np.zeros([num_years])\n",
    "    \n",
    "    if proxy_coal_map.loc[igroup,'State_Proxy_Group'] != '-':\n",
    "        if proxy_coal_map.loc[igroup,'State_Month_Flag'] == 0:\n",
    "            vars()[proxy_coal_map.loc[igroup,'State_Proxy_Group']] = np.zeros([len(State_ANSI),num_years])\n",
    "            #print('here')\n",
    "        else:\n",
    "            vars()[proxy_coal_map.loc[igroup,'State_Proxy_Group']] = np.zeros([len(State_ANSI),num_years,num_months])\n",
    "    else:\n",
    "        continue # do not make state proxy variable if no variable assigned in mapping file\n",
    "        \n",
    "emi_group_names = np.unique(ghgi_coal_map['GHGI_Emi_Group'])\n",
    "\n",
    "print('QA/QC: Is the number of emission groups the same for the proxy and emissions tabs?')\n",
    "if (len(emi_group_names) == len(np.unique(proxy_coal_map['GHGI_Emi_Group']))):\n",
    "    print('PASS')\n",
    "else:\n",
    "    print('FAIL')\n",
    "    print(emi_group_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.2. Read in EPA State-Level Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Read in State-Level Data from InvDB tab in the Inventory workbook (Tg == 1000 kt)\n",
    "\n",
    "names = pd.read_excel(EPA_coal_inputfile, sheet_name = \"InvDB\", usecols = \"A:AJ\",skiprows = 15, header = 0)\n",
    "colnames = names.columns.values\n",
    "EPA_emi_coal_CH4 = pd.read_excel(EPA_coal_inputfile, sheet_name = \"InvDB\", usecols = \"A:AJ\", skiprows = 15, nrows = 140,names = colnames)\n",
    "EPA_emi_coal_CH4 = EPA_emi_coal_CH4.fillna('')\n",
    "EPA_emi_coal_CH4 = EPA_emi_coal_CH4.drop(columns = [n for n in range(1990, start_year,1)])\n",
    "EPA_emi_coal_CH4 = EPA_emi_coal_CH4.drop(columns = ['Sector','Source','Subsource','Fuel','GHG'])\n",
    "EPA_emi_coal_CH4.rename(columns={'Subref':'Source'},inplace=True)\n",
    "EPA_emi_coal_CH4['Source']= EPA_emi_coal_CH4['Source'].str.replace(r\"\\(\",\"\")\n",
    "EPA_emi_coal_CH4['Source']= EPA_emi_coal_CH4['Source'].str.replace(r\"\\)\",\"\")\n",
    "EPA_emi_coal_CH4.reset_index(inplace=True, drop=True)\n",
    "\n",
    "\n",
    "display(EPA_emi_coal_CH4)\n",
    "\n",
    "# Make State_arrays for net underground emissions, post-mining underground, post-mining surface, and surface emissions\n",
    "state_under = np.zeros([len(State_ANSI),num_years])\n",
    "state_post_under = np.zeros([len(State_ANSI),num_years])\n",
    "state_post_surf = np.zeros([len(State_ANSI),num_years])\n",
    "state_suface = np.zeros([len(State_ANSI),num_years])\n",
    "\n",
    "for istate in np.arange(0, len(State_ANSI)):\n",
    "    temp = EPA_emi_coal_CH4[EPA_emi_coal_CH4['State'] == State_ANSI['abbr'][istate]]\n",
    "    if len(temp) > 0:\n",
    "        for iyear in np.arange(0, num_years):\n",
    "            state_under[istate,iyear] = float(temp.loc[temp['Source']=='Underground Liberated',year_range[iyear]])+\\\n",
    "                                        float(temp.loc[temp['Source']=='Underground Recovered &Used',year_range[iyear]])\n",
    "            state_post_under[istate,iyear] = float(temp.loc[temp['Source']=='Post-Mining Underground',year_range[iyear]])\n",
    "            state_post_surf[istate,iyear] = float(temp.loc[temp['Source']=='Post-Mining Surface',year_range[iyear]])\n",
    "            state_suface[istate,iyear] = float(temp.loc[temp['Source']=='Surface Mining',year_range[iyear]])\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.3. Read mine-level Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2.3.1 Read in EPA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1) Read-in Mine level emissions data (from GHGI workbook) \n",
    "# emissions in Tg\n",
    "\n",
    "for iyear in np.arange(0,num_years):\n",
    "    year_name = 'UG-'+year_range_str[iyear]\n",
    "    start_row = 3\n",
    "    if year_range[iyear]==2012:\n",
    "        start_row = 2\n",
    "        num_rows = 117\n",
    "    elif year_range[iyear] ==2013:\n",
    "        num_rows = 204\n",
    "    elif year_range[iyear] ==2014:\n",
    "        num_rows = 178\n",
    "    elif year_range[iyear] ==2015:\n",
    "        num_rows = 219\n",
    "    elif year_range[iyear] ==2016:\n",
    "        num_rows = 162\n",
    "    elif year_range[iyear] ==2017:\n",
    "        num_rows = 161\n",
    "    elif year_range[iyear] ==2018:\n",
    "        num_rows = 163\n",
    "    names = pd.read_excel(EPA_coal_inputfile, sheet_name = year_name, usecols = \"A,D,G,J\",skiprows = start_row, header = 0)\n",
    "    colnames = names.columns.values\n",
    "    EPA_emi_mine = pd.read_excel(EPA_coal_inputfile, sheet_name = year_name, usecols = \"A,D,G,J\", skiprows = start_row, nrows = num_rows,names = colnames)\n",
    "    EPA_emi_mine = EPA_emi_mine.fillna('')\n",
    "   # mmcf_to_tg\n",
    "    \n",
    "    EPA_emi_mine.rename(columns={EPA_emi_mine.columns[3]: 'Net Emissions Tg'},inplace=True)\n",
    "    EPA_emi_mine['Net Emissions Tg'] /= mmcf_to_tg #convert to from mmcf Tg\n",
    "    EPA_emi_mine.reset_index(inplace=True, drop=True)\n",
    "    vars()['EPA_mine_emi_'+year_range_str[iyear]] = EPA_emi_mine\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2.3.2 Read in EIA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#2 ) Read in EIA Data\n",
    "for iyear in np.arange(0,num_years):\n",
    "    if year_range[iyear]==2012:\n",
    "        cols= \"A,B,D,G,M\"\n",
    "    else:\n",
    "        cols = \"A,B,D,G,N\"\n",
    "    filename = EIA_mine_inputfile+year_range_str[iyear]+'.xls'\n",
    "    names = pd.read_excel(filename, sheet_name = 'Hist_Coal_Prod', usecols = cols,skiprows = 3, header = 0)\n",
    "    colnames = names.columns.values\n",
    "    EIA_mine_prod = pd.read_excel(filename, sheet_name = 'Hist_Coal_Prod', usecols = cols, skiprows = 3, names = colnames)\n",
    "    EIA_mine_prod = EIA_mine_prod.fillna('')\n",
    "\n",
    "    EIA_mine_prod.rename(columns={EIA_mine_prod.columns[4]: 'Production Short Tons'},inplace=True)\n",
    "    EIA_mine_prod.rename(columns={EIA_mine_prod.columns[1]: 'MSHA'},inplace=True)\n",
    "    EIA_mine_prod.reset_index(inplace=True, drop=True)\n",
    "    vars()['EIA_mine_prod'+year_range_str[iyear]] = EIA_mine_prod\n",
    "\n",
    "    display(vars()['EIA_mine_prod'+year_range_str[iyear]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2.3.3 Make Mine Reference Array with Mine-Level ID, Production, and Emissions Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make mine reference dataframe for EIA mines (make a list of all unique mines)\n",
    "\n",
    "# Start with 2012 data\n",
    "iyear = 0\n",
    "mine_ref = pd.DataFrame(data=vars()['EIA_mine_prod'+year_range_str[iyear]]['MSHA'])\n",
    "mine_ref['Mine Type'] = vars()['EIA_mine_prod'+year_range_str[iyear]]['Mine Type']\n",
    "mine_ref['Mine State'] = vars()['EIA_mine_prod'+year_range_str[iyear]]['Mine State']\n",
    "\n",
    "# Fill out dataframe with unique mines for the rest of years\n",
    "for iyear in np.arange(0,num_years):\n",
    "    temp_df = vars()['EIA_mine_prod'+year_range_str[iyear]]\n",
    "    for imine in np.arange(0,len(temp_df)):\n",
    "        if len(mine_ref.loc[mine_ref['MSHA']==temp_df['MSHA'][imine]])==0: # if mine not already in dataframe\n",
    "            new_mine = pd.DataFrame([[temp_df['MSHA'][imine],temp_df['Mine Type'][imine],temp_df['Mine State'][imine]]], columns=['MSHA','Mine Type','Mine State']) # add mine entry to mine_ref\n",
    "            mine_ref=mine_ref.append(new_mine,ignore_index=True)\n",
    "mine_ref.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Add production and emissions for each mine for each year\n",
    "for iyear in np.arange(0,num_years):\n",
    "    temp_eia_df = vars()['EIA_mine_prod'+year_range_str[iyear]]\n",
    "    temp_epa_df = vars()['EPA_mine_emi_'+year_range_str[iyear]] \n",
    "    mine_ref['prod_'+year_range_str[iyear]]=0.0 #add production columns for each year\n",
    "    mine_ref['emi_'+year_range_str[iyear]]=0.0 #add emissions columns for each year\n",
    "    \n",
    "    for imine in np.arange(0, len(temp_eia_df)): #add production values\n",
    "        match_mine = np.where(mine_ref['MSHA']==temp_eia_df['MSHA'][imine])[0][0]   \n",
    "        mine_ref.at[match_mine, 'prod_'+year_range_str[iyear]] = temp_eia_df['Production Short Tons'][imine]\n",
    "        \n",
    "        \n",
    "    for imine in np.arange(0, len(temp_epa_df)): #add emi values\n",
    "        if len(np.where(mine_ref['MSHA']==temp_epa_df['MSHA Mine ID'][imine])[0])!=0:\n",
    "            match_mine = np.where(mine_ref['MSHA']==temp_epa_df['MSHA Mine ID'][imine])[0][0]            \n",
    "            mine_ref.at[match_mine, 'emi_'+year_range_str[iyear]] = temp_epa_df['Net Emissions Tg'][imine]\n",
    "                           \n",
    "display(mine_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.4 Add Mine Location Information (from MSHA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2.4.1 Read in MSHA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read datafiles with accurate lat/lon - Source: msha.gov\n",
    "MSHA_Locations = pd.read_csv(Mine_loc_inputfile,sep=\"|\",encoding= 'unicode_escape',usecols=[\"MINE_ID\",\"LATITUDE\",\"LONGITUDE\"])\n",
    "MSHA_Locations.dropna(axis=0,inplace=True)\n",
    "MSHA_Locations.reset_index(inplace=True)\n",
    "\n",
    "# Add lat/lon columns to mine_ref\n",
    "mine_ref['LAT']=0.0\n",
    "mine_ref['LON']=0.0\n",
    "\n",
    "counter=0\n",
    "for imine in np.arange(0,len(mine_ref)):\n",
    "    if len(MSHA_Locations[MSHA_Locations['MINE_ID']==mine_ref['MSHA'][imine]])!=0:\n",
    "        match_mine = np.where(mine_ref['MSHA'][imine]==MSHA_Locations['MINE_ID'])[0][0]\n",
    "        mine_ref.at[imine,'LAT'] = MSHA_Locations['LATITUDE'][match_mine]\n",
    "        if MSHA_Locations['LONGITUDE'][match_mine] <0:\n",
    "            mine_ref.at[imine,'LON'] = MSHA_Locations['LONGITUDE'][match_mine] \n",
    "        else:\n",
    "            mine_ref.at[imine,'LON'] = -MSHA_Locations['LONGITUDE'][match_mine] #msha longitudes must be made negative\\\n",
    "        counter += 1\n",
    "\n",
    "display(mine_ref.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2.4.2. Format/Correct Location Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Throw out mines without location as we won't allocate emissions to them\n",
    "to_delete=[]\n",
    "for imine in np.arange(0,len(mine_ref)):\n",
    "    if mine_ref['LAT'][imine]==0:\n",
    "        to_delete.append(imine)\n",
    "\n",
    "mine_ref.drop(to_delete,inplace=True)\n",
    "mine_ref.reset_index(inplace=True,drop=True)\n",
    "        \n",
    "# Print used mines and production percentage captured with MSHA locations\n",
    "print('Used mines: ', len(mine_ref))\n",
    "print('')\n",
    "print('QA/QC: Check that all mines that have production data also have location data')\n",
    "for iyear in np.arange(0, num_years):\n",
    "    if np.sum(mine_ref['prod_'+year_range_str[iyear]][mine_ref['LAT']>0])/np.sum(mine_ref['prod_'+year_range_str[iyear]]) ==1:\n",
    "        print(year_range_str[iyear], ': PASS')\n",
    "    else:\n",
    "        print(year_range_str[iyear], 'FAIL - Check')     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2.4.3. Correct mine locations based on checking them on Google Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#surface mines\n",
    "Updated_Loc = pd.read_csv(Corrected_surf_mine_inputfile,usecols=[0,1,2])\n",
    "Updated_Loc[['correct_lat', 'correct_lng']] = Updated_Loc['correct_lat'].str.split(' ',expand = True)\n",
    "Updated_Loc['msha_change'] = Updated_Loc['msha_change'].replace(np.nan,0)\n",
    "Updated_Loc['correct_lat'] = Updated_Loc['correct_lat'].replace(np.nan,0)\n",
    "Updated_Loc['correct_lng'] = Updated_Loc['correct_lng'].replace(np.nan,0)\n",
    "Updated_Loc['msha_change'] = Updated_Loc['msha_change'].astype(int)\n",
    "\n",
    "#underground mines\n",
    "Updated_Loc_ug = pd.read_csv(Corrected_ug_mine_inputfile,usecols=[0,1,2])\n",
    "Updated_Loc_ug[['correct_lat', 'correct_lng']] = Updated_Loc_ug['correct_lat'].str.split(' ',expand = True)\n",
    "Updated_Loc_ug['msha_change'] = Updated_Loc_ug['msha_change'].replace(np.nan,0)\n",
    "Updated_Loc_ug['correct_lat'] = Updated_Loc_ug['correct_lat'].replace(np.nan,0)\n",
    "Updated_Loc_ug['correct_lng'] = Updated_Loc_ug['correct_lng'].replace(np.nan,0)\n",
    "Updated_Loc_ug['msha_change'] = Updated_Loc_ug['msha_change'].astype(int)\n",
    "\n",
    "#surface mines\n",
    "for imine in np.arange(0,len(Updated_Loc)):\n",
    "    if Updated_Loc['msha_change'][imine] >0:\n",
    "        match_change = np.where(mine_ref['MSHA'] == Updated_Loc['msha_change'][imine])[0][0]\n",
    "        mine_ref.at[match_change,'LAT'] = Updated_Loc['correct_lat'][imine]\n",
    "        mine_ref.at[match_change,'LON']= Updated_Loc['correct_lng'][imine]\n",
    "        \n",
    "#underground mines\n",
    "for imine in np.arange(len(Updated_Loc_ug)):\n",
    "    if Updated_Loc_ug['msha_change'][imine] >0:\n",
    "        match_change = np.where(mine_ref['MSHA'] == Updated_Loc_ug['msha_change'][imine])[0][0]\n",
    "        mine_ref.at[match_change,'LAT'] = Updated_Loc_ug['correct_lat'][imine]\n",
    "        mine_ref.at[match_change,'LON']= Updated_Loc_ug['correct_lng'][imine]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.5 Calculate Mine Emissions (based on GHGRP/EPA mine emissions and estimated from mine Production)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The proxy used to take state-level emissions down to the grid-cell level are estimates of the relative emissions\n",
    "# from each mine. Emissions are either taken from the GHGRP (read in above) or estimated based on the relative\n",
    "# amount of coal production at each mine. \n",
    "# Step 1. Emissions are estimated for each mine\n",
    "#     1A. State-level production levels are calculated\n",
    "#     1B. Mine-level emissions are calculated (as state emissions weighted by coal production at each well relative to state total)\n",
    "# Step 2. Where available, GHGRP emissions for the well are used for underground mines. \n",
    "# Step 3. Emissions are placed onto a grid\n",
    "\n",
    "#Step 1. Emissions are estimated at each mine using state-level emissions * mine production/state production\n",
    "# Step 1.A - Calculate State-based totals for both underground and surface mines\n",
    "\n",
    "State_underground_production = np.zeros([len(State_ANSI),num_years])\n",
    "State_surface_production = np.zeros([len(State_ANSI),num_years])\n",
    "EIA_und = np.zeros([len(mine_ref),num_years])\n",
    "EIA_und_post = np.zeros([len(mine_ref),num_years])\n",
    "EIA_sur = np.zeros([len(mine_ref),num_years])\n",
    "EIA_sur_post = np.zeros([len(mine_ref),num_years])\n",
    "map_und      = np.zeros([len(lat001),len(lon001),num_years])\n",
    "map_und_post = np.zeros([len(lat001),len(lon001),num_years])\n",
    "map_sur      = np.zeros([len(lat001),len(lon001),num_years])\n",
    "map_sur_post = np.zeros([len(lat001),len(lon001),num_years])\n",
    "map_und_nongrid      = np.zeros([num_years])\n",
    "map_und_post_nongrid = np.zeros([num_years])\n",
    "map_sur_nongrid      = np.zeros([num_years])\n",
    "map_sur_post_nongrid = np.zeros([num_years])\n",
    "\n",
    "for iyear in np.arange(0, num_years):\n",
    "    #Weight Kentucky & West Virginia based on basin\n",
    "    for imine in np.arange(0,len(mine_ref)):\n",
    "        if mine_ref['Mine Type'][imine] == 'Underground':  \n",
    "            if mine_ref['Mine State'][imine] == 'Kentucky (East)':\n",
    "                istate = np.where(State_ANSI==name_dict['Kentucky'])[0][0]\n",
    "                State_underground_production[istate,iyear] += 61.4*float(mine_ref['prod_'+year_range_str[iyear]][imine])\n",
    "            elif mine_ref['Mine State'][imine] == 'Kentucky (West)':\n",
    "                istate = np.where(State_ANSI==name_dict['Kentucky'])[0][0]\n",
    "                State_underground_production[istate,iyear] += 64.3*float(mine_ref['prod_'+year_range_str[iyear]][imine])\n",
    "            elif mine_ref['Mine State'][imine] == 'West Virginia (Northern)':\n",
    "                istate = np.where(State_ANSI==name_dict['West Virginia'])[0][0]\n",
    "                State_underground_production[istate,iyear] += 138.4*float(mine_ref['prod_'+year_range_str[iyear]][imine])\n",
    "            elif mine_ref['Mine State'][imine] == 'West Virginia (Southern)':\n",
    "                istate = np.where(State_ANSI==name_dict['West Virginia'])[0][0]\n",
    "                State_underground_production[istate,iyear] += 136.8*float(mine_ref['prod_'+year_range_str[iyear]][imine])\n",
    "            elif (mine_ref['Mine State'][imine] == 'Pennsylvania (Bituminous)') or (mine_ref['Mine State'][imine] == 'Pennsylvania (Anthracite)'):\n",
    "                istate = np.where(State_ANSI==name_dict['Pennsylvania'])[0][0]\n",
    "                State_underground_production[istate,iyear] += float(mine_ref['prod_'+year_range_str[iyear]][imine])\n",
    "\n",
    "            elif mine_ref['Mine State'][imine] == 'Refuse Recovery':\n",
    "                continue\n",
    "            else:\n",
    "                istate = np.where(State_ANSI==name_dict[mine_ref['Mine State'][imine]])[0][0]\n",
    "                State_underground_production[istate,iyear] += float(mine_ref['prod_'+year_range_str[iyear]][imine])\n",
    "                \n",
    "        elif mine_ref['Mine Type'][imine] == 'Surface':  \n",
    "            if mine_ref['Mine State'][imine] == 'Kentucky (East)':\n",
    "                istate = np.where(State_ANSI==name_dict['Kentucky'])[0][0]\n",
    "                State_surface_production[istate,iyear] += 24.9*float(mine_ref['prod_'+year_range_str[iyear]][imine])\n",
    "            elif mine_ref['Mine State'][imine] == 'Kentucky (West)':\n",
    "                istate = np.where(State_ANSI==name_dict['Kentucky'])[0][0]\n",
    "                State_surface_production[istate,iyear] += 34.3*float(mine_ref['prod_'+year_range_str[iyear]][imine])\n",
    "            elif mine_ref['Mine State'][imine] == 'West Virginia (Northern)':\n",
    "                istate = np.where(State_ANSI==name_dict['West Virginia'])[0][0]\n",
    "                State_surface_production[istate,iyear] += 59.5*float(mine_ref['prod_'+year_range_str[iyear]][imine])\n",
    "            elif mine_ref['Mine State'][imine] == 'West Virginia (Southern)':\n",
    "                istate = np.where(State_ANSI==name_dict['West Virginia'])[0][0]\n",
    "                State_surface_production[istate,iyear] += 24.9*float(mine_ref['prod_'+year_range_str[iyear]][imine])\n",
    "            elif (mine_ref['Mine State'][imine] == 'Pennsylvania (Bituminous)') or (mine_ref['Mine State'][imine] == 'Pennsylvania (Anthracite)'):\n",
    "                istate = np.where(State_ANSI==name_dict['Pennsylvania'])[0][0]\n",
    "                State_surface_production[istate,iyear] += float(mine_ref['prod_'+year_range_str[iyear]][imine])\n",
    "            elif mine_ref['Mine State'][imine] == 'Refuse Recovery':\n",
    "                continue\n",
    "            else:\n",
    "                istate = np.where(State_ANSI==name_dict[mine_ref['Mine State'][imine]])[0][0]\n",
    "                State_surface_production[istate,iyear] += float(mine_ref['prod_'+year_range_str[iyear]][imine])\n",
    "\n",
    "# Step 1.B - Calculate Mine-based emissions\n",
    "# Calculate mine-by-mine emissions based on production (for all surface mines and underground mines where GHGRP unavailable)\n",
    "\n",
    "for iyear in np.arange(0, num_years):\n",
    "    #Weight Kentucky & West Virginia based on basin\n",
    "    for imine in np.arange(0,len(mine_ref)):\n",
    "        if mine_ref['Mine Type'][imine] == 'Underground':\n",
    "            if mine_ref['Mine State'][imine] == 'Kentucky (East)':\n",
    "                istate = np.where(State_ANSI==name_dict['Kentucky'])[0][0]\n",
    "                EIA_und_post[imine,iyear] = state_post_under[istate,iyear]*61.4*data_fn.safe_div(mine_ref['prod_'+year_range_str[iyear]][imine],State_underground_production[istate,iyear])\n",
    "                if mine_ref['emi_'+year_range_str[iyear]][imine] == 0:\n",
    "                    EIA_und[imine,iyear] = state_under[istate,iyear]*61.4*data_fn.safe_div(mine_ref['prod_'+year_range_str[iyear]][imine],State_underground_production[istate,iyear])\n",
    "\n",
    "            elif mine_ref['Mine State'][imine] == 'Kentucky (West)':\n",
    "                istate = np.where(State_ANSI==name_dict['Kentucky'])[0][0]\n",
    "                EIA_und_post[imine,iyear] = state_post_under[istate,iyear]*64.3*data_fn.safe_div(mine_ref['prod_'+year_range_str[iyear]][imine],State_underground_production[istate,iyear])\n",
    "                if mine_ref['emi_'+year_range_str[iyear]][imine] == 0:\n",
    "                    EIA_und[imine,iyear] = state_under[istate,iyear]*64.3*data_fn.safe_div(mine_ref['prod_'+year_range_str[iyear]][imine],State_underground_production[istate,iyear])\n",
    "\n",
    "            elif mine_ref['Mine State'][imine] == 'West Virginia (Northern)':\n",
    "                istate = np.where(State_ANSI==name_dict['West Virginia'])[0][0]\n",
    "                EIA_und_post[imine,iyear] = state_post_under[istate,iyear]*138.4*data_fn.safe_div(mine_ref['prod_'+year_range_str[iyear]][imine],State_underground_production[istate,iyear])\n",
    "                if mine_ref['emi_'+year_range_str[iyear]][imine] == 0:\n",
    "                    EIA_und[imine,iyear] = state_under[istate,iyear]*138.4*data_fn.safe_div(mine_ref['prod_'+year_range_str[iyear]][imine],State_underground_production[istate,iyear])            \n",
    "\n",
    "            elif mine_ref['Mine State'][imine] == 'West Virginia (Southern)':\n",
    "                istate = np.where(State_ANSI==name_dict['West Virginia'])[0][0]\n",
    "                EIA_und_post[imine,iyear] = state_post_under[istate,iyear]*136.8*data_fn.safe_div(mine_ref['prod_'+year_range_str[iyear]][imine],State_underground_production[istate,iyear])\n",
    "                if mine_ref['emi_'+year_range_str[iyear]][imine] == 0:\n",
    "                    EIA_und[imine] = state_under[istate,iyear]*136.8*data_fn.safe_div(mine_ref['prod_'+year_range_str[iyear]][imine],State_underground_production[istate,iyear])            \n",
    "\n",
    "            elif mine_ref['Mine State'][imine] == 'Pennsylvania (Bituminous)' or mine_ref['Mine State'][imine] == 'Pennsylvania (Anthracite)':\n",
    "                istate = np.where(State_ANSI==name_dict['Pennsylvania'])[0][0]\n",
    "                EIA_und_post[imine,iyear] = state_post_under[istate,iyear]*data_fn.safe_div(mine_ref['prod_'+year_range_str[iyear]][imine],State_underground_production[istate,iyear])\n",
    "                if mine_ref['emi_'+year_range_str[iyear]][imine] == 0:\n",
    "                    EIA_und[imine,iyear] = state_under[istate,iyear]*data_fn.safe_div(mine_ref['prod_'+year_range_str[iyear]][imine],State_underground_production[istate,iyear])            \n",
    "\n",
    "            elif mine_ref['Mine State'][imine] == 'Refuse Recovery':\n",
    "                continue\n",
    "            else:\n",
    "                istate = np.where(State_ANSI==name_dict[mine_ref['Mine State'][imine]])[0][0]\n",
    "                EIA_und_post[imine,iyear] = state_post_under[istate,iyear]*data_fn.safe_div(mine_ref['prod_'+year_range_str[iyear]][imine],State_underground_production[istate,iyear])\n",
    "                if mine_ref['emi_'+year_range_str[iyear]][imine] == 0:\n",
    "                    EIA_und[imine,iyear] = state_under[istate,iyear]*data_fn.safe_div(mine_ref['prod_'+year_range_str[iyear]][imine],State_underground_production[istate,iyear])            \n",
    "\n",
    "\n",
    "        elif mine_ref['Mine Type'][imine] == 'Surface':  \n",
    "            if mine_ref['Mine State'][imine] == 'Kentucky (East)':\n",
    "                istate = np.where(State_ANSI==name_dict['Kentucky'])[0][0]\n",
    "                EIA_sur_post[imine,iyear] = state_post_surf[istate,iyear]*24.9*data_fn.safe_div(mine_ref['prod_'+year_range_str[iyear]][imine],State_surface_production[istate,iyear])\n",
    "                EIA_sur[imine,iyear] =      state_suface[istate,iyear]*24.9*data_fn.safe_div(mine_ref['prod_'+year_range_str[iyear]][imine],State_surface_production[istate,iyear])            \n",
    "            elif mine_ref['Mine State'][imine] == 'Kentucky (West)':\n",
    "                istate = np.where(State_ANSI==name_dict['Kentucky'])[0][0]\n",
    "                EIA_sur_post[imine,iyear] = state_post_surf[istate,iyear]*34.3*data_fn.safe_div(mine_ref['prod_'+year_range_str[iyear]][imine],State_surface_production[istate,iyear])\n",
    "                EIA_sur[imine,iyear] =      state_suface[istate,iyear]*34.3*data_fn.safe_div(mine_ref['prod_'+year_range_str[iyear]][imine],State_surface_production[istate,iyear])           \n",
    "            elif mine_ref['Mine State'][imine] == 'West Virginia (Northern)':\n",
    "                istate = np.where(State_ANSI==name_dict['West Virginia'])[0][0]\n",
    "                EIA_sur_post[imine,iyear] = state_post_surf[istate,iyear]*59.5*data_fn.safe_div(mine_ref['prod_'+year_range_str[iyear]][imine],State_surface_production[istate,iyear])\n",
    "                EIA_sur[imine,iyear] =      state_suface[istate,iyear]*59.5*data_fn.safe_div(mine_ref['prod_'+year_range_str[iyear]][imine],State_surface_production[istate,iyear])            \n",
    "            elif mine_ref['Mine State'][imine] == 'West Virginia (Southern)':\n",
    "                istate = np.where(State_ANSI==name_dict['West Virginia'])[0][0]\n",
    "                EIA_sur_post[imine,iyear] = state_post_surf[istate,iyear]*24.9*data_fn.safe_div(mine_ref['prod_'+year_range_str[iyear]][imine],State_surface_production[istate,iyear])\n",
    "                EIA_sur[imine,iyear] =      state_suface[istate,iyear]*24.9*data_fn.safe_div(mine_ref['prod_'+year_range_str[iyear]][imine],State_surface_production[istate,iyear])            \n",
    "            elif mine_ref['Mine State'][imine] == 'Pennsylvania (Bituminous)' or mine_ref['Mine State'][imine] == 'Pennsylvania (Anthracite)':\n",
    "                istate = np.where(State_ANSI==name_dict['Pennsylvania'])[0][0]\n",
    "                EIA_sur_post[imine,iyear] = state_post_surf[istate,iyear]*data_fn.safe_div(mine_ref['prod_'+year_range_str[iyear]][imine],State_surface_production[istate,iyear])\n",
    "                EIA_sur[imine,iyear] = state_suface[istate,iyear]*data_fn.safe_div(mine_ref['prod_'+year_range_str[iyear]][imine],State_surface_production[istate,iyear])            \n",
    "            elif mine_ref['Mine State'][imine] == 'Refuse Recovery':\n",
    "                continue\n",
    "            else:\n",
    "                istate = np.where(State_ANSI==name_dict[mine_ref['Mine State'][imine]])[0][0]\n",
    "                EIA_sur_post[imine,iyear] = state_post_surf[istate,iyear]*data_fn.safe_div(mine_ref['prod_'+year_range_str[iyear]][imine],State_surface_production[istate,iyear])\n",
    "                EIA_sur[imine,iyear] = state_suface[istate,iyear]*data_fn.safe_div(mine_ref['prod_'+year_range_str[iyear]][imine],State_surface_production[istate,iyear])   \n",
    "\n",
    "# Step 2. Emissions are replaced where GHGRP emissions are avialable\n",
    "#(first scale to match national total so that estimated emissions are not over or under weighted relative to GHGRP)\n",
    "for iyear in np.arange(0, num_years):\n",
    "    EIA_und[:,iyear] = EIA_und[:,iyear]*(state_under[:,iyear].sum()-np.array(mine_ref['emi_'+year_range_str[iyear]]).sum())/float(EIA_und[:,iyear].sum())\n",
    "    \n",
    "    #Add in GHGRP underground mine emissions\n",
    "    array_with_GHGRP = np.array(mine_ref['emi_'+year_range_str[iyear]])\n",
    "    EIA_und[array_with_GHGRP>0,iyear] = array_with_GHGRP[array_with_GHGRP>0]\n",
    "    \n",
    "# Replace nan values as zero\n",
    "EIA_und = np.nan_to_num(EIA_und, copy=True)\n",
    "EIA_und_post = np.nan_to_num(EIA_und_post, copy=True)\n",
    "EIA_sur = np.nan_to_num(EIA_sur, copy=True)\n",
    "EIA_sur_post = np.nan_to_num(EIA_sur_post, copy=True)\n",
    "\n",
    "\n",
    "#Step 3. Place data onto grid (0.01 x0.01)\n",
    "for imine in np.arange(0,len(mine_ref)):\n",
    "    if mine_ref['LON'][imine] > Lon_left and mine_ref['LON'][imine] < Lon_right and \\\n",
    "        mine_ref['LAT'][imine] > Lat_low and mine_ref['LAT'][imine] < Lat_up:\n",
    "        ilat = int((mine_ref['LAT'][imine] - Lat_low)/Res_01)\n",
    "        ilon = int((mine_ref['LON'][imine] - Lon_left)/Res_01)\n",
    "        for iyear in np.arange(0, num_years):\n",
    "            map_und[ilat,ilon,iyear] += EIA_und[imine,iyear]\n",
    "            map_und_post[ilat,ilon,iyear] += EIA_und_post[imine,iyear]\n",
    "            map_sur[ilat,ilon,iyear] += EIA_sur[imine,iyear]\n",
    "            map_sur_post[ilat,ilon,iyear] += EIA_sur_post[imine,iyear]\n",
    "    else:\n",
    "        for iyear in np.arange(0, num_years):\n",
    "            map_und_nongrid[iyear] += EIA_und[imine,iyear]\n",
    "            map_und_post_nongrid[iyear] += EIA_und_post[imine,iyear]\n",
    "            map_sur_nongrid[iyear] += EIA_sur[imine,iyear]\n",
    "            map_sur_post_nongrid[iyear] += EIA_sur_post[imine,iyear]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "## Step 3. Read in and Format US EPA GHGI Emissions\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in Data from InvDB tab in the Inventory workbook (Tg == 1000 kt)\n",
    "\n",
    "names = pd.read_excel(EPA_coal_inputfile, sheet_name = \"InvDB\", usecols = \"A:AJ\",skiprows = 15, header = 0)\n",
    "colnames = names.columns.values\n",
    "EPA_emi_coal_CH4 = pd.read_excel(EPA_coal_inputfile, sheet_name = \"InvDB\", usecols = \"A:AJ\", skiprows = 15, nrows = 140,names = colnames)\n",
    "EPA_emi_coal_CH4 = EPA_emi_coal_CH4.fillna('')\n",
    "EPA_emi_coal_CH4 = EPA_emi_coal_CH4.drop(columns = [n for n in range(1990, start_year,1)])\n",
    "EPA_emi_coal_CH4 = EPA_emi_coal_CH4.drop(columns = ['Sector','Source','Subsource','Fuel','GHG'])\n",
    "EPA_emi_coal_CH4.rename(columns={'Subref':'Source'},inplace=True)\n",
    "EPA_emi_coal_CH4['Source']= EPA_emi_coal_CH4['Source'].str.replace(r\"\\(\",\"\")\n",
    "EPA_emi_coal_CH4['Source']= EPA_emi_coal_CH4['Source'].str.replace(r\"\\)\",\"\")\n",
    "EPA_emi_coal_CH4.reset_index(inplace=True, drop=True)\n",
    "\n",
    "#calculate national total from state values\n",
    "temp = EPA_emi_coal_CH4.sum(axis=0)\n",
    "EPA_emi_coal_CH4 = EPA_emi_coal_CH4.append(temp, ignore_index=True)\n",
    "EPA_emi_coal_CH4.iloc[-1,0] = 'Total'\n",
    "EPA_emi_coal_CH4.iloc[-1,1] = ''\n",
    "EPA_emi_coal_total = EPA_emi_coal_CH4[EPA_emi_coal_CH4['Source'] == 'Total']\n",
    "\n",
    "display(EPA_emi_coal_total)\n",
    "#display(EPA_emi_coal_CH4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Split Emissions into Gridding Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#split GHG emissions into gridding groups, based on Coal Proxy Mapping file\n",
    "\n",
    "DEBUG =1\n",
    "start_year_idx = EPA_emi_coal_CH4.columns.get_loc((start_year))\n",
    "end_year_idx = EPA_emi_coal_CH4.columns.get_loc((end_year))+1\n",
    "ghgi_coal_groups = ghgi_coal_map['GHGI_Emi_Group'].unique()\n",
    "sum_emi = np.zeros([num_years])\n",
    "\n",
    "for igroup in np.arange(0,len(ghgi_coal_groups)): #loop through all groups, finding the GHGI sources in that group and summing emissions for that region, year        vars()[ghgi_prod_groups[igroup]] = np.zeros([num_regions-1,num_years])\n",
    "    ##DEBUG## print(ghgi_stat_groups[igroup])\n",
    "    vars()[ghgi_coal_groups[igroup]] = np.zeros([num_years])\n",
    "    source_temp = ghgi_coal_map.loc[ghgi_coal_map['GHGI_Emi_Group'] == ghgi_coal_groups[igroup], 'GHGI_Source']\n",
    "    pattern_temp  = '|'.join(source_temp) \n",
    "    #print(pattern_temp) \n",
    "    emi_temp =EPA_emi_coal_CH4[EPA_emi_coal_CH4['Source'].str.contains(pattern_temp)]\n",
    "    #display(emi_temp)\n",
    "    vars()[ghgi_coal_groups[igroup]][:] = emi_temp.iloc[:,start_year_idx:].sum()\n",
    "        \n",
    "        \n",
    "#Check against total summary emissions \n",
    "print('QA/QC #1: Check Processing Emission Sum against GHGI Summary Emissions')\n",
    "for iyear in np.arange(0,num_years): \n",
    "    for igroup in np.arange(0,len(ghgi_coal_groups)):\n",
    "        sum_emi[iyear] += vars()[ghgi_coal_groups[igroup]][iyear]\n",
    "        \n",
    "    summary_emi = EPA_emi_coal_total.iloc[0,iyear+2]  \n",
    "    #Check 1 - make sure that the sums from all the regions equal the totals reported\n",
    "    diff1 = abs(sum_emi[iyear] - summary_emi)/((sum_emi[iyear] + summary_emi)/2)\n",
    "    if DEBUG==1:\n",
    "        print(summary_emi)\n",
    "        print(sum_emi[iyear])\n",
    "    if diff1 < 0.0001:\n",
    "        print('Year ', year_range[iyear],': PASS, difference < 0.01%')\n",
    "    else:\n",
    "        print('Year ', year_range[iyear],': FAIL (check Production & summary tabs): ', diff1,'%') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "## Step 4. Grid Data\n",
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4.1. Allocate emissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 4.1.1 Assign the Appropriate Proxy Variable Names (state & grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The names on the *left* need to match the 'Coal_ProxyMapping' 'State_Proxy_Group' names \n",
    "# (these are initialized in Step 2). \n",
    "# The names on the *right* are the variable names used to caluclate the proxies in this code.\n",
    "# Names on the right need to match those from the code in Step 2\n",
    "\n",
    "#national --> state proxies (state x year )\n",
    "State_Under = state_under\n",
    "State_Post_Under = state_post_under\n",
    "State_Post_Surf = state_post_surf\n",
    "State_Surf = state_suface\n",
    "\n",
    "#state --> grid proxies (0.01x0.01)\n",
    "Map_Under = map_und\n",
    "Map_Post_Under = map_und_post\n",
    "Map_Surface = map_sur\n",
    "Map_Post_Surface = map_sur_post\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 4.1.2 Allocate National EPA Emissions to the State-Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate state-level emissions\n",
    "# Emissions in Tg\n",
    "# State data = national GHGI emissions * state proxy/national total\n",
    "\n",
    "\n",
    "# Note that national emissions are retained for groups that do not have state proxies (identified in the mapping file)\n",
    "# and are gridded in the next step\n",
    "\n",
    "# Make placeholder emission arrays for each group\n",
    "for igroup in np.arange(0,len(proxy_coal_map)):\n",
    "    vars()['State_'+proxy_coal_map.loc[igroup,'GHGI_Emi_Group']] = np.zeros([len(State_ANSI),num_years])\n",
    "    vars()['NonState_'+proxy_coal_map.loc[igroup,'GHGI_Emi_Group']] = np.zeros([num_years])\n",
    "        \n",
    "#Loop over years\n",
    "for iyear in np.arange(num_years):\n",
    "    #Loop over states\n",
    "    for istate in np.arange(len(State_ANSI)):\n",
    "        for igroup in np.arange(0,len(proxy_coal_map)):    \n",
    "            if proxy_coal_map.loc[igroup,'State_Proxy_Group'] != '-' and proxy_coal_map.loc[igroup,'GHGI_Emi_Group'] != 'Emi_not_mapped':\n",
    "                vars()['State_'+proxy_coal_map.loc[igroup,'GHGI_Emi_Group']][istate,iyear] += vars()[proxy_coal_map.loc[igroup,'GHGI_Emi_Group']][iyear] * \\\n",
    "                        data_fn.safe_div(vars()[proxy_coal_map.loc[igroup,'State_Proxy_Group']][istate,iyear], np.sum(vars()[proxy_coal_map.loc[igroup,'State_Proxy_Group']][:,iyear]))\n",
    "            else:\n",
    "                vars()['NonState_'+proxy_coal_map.loc[igroup,'GHGI_Emi_Group']][iyear] = vars()[proxy_coal_map.loc[igroup,'GHGI_Emi_Group']][iyear]\n",
    "                \n",
    "# Check sum of all gridded emissions + emissions not included in state allocation\n",
    "print('QA/QC #1: Check weighted emissions against GHGI')   \n",
    "for iyear in np.arange(0,num_years):\n",
    "    summary_emi = EPA_emi_coal_total.iloc[0,iyear+2] \n",
    "    calc_emi = 0\n",
    "    for igroup in np.arange(0,len(proxy_coal_map)):\n",
    "        calc_emi +=  np.sum(vars()['State_'+proxy_coal_map.loc[igroup,'GHGI_Emi_Group']][:,iyear])+\\\n",
    "            vars()['NonState_'+proxy_coal_map.loc[igroup,'GHGI_Emi_Group']][iyear] \n",
    "    if DEBUG ==1:\n",
    "        print(summary_emi)\n",
    "        print(calc_emi)\n",
    "    diff = abs(summary_emi-calc_emi)/((summary_emi+calc_emi)/2)\n",
    "    if diff < 0.0002:\n",
    "        print('Year ', year_range[iyear], ': PASS, difference < 0.01%')\n",
    "    else:\n",
    "        print('Year ', year_range[iyear], ': FAIL -- Difference = ', diff*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 4.1.3 Allocate emissions to the CONUS region (0.1x0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Allocate State-Level emissions (Tg) onto a 0.1x0.1 grid using gridcell level 'Proxy_Groups'\n",
    "\n",
    "DEBUG =1\n",
    "#Define emission arrays\n",
    "Emissions_array_01 = np.zeros([len(Lat_01),len(Lon_01),num_years])\n",
    "Emissions_surf_array_01 = np.zeros([len(Lat_01),len(Lon_01),num_years])\n",
    "Emissions_und_array_01 = np.zeros([len(Lat_01),len(Lon_01),num_years])\n",
    "Emissions_array_001 = np.zeros([len(lat001),len(lon001),num_years])\n",
    "Emissions_surf_array_001= np.zeros([len(lat001),len(lon001),num_years])\n",
    "Emissions_und_array_001 = np.zeros([len(lat001),len(lon001),num_years]) \n",
    "Emissions_nongrid = np.zeros([num_years])\n",
    "Emissions_surf_nongrid = np.zeros([num_years])\n",
    "Emissions_und_nongrid = np.zeros([num_years])\n",
    "\n",
    "\n",
    "# For each year, (2a) distribute state-level emissions onto a grid using proxies defined above ....\n",
    "# To speed up the code, masks are used rather than looping individually through each lat/lon. \n",
    "# In this case, a mask of 1's is made for the grid cells that match the ANSI values for a given state\n",
    "# The masked values are set to zero, remaining values = 1. \n",
    "# AK and HI and territories are removed from the analysis at this stage. \n",
    "# The emissions allocated to each state are at 0.01x0.01 degree resolution, as required to calculate accurate 'mask'\n",
    "# arrays for each state. \n",
    "# (2b - not applicable here) For emission groups that were not first allocated to states, national emissions for those groups are gridded\n",
    "# based on the relevant gridded proxy arrays (0.1x0.1 resolution). These emissions are at 0.1x0.1 degrees resolution. \n",
    "# (2c - not applicable here) - record 'not mapped' emission groups in the 'non-grid' array\n",
    "\n",
    "print('**QA/QC Check: Sum of national gridded emissions vs. GHGI national emissions')\n",
    "running_sum = np.zeros([len(proxy_coal_map),num_years])\n",
    "\n",
    "for igroup in np.arange(0,len(proxy_coal_map)):\n",
    "    proxy_temp = vars()[proxy_coal_map.loc[igroup,'Proxy_Group']]\n",
    "    proxy_temp_nongrid = vars()[proxy_coal_map.loc[igroup,'Proxy_Group']+'_nongrid']\n",
    "    vars()['Ext_'+proxy_coal_map.loc[igroup,'GHGI_Emi_Group']+'_01'] = np.zeros([len(lat001),len(lon001),num_years])\n",
    "\n",
    "    #2a. Step through each state (if group was previously allocated to state level)\n",
    "    if proxy_coal_map.loc[igroup,'State_Proxy_Group'] != '-' and \\\n",
    "        proxy_coal_map.loc[igroup,'State_Proxy_Group'] != 'state_not_mapped':\n",
    "        print('Group:',igroup,'of ',len(proxy_coal_map))\n",
    "        for istate in np.arange(0,len(State_ANSI)):\n",
    "            #print(igroup,istate)\n",
    "            \n",
    "            if State_ANSI['abbr'][istate] not in {'AK','HI'} and istate < 51:\n",
    "                mask_state = np.ma.ones(np.shape(state_ANSI_map))\n",
    "                mask_state = np.ma.masked_where(state_ANSI_map != State_ANSI['ansi'][istate], mask_state)\n",
    "                mask_state = np.ma.filled(mask_state,0) \n",
    "                for iyear in np.arange(0,num_years):\n",
    "                    emi_temp = vars()['State_'+proxy_coal_map.loc[igroup,'GHGI_Emi_Group']][istate,iyear]\n",
    "                    #print(emi_temp)\n",
    "                    if np.sum(mask_state*proxy_temp[:,:,iyear]) > 0 and emi_temp > 0: \n",
    "                    # if state is on grid and proxy for that state is non-zero\n",
    "                        weighted_array = data_fn.safe_div(mask_state*proxy_temp[:,:,iyear], \\\n",
    "                                            np.sum(mask_state*proxy_temp[:,:,iyear]))\n",
    "                        #weighted_array_01 = data_fn.regrid001_to_01(weighted_array, Lat_01, Lon_01)\n",
    "                        #print(np.sum(weighted_array))\n",
    "                        Emissions_array_001[:,:,iyear] += emi_temp*weighted_array#_01\n",
    "                        running_sum[igroup,iyear] += np.sum(emi_temp*weighted_array)\n",
    "                        if 'Surf' in 'State_'+proxy_coal_map.loc[igroup,'GHGI_Emi_Group']:\n",
    "                            Emissions_surf_array_001[:,:,iyear] += emi_temp*weighted_array\n",
    "                        else:\n",
    "                            Emissions_und_array_001[:,:,iyear] += emi_temp*weighted_array\n",
    "                        vars()['Ext_'+proxy_coal_map.loc[igroup,'GHGI_Emi_Group']+'_01'][:,:,iyear]+=emi_temp*weighted_array\n",
    "                    else:\n",
    "                        #for imonth in np.arange(0,num_months):\n",
    "                        Emissions_nongrid[iyear] += emi_temp\n",
    "                        running_sum[igroup,iyear] += np.sum(emi_temp)\n",
    "                        if 'Surf' in 'State_'+proxy_coal_map.loc[igroup,'GHGI_Emi_Group']:\n",
    "                            Emissions_surf_nongrid[iyear] += emi_temp\n",
    "                        else:\n",
    "                            Emissions_und_nongrid[iyear] += emi_temp\n",
    "                #print(running_sum[igroup,iyear])\n",
    "            \n",
    "\n",
    "            else:\n",
    "            #    if proxy_coal_map.loc[igroup, 'Urban_Rural_Flag'] ==2:\n",
    "                for iyear in np.arange(0, num_years):\n",
    "                    Emissions_nongrid[iyear] += np.sum(vars()['State_'+proxy_coal_map.loc[igroup,'GHGI_Emi_Group']][istate,iyear])\n",
    "                    running_sum[igroup,iyear] += np.sum(vars()['State_'+proxy_coal_map.loc[igroup,'GHGI_Emi_Group']][istate,iyear])    \n",
    "                    if 'Surf' in 'State_'+proxy_coal_map.loc[igroup,'GHGI_Emi_Group']:\n",
    "                        Emissions_surf_nongrid[iyear] += np.sum(vars()['State_'+proxy_coal_map.loc[igroup,'GHGI_Emi_Group']][istate,iyear])\n",
    "                    else:\n",
    "                        Emissions_und_nongrid[iyear] += np.sum(vars()['State_'+proxy_coal_map.loc[igroup,'GHGI_Emi_Group']][istate,iyear])\n",
    "                    \n",
    "for igroup in np.arange(0,len(proxy_coal_map)):\n",
    "    vars()['Ext_'+proxy_coal_map.loc[igroup,'GHGI_Emi_Group']] = np.zeros([len(Lat_01),len(Lon_01),num_years])\n",
    "    \n",
    "for iyear in np.arange(0, num_years):    \n",
    "    Emissions_array_01[:,:,iyear] = data_fn.regrid001_to_01(Emissions_array_001[:,:,iyear], Lat_01, Lon_01)\n",
    "    Emissions_surf_array_01[:,:,iyear] = data_fn.regrid001_to_01(Emissions_surf_array_001[:,:,iyear], Lat_01, Lon_01)\n",
    "    Emissions_und_array_01[:,:,iyear] = data_fn.regrid001_to_01(Emissions_und_array_001[:,:,iyear], Lat_01, Lon_01)\n",
    "    #Emissions_array_01[:,:,iyear] += Emissions_array_01_temp[:,:,iyear]\n",
    "    calc_emi = np.sum(Emissions_array_01[:,:,iyear]) + np.sum(Emissions_nongrid[iyear]) \n",
    "    summary_emi = EPA_emi_coal_total.iloc[0,iyear+2]\n",
    "    calc_emi3 = 0\n",
    "    for igroup in np.arange(0,len(proxy_coal_map)):\n",
    "        vars()['Ext_'+proxy_coal_map.loc[igroup,'GHGI_Emi_Group']][:,:,iyear] = data_fn.regrid001_to_01(vars()['Ext_'+proxy_coal_map.loc[igroup,'GHGI_Emi_Group']+'_01'][:,:,iyear], Lat_01, Lon_01)\n",
    "        calc_emi3 += np.sum(vars()['Ext_'+proxy_coal_map.loc[igroup,'GHGI_Emi_Group']][:,:,iyear])\n",
    "    calc_emi3 += np.sum(Emissions_nongrid[iyear])\n",
    "    emi_diff = abs(summary_emi-calc_emi)/((summary_emi+calc_emi)/2)\n",
    "    #check two\n",
    "    calc_emi2 = np.sum(Emissions_surf_array_01[:,:,iyear]) + np.sum(Emissions_surf_nongrid[iyear]) +\\\n",
    "                np.sum(Emissions_und_array_01[:,:,iyear]) + np.sum(Emissions_und_nongrid[iyear]) \n",
    "    emi_diff2 = abs(calc_emi2-calc_emi)/((calc_emi2+calc_emi)/2)\n",
    "    if DEBUG==1:\n",
    "        print(calc_emi)\n",
    "        print(calc_emi2)\n",
    "        print(calc_emi3)\n",
    "        print(summary_emi)\n",
    "    if abs(emi_diff) < 0.0001:\n",
    "        print('Year '+ year_range_str[iyear]+': Difference < 0.01%: PASS')\n",
    "    else: \n",
    "        print('Year '+ year_range_str[iyear]+': Difference > 0.01%: FAIL, diff: '+str(emi_diff))\n",
    "        \n",
    "ct = datetime.datetime.now() \n",
    "print(\"current time:\", ct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4.1.4 Save gridded emissions (kt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save gridded emissions for each gridding group - for extension\n",
    "\n",
    "#Initialize file\n",
    "data_IO_fn.initialize_netCDF(grid_emi_outputfile, netCDF_description, 0, year_range, loc_dimensions, Lat_01, Lon_01)\n",
    "\n",
    "unique_groups = np.unique(proxy_coal_map['GHGI_Emi_Group'])\n",
    "unique_groups = unique_groups[unique_groups != 'Emi_not_mapped']\n",
    "\n",
    "nc_out = Dataset(grid_emi_outputfile, 'r+', format='NETCDF4')\n",
    "\n",
    "for igroup in np.arange(0,len(unique_groups)):\n",
    "    print('Ext_'+unique_groups[igroup])\n",
    "    if len(np.shape(vars()['Ext_'+unique_groups[igroup]])) ==4:\n",
    "        ghgi_temp = np.sum(vars()[unique_groups[igroup]],axis=3) #sum month data if data is monthly\n",
    "    else:\n",
    "        ghgi_temp = vars()['Ext_'+unique_groups[igroup]]\n",
    "\n",
    "    # Write data to netCDF\n",
    "    data_out = nc_out.createVariable('Ext_'+unique_groups[igroup], 'f8', ('lat', 'lon','year'), zlib=True)\n",
    "    data_out[:,:,:] = ghgi_temp[:,:,:]\n",
    "\n",
    "#save nongrid data to calculate non-grid fraction extension\n",
    "data_out = nc_out.createVariable('Emissions_nongrid', 'f8', ('year'), zlib=True)  \n",
    "data_out[:] = Emissions_surf_nongrid[:]+Emissions_und_nongrid[:]\n",
    "nc_out.close()\n",
    "\n",
    "#Confirm file location\n",
    "print('** SUCCESS **')\n",
    "print(\"Gridded emissions (kt) written to file: {}\" .format(os.getcwd())+grid_emi_outputfile)\n",
    "print(' ')\n",
    "\n",
    "del data_out, ghgi_temp, nc_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Calculate Gridded Emission Fluxes (molec./cm2/s) (0.1x0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Convert emissions to emission flux\n",
    "# conversion: Tg emissions to molec/cm2/s flux\n",
    "\n",
    "Flux_array_01_annual = np.zeros([len(Lat_01),len(Lon_01),num_years])\n",
    "Flux_surf_array_01_annual = np.zeros([len(Lat_01),len(Lon_01),num_years])\n",
    "Flux_und_array_01_annual = np.zeros([len(Lat_01),len(Lon_01),num_years])\n",
    "print('**QA/QC Check: Sum of national gridded emissions vs. GHGI national emissions')\n",
    "  \n",
    "for iyear in np.arange(0,num_years):\n",
    "    calc_emi = 0\n",
    "    if year_range[iyear]==2012 or year_range[iyear]==2016:\n",
    "        year_days = np.sum(month_day_leap)\n",
    "    else:\n",
    "        year_days = np.sum(month_day_nonleap)\n",
    "\n",
    "    conversion_factor_01 = 10**12 * Avogadro / float(Molarch4 *year_days * 24 * 60 *60) / area_matrix_01\n",
    "    Flux_array_01_annual[:,:,iyear] = Emissions_array_01[:,:,iyear]*conversion_factor_01\n",
    "    Flux_surf_array_01_annual[:,:,iyear] = Emissions_surf_array_01[:,:,iyear]*conversion_factor_01\n",
    "    Flux_und_array_01_annual[:,:,iyear] = Emissions_und_array_01[:,:,iyear]*conversion_factor_01\n",
    "    #convert back to mass to check\n",
    "    conversion_factor_annual = 10**12 * Avogadro / float(Molarch4 *year_days * 24 * 60 *60) / area_matrix_01\n",
    "    calc_emi = np.sum(Flux_array_01_annual[:,:,iyear]/conversion_factor_annual)+np.sum(Emissions_nongrid[iyear])\n",
    "    calc_emi2 = np.sum(Flux_surf_array_01_annual[:,:,iyear]/conversion_factor_annual)+np.sum(Emissions_surf_nongrid[iyear]) +\\\n",
    "                np.sum(Flux_und_array_01_annual[:,:,iyear]/conversion_factor_annual)+np.sum(Emissions_und_nongrid[iyear])\n",
    "    summary_emi = EPA_emi_coal_total.iloc[0,iyear+2]\n",
    "    emi_diff = abs(summary_emi-calc_emi)/((summary_emi+calc_emi)/2)\n",
    "    if DEBUG==1:\n",
    "        print(calc_emi)\n",
    "        print(calc_emi2)\n",
    "        print(summary_emi)\n",
    "    if abs(emi_diff) < 0.0001:\n",
    "        print('Year '+ year_range_str[iyear]+': Difference < 0.01%: PASS')\n",
    "    else: \n",
    "        print('Year '+ year_range_str[iyear]+': Difference > 0.01%: FAIL, diff: '+str(emi_diff))\n",
    "        \n",
    "Flux_Emissions_Total_annual = Flux_array_01_annual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "## Step 5. Write netCDF\n",
    "------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yearly data\n",
    "#Initialize file\n",
    "data_IO_fn.initialize_netCDF(gridded_outputfile, netCDF_description, 0, year_range, loc_dimensions, Lat_01, Lon_01)\n",
    "\n",
    "# Write data to netCDF\n",
    "nc_out = Dataset(gridded_outputfile, 'r+', format='NETCDF4')\n",
    "nc_out.variables['emi_ch4'][:,:,:] = Flux_Emissions_Total_annual\n",
    "nc_out.close()\n",
    "#Confirm file location\n",
    "print('** SUCCESS **')\n",
    "print(\"Gridded total coal mine fluxes written to file: {}\" .format(os.getcwd())+gridded_outputfile)\n",
    "\n",
    "\n",
    "# yearly data - surface emissions ONLY (post-mining and venting)\n",
    "#Initialize file\n",
    "data_IO_fn.initialize_netCDF(gridded_surf_outputfile, netCDF_surf_description, 0, year_range, loc_dimensions, Lat_01, Lon_01)\n",
    "\n",
    "# Write data to netCDF\n",
    "nc_out = Dataset(gridded_surf_outputfile, 'r+', format='NETCDF4')\n",
    "nc_out.variables['emi_ch4'][:,:,:] = Flux_surf_array_01_annual\n",
    "nc_out.close()\n",
    "#Confirm file location\n",
    "print('** SUCCESS **')\n",
    "print(\"Gridded surface coal mine fluxes written to file: {}\" .format(os.getcwd())+gridded_surf_outputfile)\n",
    "\n",
    "\n",
    "# yearly data - Underground emissions ONLY (post mining + venting)\n",
    "#Initialize file\n",
    "data_IO_fn.initialize_netCDF(gridded_und_outputfile, netCDF_und_description, 0, year_range, loc_dimensions, Lat_01, Lon_01)\n",
    "\n",
    "# Write data to netCDF\n",
    "nc_out = Dataset(gridded_und_outputfile, 'r+', format='NETCDF4')\n",
    "nc_out.variables['emi_ch4'][:,:,:] = Flux_und_array_01_annual\n",
    "nc_out.close()\n",
    "#Confirm file location\n",
    "print('** SUCCESS **')\n",
    "print(\"Gridded underground coal mine fluxes written to file: {}\" .format(os.getcwd())+gridded_und_outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "## Step 6. Plot Gridded Data\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6.1. Plot Annual Emission Fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plot Annual Data\n",
    "scale_max = 10\n",
    "save_flag =0\n",
    "save_outfile =''\n",
    "data_plot_fn.plot_annual_emission_flux_map(Flux_Emissions_Total_annual, Lat_01, Lon_01, year_range, title_str,scale_max,save_flag,save_outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plot Annual Data - Surface Emissions Only\n",
    "scale_max = 10\n",
    "save_flag =0\n",
    "save_outfile =''\n",
    "data_plot_fn.plot_annual_emission_flux_map(Flux_surf_array_01_annual, Lat_01, Lon_01, year_range, title_str,scale_max,save_flag,save_outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plot Annual Data - Underground Emissions Only\n",
    "scale_max = 10\n",
    "save_flag =0\n",
    "save_outfile =''\n",
    "data_plot_fn.plot_annual_emission_flux_map(Flux_und_array_01_annual, Lat_01, Lon_01, year_range, title_str,scale_max,save_flag,save_outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6.2 Plot Difference between first and last inventory year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot difference between last and first year\n",
    "save_flag =0\n",
    "save_fig = ''\n",
    "data_plot_fn.plot_diff_emission_flux_map(Flux_Emissions_Total_annual, Lat_01, Lon_01, year_range, title_diff_str,save_flag,save_outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot difference between last and first year - Surface Emissions Only\n",
    "save_flag =0\n",
    "save_fig = ''\n",
    "data_plot_fn.plot_diff_emission_flux_map(Flux_surf_array_01_annual, Lat_01, Lon_01, year_range, title_diff_str,save_flag,save_outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot difference between last and first year - Underground Emissions Only\n",
    "save_flag =0\n",
    "save_fig = ''\n",
    "data_plot_fn.plot_diff_emission_flux_map(Flux_und_array_01_annual, Lat_01, Lon_01, year_range, title_diff_str,save_flag,save_outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = datetime.datetime.now() \n",
    "ft = ct.timestamp() \n",
    "time_elapsed = (ft-it)/(60*60)\n",
    "print('Time to run: '+str(time_elapsed)+' hours')\n",
    "print('** GEPA_1B1a_Coal: COMPLETE **')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
