{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridded EPA Methane Inventory\n",
    "## Category: 1B1a Abandoned Coal Mines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### Authors: \n",
    "Joannes D. Maasakkers, Erin E. McDuffie\n",
    "#### Date Last Updated: \n",
    "see Step 0\n",
    "#### Notebook Purpose: \n",
    "This Notebook calculates and saves annual gridded (0.1°x0.1°) methane emission fluxes (molec./cm2/s) from abandoned coal mines in the CONUS region between 2012-2018.    \n",
    "#### Summary & Notes:\n",
    "EPA GHGI abandoned underground coal mine emissions are read in at the national level from the GHGI (from GHGI workbook). Net liberated and recovered & used emissions are grouped into a single emissions group. National emissions are allocated to relative mine-level emission estimates. The complete list of abandoned mines is from 2021 GHGI workbook (largely from the MSHA database), which includes active emission estimates (at the time of abandonment) and MSHA IDs. Mine emissions are calculated using emission decay curves (also used in the GHGI) as a function of mine type, basin, and the number of years since closure. National emissions are then mapped to a 0.01°x0.01° grid using latitude and longitude values from the MSHA master mine database (matched based on ID, mine name, state, and county). For mines on the master list whose location could not be found, emissions are allocated across the county on record for that mine.  All emissions are re-gridded to a 0.1°x0.1° grid. Emissions are converted to emission flux. Annual emission fluxes (molec./cm2/s) are written to final netCDFs in the ‘/code/Final_Gridded_Data/’ folder.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "## Step 0. Set-Up Notebook Modules, Functions, and Local Parameters and Constants\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirm working directory\n",
    "import os\n",
    "import time\n",
    "modtime = os.path.getmtime('./v2_1B1a_Coal_Abandoned.ipynb')\n",
    "modificationTime = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(modtime))\n",
    "print(\"This file was last modified on: \", modificationTime)\n",
    "print('')\n",
    "print(\"The directory we are working in is {}\" .format(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Include plots within notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import base modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import datetime\n",
    "from copy import copy\n",
    "\n",
    "# Import additional modules\n",
    "# Load plotting package Basemap \n",
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "# Load netCDF (for manipulating netCDF file types)\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "# Set up ticker\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "#add path for the global function module (file)\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../Global_Functions/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# Load Tabula (for reading tables from PDFs)\n",
    "import tabula as tb   \n",
    "    \n",
    "# Load user-defined global functions (modules)\n",
    "import data_load_functions as data_load_fn\n",
    "import data_functions as data_fn\n",
    "import data_IO_functions as data_IO_fn\n",
    "import data_plot_functions as data_plot_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INPUT Files\n",
    "# Assign global file names\n",
    "global_filenames = data_load_fn.load_global_file_names()\n",
    "State_ANSI_inputfile = global_filenames[0]\n",
    "County_ANSI_inputfile = global_filenames[1]\n",
    "pop_map_inputfile = global_filenames[2]\n",
    "Grid_area01_inputfile = global_filenames[3]\n",
    "Grid_area001_inputfile = global_filenames[4]\n",
    "Grid_state001_ansi_inputfile = global_filenames[5]\n",
    "Grid_county001_ansi_inputfile = global_filenames[6]\n",
    "globalinputlocation = global_filenames[0][0:20]\n",
    "print(globalinputlocation)\n",
    "\n",
    "# Specify names of inputs files used in this notebook\n",
    "#EPA Data\n",
    "EPA_abdcoal_inputfile = '../Global_InputData/GHGI/Ch3_Energy/AbandonedCoalMines1990-2018_02.20.20.xlsm'\n",
    "EPA_abdcoal_2019_inputfile = '../Global_InputData/GHGI/Ch3_Energy/AbandonedCoalMines1990-2019_erg_03-04-2021.xlsm'\n",
    "\n",
    "#Proxy Data file\n",
    "AbdCoal_Mapping_inputfile = \"./InputData/AbandonedCoal_ProxyMapping.xlsx\"\n",
    "\n",
    "\n",
    "#Activity Data\n",
    "Mine_loc_inputfile = \"../Global_InputData/MSHA/Mines.txt\"\n",
    "AbdMine_list_inputfile = \"./InputData/amm_opportunities_list.csv\"\n",
    "\n",
    "\n",
    "#OUTPUT FILES\n",
    "gridded_outputfile = '../Final_Gridded_Data/EPA_v2_1B1a_Abandoned_Coal.nc'\n",
    "netCDF_description = 'Gridded EPA Inventory - Abandoned Underground Coal Mine Emissions - IPCC Source Category 1B1a'\n",
    "title_str = \"EPA methane emissions from abandoned coal mines\"\n",
    "title_diff_str = \"Emissions from abandoned coal mines difference: 2018-2012\"\n",
    "\n",
    "#output gridded proxy data\n",
    "grid_emi_outputfile = '../Final_Gridded_Data/Extension/v2_input_data/Abandoned_Coal_Grid_Emi.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define local variables\n",
    "start_year = 2012  #First year in emission timeseries\n",
    "end_year = 2018    #Last year in emission timeseries\n",
    "year_range = [*range(start_year, end_year+1,1)] #List of emission years\n",
    "year_range_str=[str(i) for i in year_range]\n",
    "num_years = len(year_range)\n",
    "\n",
    "# Define constants\n",
    "Avogadro   = 6.02214129 * 10**(23)  #molecules/mol\n",
    "Molarch4   = 16.04                  #g/mol\n",
    "Res01      = 0.1                    # degrees\n",
    "Res_01     = 0.01\n",
    "tg_scale   = 0.001                  #Tg scale number [New file allows for the exclusion of the territories] \n",
    "\n",
    "# Continental US Lat/Lon Limits (for netCDF files)\n",
    "Lon_left = -130       #deg\n",
    "Lon_right = -60       #deg\n",
    "Lat_low  = 20         #deg\n",
    "Lat_up  = 55          #deg\n",
    "loc_dimensions = [Lat_low, Lat_up, Lon_left, Lon_right]\n",
    "\n",
    "ilat_start = int((90+Lat_low)/Res01) #1100:1450 (continental US range)\n",
    "ilat_end = int((90+Lat_up)/Res01)\n",
    "ilon_start = abs(int((-180-Lon_left)/Res01)) #500:1200 (continental US range)\n",
    "ilon_end = abs(int((-180-Lon_right)/Res01))\n",
    "\n",
    "# Number of days in each month\n",
    "month_day_leap  = [  31,  29,  31,  30,  31,  30,  31,  31,  30,  31,  30,  31]\n",
    "month_day_nonleap = [  31,  28,  31,  30,  31,  30,  31,  31,  30,  31,  30,  31]\n",
    "\n",
    "# Month arrays\n",
    "month_range_str = ['January','February','March','April','May','June','July','August','September','October','November','December']\n",
    "num_months = len(month_range_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.auto_scroll_threshold = 9999;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track run time\n",
    "ct = datetime.datetime.now() \n",
    "it = ct.timestamp() \n",
    "print(\"current time:\", ct) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "## Step 1. Load in State ANSI data and Area Maps\n",
    "_____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State-level ANSI Data\n",
    "#Read the state ANSI file array\n",
    "State_ANSI, name_dict = data_load_fn.load_state_ansi(State_ANSI_inputfile)[0:2]\n",
    "#QA: number of states\n",
    "print('Read input file: '+ f\"{State_ANSI_inputfile}\")\n",
    "print('Total \"States\" found: ' + '%.0f' % len(State_ANSI))\n",
    "print(' ')\n",
    "\n",
    "abbr_dict = State_ANSI.set_index('abbr')['ansi'].to_dict()\n",
    "name_dict = State_ANSI.set_index('name')['ansi'].to_dict()\n",
    "\n",
    "# 0.01 x0.01 degree Data\n",
    "# State ANSI IDs and grid cell area (m2) maps\n",
    "state_ANSI_map = data_load_fn.load_state_ansi_map(Grid_state001_ansi_inputfile)\n",
    "area_map, lat001, lon001 = data_load_fn.load_area_map_001(Grid_area001_inputfile)\n",
    "\n",
    "#County ANSI Data\n",
    "#Includes State ANSI number, county ANSI number, county name, and country area (square miles)\n",
    "County_ANSI = pd.read_csv(County_ANSI_inputfile,encoding='latin-1')\n",
    "#QA: number of counties\n",
    "print ('Read input file: ' + f\"{County_ANSI_inputfile}\")\n",
    "print('Total \"Counties\" found (include PR): ' + '%.0f' % len(County_ANSI))\n",
    "print(' ')\n",
    "for icounty in np.arange(0,len(County_ANSI)):\n",
    "    County_ANSI.loc[icounty,'Name'] = County_ANSI.loc[icounty,'Name'].lower().strip()\n",
    "    \n",
    "# 0.01 x0.01 degree Data\n",
    "# State ANSI IDs and grid cell area (m2) maps\n",
    "state_ANSI_map = data_load_fn.load_state_ansi_map(Grid_state001_ansi_inputfile)\n",
    "state_ANSI_map = state_ANSI_map.astype('int32')\n",
    "county_ANSI_map = data_load_fn.load_county_ansi_map(Grid_county001_ansi_inputfile)\n",
    "county_ANSI_map = county_ANSI_map.astype('int32')\n",
    "area_map, lat001, lon001 = data_load_fn.load_area_map_001(Grid_area001_inputfile)\n",
    "\n",
    "# 0.1 x0.1 degree data\n",
    "# grid cell area and state and county ANSI maps\n",
    "area_map01, Lat01, Lon01 = data_load_fn.load_area_map_01(Grid_area01_inputfile)[0:3]\n",
    "#Select relevant Continental 0.1 x0.1 domain\n",
    "Lat_01 = Lat01[ilat_start:ilat_end]\n",
    "Lon_01 = Lon01[ilon_start:ilon_end]\n",
    "area_matrix_01 = data_fn.regrid001_to_01(area_map, Lat_01, Lon_01)\n",
    "area_matrix_01 *= 10000  #convert from m2 to cm2\n",
    "\n",
    "state_ANSI_map_01 = data_fn.regrid001_to_01(state_ANSI_map, Lat_01, Lon_01)\n",
    "\n",
    "# Print time\n",
    "ct = datetime.datetime.now() \n",
    "print(\"current time:\", ct) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "## Step 2: Read-in and Format Proxy Data\n",
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.1 Read In Proxy Mapping File & Make Proxy Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load GHGI Mapping Groups\n",
    "names = pd.read_excel(AbdCoal_Mapping_inputfile, sheet_name = \"GHGI Map - Abn. Coal\", usecols = \"A:B\",skiprows = 1, header = 0)\n",
    "colnames = names.columns.values\n",
    "ghgi_abdcoal_map = pd.read_excel(AbdCoal_Mapping_inputfile, sheet_name = \"GHGI Map - Abn. Coal\", usecols = \"A:B\", skiprows = 1, names = colnames)\n",
    "#drop rows with no data, remove the parentheses and \"\"\n",
    "ghgi_abdcoal_map = ghgi_abdcoal_map[ghgi_abdcoal_map['GHGI_Emi_Group'] != 'na']\n",
    "ghgi_abdcoal_map = ghgi_abdcoal_map[ghgi_abdcoal_map['GHGI_Emi_Group'].notna()]\n",
    "ghgi_abdcoal_map['GHGI_Source']= ghgi_abdcoal_map['GHGI_Source'].str.replace(r\"\\(\",\"\")\n",
    "ghgi_abdcoal_map['GHGI_Source']= ghgi_abdcoal_map['GHGI_Source'].str.replace(r\"\\)\",\"\")\n",
    "ghgi_abdcoal_map.reset_index(inplace=True, drop=True)\n",
    "display(ghgi_abdcoal_map)\n",
    "\n",
    "#load emission group - proxy map\n",
    "names = pd.read_excel(AbdCoal_Mapping_inputfile, sheet_name = \"Proxy Map - Abn. Coal\", usecols = \"A:C\",skiprows = 1, header = 0)\n",
    "colnames = names.columns.values\n",
    "proxy_abdcoal_map = pd.read_excel(AbdCoal_Mapping_inputfile, sheet_name = \"Proxy Map - Abn. Coal\", usecols = \"A:C\", skiprows = 1, names = colnames)\n",
    "display((proxy_abdcoal_map))\n",
    "\n",
    "#create empty proxy and emission group arrays (add months for proxy variables that have monthly data)\n",
    "for igroup in np.arange(0,len(proxy_abdcoal_map)):\n",
    "    if proxy_abdcoal_map.loc[igroup, 'Grid_Month_Flag'] ==0:\n",
    "        vars()[proxy_abdcoal_map.loc[igroup,'Proxy_Group']] = np.zeros([len(Lat_01),len(Lon_01),num_years])\n",
    "        vars()[proxy_abdcoal_map.loc[igroup,'Proxy_Group']+'_nongrid'] = np.zeros([num_years])\n",
    "    else:\n",
    "        vars()[proxy_abdcoal_map.loc[igroup,'Proxy_Group']] = np.zeros([len(Lat_01),len(Lon_01),num_years,num_months])\n",
    "        vars()[proxy_abdcoal_map.loc[igroup,'Proxy_Group']+'_nongrid'] = np.zeros([num_years,num_months])\n",
    "        \n",
    "    vars()[proxy_abdcoal_map.loc[igroup,'GHGI_Emi_Group']] = np.zeros([num_years])\n",
    "    \n",
    "   # if proxy_abdcoal_map.loc[igroup,'State_Proxy_Group'] != '-':\n",
    "   #     if proxy_abdcoal_map.loc[igroup,'State_Month_Flag'] == 0:\n",
    "   #         vars()[proxy_abdcoal_map.loc[igroup,'State_Proxy_Group']] = np.zeros([len(State_ANSI),num_years])\n",
    "   #         #print('here')\n",
    "   #     else:\n",
    "   #         vars()[proxy_abdcoal_map.loc[igroup,'State_Proxy_Group']] = np.zeros([len(State_ANSI),num_years,num_months])\n",
    "   # else:\n",
    "   #     continue # do not make state proxy variable if no variable assigned in mapping file\n",
    "        \n",
    "emi_group_names = np.unique(ghgi_abdcoal_map['GHGI_Emi_Group'])\n",
    "\n",
    "print('QA/QC: Is the number of emission groups the same for the proxy and emissions tabs?')\n",
    "if (len(emi_group_names) == len(np.unique(proxy_abdcoal_map['GHGI_Emi_Group']))):\n",
    "    print('PASS')\n",
    "else:\n",
    "    print('FAIL')\n",
    "    print(emi_group_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.2. Create and Format Mine Level Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2.2.1. Read in Abandoned Mine List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Abandoned coal mine list - from the GHGI (this list was added starting with the 1990-2019 GHGI workbook). \n",
    "# Future updates to this code should update this file to refelct the latest GHGI workbook. \n",
    "\n",
    "abdmines = names = pd.read_excel(EPA_abdcoal_2019_inputfile, sheet_name = \"Mine List\", usecols = \"A:K\",skiprows = 5, header = 0)\n",
    "\n",
    "abdmines = abdmines[abdmines['Year'] != 'x'].copy()\n",
    "abdmines.reset_index(inplace=True, drop=True)\n",
    "abdmines.loc[:,'Date of Aban.'] = abdmines.loc[:,'Date of Aban.'].dt.strftime(\"%m/%d/%y\")\n",
    "\n",
    "list_duplicated = abdmines['MSHA ID'][abdmines['MSHA ID'].duplicated()]\n",
    "print('Duplicate MSHA IDs: ', np.array(list_duplicated[list_duplicated.notna()]))\n",
    "\n",
    "display(abdmines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2.2.2. Read in mine locations from MSHA database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read mine locations from MHSA (data.gov) - Same as the one used for coal mining\n",
    "mine_loc = pd.read_csv(Mine_loc_inputfile,sep=\"|\",encoding= 'unicode_escape')\n",
    "\n",
    "mine_loc = mine_loc[mine_loc['COAL_METAL_IND']=='C']\n",
    "#display(mine_loc)\n",
    "mine_loc = mine_loc[mine_loc['LONGITUDE']!=0]\n",
    "mine_loc.reset_index(inplace=True, drop=True)\n",
    "mine_loc['date_abd'] = ''\n",
    "#display(mine_loc.head(5))\n",
    "\n",
    "#Put in dates consistent with the other array\n",
    "for imine in np.arange(len(mine_loc)):\n",
    "    mine_loc.loc[imine,'date_abd'] = mine_loc['CURRENT_STATUS_DT'][imine][:2] + '/' + mine_loc['CURRENT_STATUS_DT'][imine][3:5] + '/' + mine_loc['CURRENT_STATUS_DT'][imine][8:10]\n",
    "    if mine_loc.loc[imine,'LONGITUDE'] >0:\n",
    "        mine_loc.loc[imine,'LONGITUDE'] = -mine_loc.loc[imine,'LONGITUDE'] #logitudes must be set to negative (raw data have mix of + and - longitudes)\n",
    "# Current mine status from the MSHA database isn't used in the opportunities database so also not used here. \n",
    "\n",
    "#mine_loc.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.2.3. Add location, status, and county to abandoned mine list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add mine locations, status, basin code, and county to abandoned mine list\n",
    "\n",
    "# Step 1 - Find mine location based on series of checks (based on MSHA ID, state, county, mine name, abandonment date)\n",
    "# Step 2 - Clean up text on current status and recovery status\n",
    "# Step 3 - Add basin number\n",
    "# Step 4 - Format and record the days since abandonment \n",
    "# Step 5 - Clean up county name and add to mine array\n",
    "\n",
    "# Initialize variables\n",
    "abdmines.loc[:,'lon'] = 0.0\n",
    "abdmines.loc[:,'lat'] = 0.0\n",
    "abdmines.loc[:,'Status'] = ''\n",
    "abdmines.loc[:,'Recovering'] = 0\n",
    "abdmines.loc[:,'Basin_nr'] = 5 #Initialize to an error value (there are 5 basins)\n",
    "\n",
    "# Make sure we only use mines once\n",
    "mine_loc['used'] = 0\n",
    "\n",
    "mines_matched_msha = []\n",
    "mines_matched_namedate = []\n",
    "mines_matched_date = []\n",
    "mines_matched_name = []\n",
    "\n",
    "for iyear in np.arange(0,num_years): #Initialize columns for days closed for each year\n",
    "    col_name = 'Days_closed_'+year_range_str[iyear]\n",
    "    abdmines.loc[:,col_name]=0.0\n",
    "    col_name = 'Fraction_year_closed_'+year_range_str[iyear]\n",
    "    abdmines.loc[:,col_name]=1.0\n",
    "#print(np.shape(abdmines))\n",
    "\n",
    "    \n",
    "for imine in np.arange(0,len(abdmines)):\n",
    "    ## Step 1 - find mine location\n",
    "    location_found = 0\n",
    "    \n",
    "    # 1A) First, check to see if there is a match based on MSHA ID (between MSHA & Abd mine datasets). If so, record the mine location\n",
    "    # get rid of dashes in MSHA IDs in the abandoned mines data set\n",
    "    #print(imine, abdmines['MSHA ID'][imine])\n",
    "    abdmines['MSHA ID'][imine] = str(abdmines['MSHA ID'][imine])\n",
    "    try:\n",
    "        MSHA_String = abdmines['MSHA ID'][imine].replace('-','')\n",
    "    except:\n",
    "        MSHA_String = abdmines['MSHA ID'][imine]\n",
    "        \n",
    "    matched_id = np.where((mine_loc['MINE_ID'].astype(str) == MSHA_String) & (mine_loc['used'] == 0))[0]\n",
    "    if len(matched_id) >0:\n",
    "        matched_id = matched_id[0]\n",
    "        if mine_loc['LONGITUDE'][matched_id] > Lon_left and mine_loc['LONGITUDE'][matched_id] < Lon_right and \\\n",
    "            mine_loc['LATITUDE'][matched_id] > Lat_low and mine_loc['LATITUDE'][matched_id] < Lat_up:\n",
    "            abdmines.loc[imine,'lon'] = mine_loc['LONGITUDE'][matched_id]\n",
    "            abdmines.loc[imine,'lat'] = mine_loc['LATITUDE'][matched_id]\n",
    "            location_found = 1\n",
    "            mines_matched_msha.append(imine)\n",
    "    \n",
    "    \n",
    "    # 1B) otherwise, check to see if there is a match of based on state, county, mine name, and abandonment date. If so, record mine location\n",
    "    matched_mine = np.where((mine_loc['STATE'] == abdmines['State'][imine]) & \\\n",
    "                       (mine_loc['FIPS_CNTY_NM'] == abdmines['County'][imine]) & \\\n",
    "                       (mine_loc['CURRENT_MINE_NAME'] == abdmines['Mine Name'][imine])& \\\n",
    "                       (mine_loc['date_abd'] == abdmines['Date of Aban.'][imine])& (mine_loc['used'] == 0))[0]\n",
    "    #print(matched_mine)\n",
    "    if len(matched_mine) > 0 and location_found == 0:\n",
    "        matched_mine = matched_mine[0]\n",
    "        if mine_loc['LONGITUDE'][matched_mine] > Lon_left and mine_loc['LONGITUDE'][matched_mine] < Lon_right and \\\n",
    "            mine_loc['LATITUDE'][matched_mine] > Lat_low and mine_loc['LATITUDE'][matched_mine] < Lat_up:\n",
    "            abdmines.loc[imine,'lon'] = mine_loc['LONGITUDE'][matched_mine]\n",
    "            abdmines.loc[imine,'lat'] = mine_loc['LATITUDE'][matched_mine]\n",
    "            location_found = 1\n",
    "            mines_matched_namedate.append(imine)    \n",
    "            \n",
    "    # 1C) otherwise, check to see if there is a match just based on state, county, and date of abandonment (not including mine name)...         \n",
    "    matched_mine = np.where((mine_loc['STATE'] == abdmines['State'][imine]) & \\\n",
    "                       (mine_loc['FIPS_CNTY_NM'] == abdmines['County'][imine]) & \\\n",
    "                       (mine_loc['date_abd'] == abdmines['Date of Aban.'][imine])& (mine_loc['used'] == 0))[0]\n",
    "    if len(matched_mine) >0 and location_found == 0:\n",
    "        matched_mine = matched_mine[0]\n",
    "        if mine_loc['LONGITUDE'][matched_mine] > Lon_left and mine_loc['LONGITUDE'][matched_mine] < Lon_right and \\\n",
    "            mine_loc['LATITUDE'][matched_mine] > Lat_low and mine_loc['LATITUDE'][matched_mine] < Lat_up:\n",
    "            abdmines.loc[imine,'lon'] = mine_loc['LONGITUDE'][matched_mine]\n",
    "            abdmines.loc[imine,'lat'] = mine_loc['LATITUDE'][matched_mine]\n",
    "            location_found = 1\n",
    "            mines_matched_date.append(imine)     \n",
    "            \n",
    "    # 1D) otherwise, check to see if there is a match based on state, county, and mine name\n",
    "    #See overrule with name-match\n",
    "    matched_mine = np.where((mine_loc['STATE'] == abdmines['State'][imine]) & \\\n",
    "                       (mine_loc['FIPS_CNTY_NM'] == abdmines['County'][imine]) & \\\n",
    "                       (mine_loc['CURRENT_MINE_NAME'] == abdmines['Mine Name'][imine])& \\\n",
    "                       (mine_loc['used'] == 0))[0]\n",
    "    if len(matched_mine) > 0 and location_found == 0:\n",
    "        matched_mine = matched_mine[0]\n",
    "        if mine_loc['LONGITUDE'][matched_mine] > Lon_left and mine_loc['LONGITUDE'][matched_mine] < Lon_right and \\\n",
    "        mine_loc['LATITUDE'][matched_mine] > Lat_low and mine_loc['LATITUDE'][matched_mine] < Lat_up:\n",
    "            abdmines.loc[imine,'lon'] = mine_loc['LONGITUDE'][matched_mine]\n",
    "            abdmines.loc[imine,'lat'] = mine_loc['LATITUDE'][matched_mine]\n",
    "            location_found = 1\n",
    "            mines_matched_name.append(imine)     \n",
    "\n",
    "    \n",
    "    ## Step 2. Clean up Current Status and Recovery Status Text\n",
    "    #Strip leading/trailing\n",
    "    try:\n",
    "        abdmines.loc[imine,'Current Emissions Status'] = abdmines['Current Emissions Status'][imine].strip()\n",
    "    except:\n",
    "        0\n",
    "    \n",
    "    # 2A) Clean up the current status text\n",
    "    if abdmines['Current Emissions Status'][imine] == 'Flooding' or \\\n",
    "        abdmines['Current Emissions Status'][imine] == 'Flooded/Recovering Methane' or \\\n",
    "        abdmines['Current Emissions Status'][imine] == 'Recovering Methane/Partially Flooded' or \\\n",
    "        abdmines['Current Emissions Status'][imine] == 'Flooded/Pumping Water' or \\\n",
    "        abdmines['Current Emissions Status'][imine] == 'Venting/Flooded' or \\\n",
    "        abdmines['Current Emissions Status'][imine] == 'Flooded' or \\\n",
    "        abdmines['Current Emissions Status'][imine] == 'Venting/Partially Flooded' or \\\n",
    "        abdmines['Current Emissions Status'][imine] == 'Flooding/Recovering Methane':\n",
    "        abdmines.loc[imine,'Status'] = 'Flooded'\n",
    "    elif abdmines['Current Emissions Status'][imine] == 'Sealed Recovering Methane' or \\\n",
    "        abdmines['Current Emissions Status'][imine] == 'Sealed/Partially Flooded' or \\\n",
    "        abdmines['Current Emissions Status'][imine] == 'Abandoned/Sealed' or \\\n",
    "        abdmines['Current Emissions Status'][imine] == 'Sealed/Pumping Water' or \\\n",
    "        abdmines['Current Emissions Status'][imine] == 'Temporary Seal' or \\\n",
    "        abdmines['Current Emissions Status'][imine] == 'Sealed/Filled' or \\\n",
    "        abdmines['Current Emissions Status'][imine] == 'Sealed/Recovery Pending' or \\\n",
    "        abdmines['Current Emissions Status'][imine] == 'Sealed/Recovering Methane' or \\\n",
    "        abdmines['Current Emissions Status'][imine] == 'Sealed' or \\\n",
    "        abdmines['Current Emissions Status'][imine] == 'Sealed*' or \\\n",
    "        abdmines['Current Emissions Status'][imine] == 'Sealed/Adj to Dianne Mine':\n",
    "        abdmines.loc[imine,'Status'] = 'Sealed'\n",
    "    elif abdmines['Current Emissions Status'][imine] == 'Venting/Recovering Gas' or \\\n",
    "        abdmines['Current Emissions Status'][imine] == 'Venting/Recovering Methane' or \\\n",
    "        abdmines['Current Emissions Status'][imine] == 'Venting':\n",
    "        abdmines.loc[imine,'Status'] = 'Venting'\n",
    "    else:\n",
    "        abdmines.loc[imine,'Status'] = 'Unknown'\n",
    "        \n",
    "    #2B) Clean up recovery status text\n",
    "    if abdmines['Current Emissions Status'][imine] == 'Sealed Recovering Methane' or \\\n",
    "        abdmines['Current Emissions Status'][imine] == 'Flooded/Recovering Methane' or \\\n",
    "        abdmines['Current Emissions Status'][imine] == 'Venting/Recovering Gas' or \\\n",
    "        abdmines['Current Emissions Status'][imine] == 'Recovering Methane/Partially Flooded' or \\\n",
    "        abdmines['Current Emissions Status'][imine] == 'Venting/Recovering Methane' or \\\n",
    "        abdmines['Current Emissions Status'][imine] == 'Sealed/Recovering Methane' or \\\n",
    "        abdmines['Current Emissions Status'][imine] == 'Flooding/Recovering Methane':\n",
    "        abdmines.loc[imine,'Recovering'] = 1       \n",
    "\n",
    "    ## Step 3 - Add basin number. #CA, IL, NA, BW, WS\n",
    "    # There are 5 basins, Central Appalachia, Illinois, Northern Appalachia, Warrior Basin, and Western Basins\n",
    "    # Western basins include: Arkoma [OK], Uinta [UT], Piceance [CO], Raton [CO/NM], WTB [CO]\n",
    "    if abdmines['Coal Basin'][imine] == 'Central Appl.':\n",
    "        abdmines.loc[imine,'Basin_nr'] = 0\n",
    "    elif abdmines['Coal Basin'][imine] == 'Illinois':\n",
    "        abdmines.loc[imine,'Basin_nr'] = 1\n",
    "    elif abdmines['Coal Basin'][imine] == 'Northern Appl.':\n",
    "        abdmines.loc[imine,'Basin_nr'] = 2    \n",
    "    elif abdmines['Coal Basin'][imine] == 'Warrior':\n",
    "        abdmines.loc[imine,'Basin_nr'] = 3\n",
    "    else:\n",
    "        abdmines.loc[imine,'Basin_nr'] = 4\n",
    "\n",
    "    \n",
    "    \n",
    "    ## Step 4. Record the number of days since the mine has closed\n",
    "    #Add number of days since closure\n",
    "    for iyear in np.arange(0,num_years):\n",
    "        if year_range[iyear]==2012 or year_range[iyear]==2016:\n",
    "            year_days = np.sum(month_day_leap)\n",
    "            month_days = month_day_leap\n",
    "        else:\n",
    "            year_days = np.sum(month_day_nonleap)\n",
    "            month_days = month_day_nonleap\n",
    "            \n",
    "        ab_mon = float(abdmines['Date of Aban.'][imine][:2])\n",
    "        ab_day = float(abdmines['Date of Aban.'][imine][3:5])\n",
    "        ab_yea = float(abdmines['Date of Aban.'][imine][6:8])\n",
    "\n",
    "        #Deal with faulty dates\n",
    "        if ab_mon > 12:\n",
    "            ab_day = float(abdmines['Date of Aban.'][imine][:2])\n",
    "            ab_mon = float(abdmines['Date of Aban.'][imine][3:5])\n",
    "        \n",
    "        # Count days relative to 07/02, middle of the year, for flux estimates\n",
    "        days = 0\n",
    "        days += 2 - ab_day\n",
    "        days += 31*(7-ab_mon)\n",
    "\n",
    "        if ab_yea > 19: # years in the 1900s\n",
    "            days += year_days*(year_range[iyear] - (1900 + ab_yea))\n",
    "        else: # years in the 2000s\n",
    "            days += year_days*(year_range[iyear] - (2000 + ab_yea))\n",
    "\n",
    "        abdmines.loc[imine,'Days_closed_'+year_range_str[iyear]] = days\n",
    "        \n",
    "        #Special treatment for mines that closed the same year\n",
    "        if year_range[iyear] == (2000 + ab_yea):\n",
    "            # Calculate average number of days closed by dividing days closed by 2\n",
    "            days = 0\n",
    "            days += 31 - ab_day\n",
    "            days += 30.5*(12-ab_mon)\n",
    "            abdmines.loc[imine,'Days_closed_'+year_range_str[iyear]] = days/2\n",
    "            abdmines.loc[imine,'Fraction_year_closed_'+year_range_str[iyear]] = days/year_days\n",
    "            \n",
    "## Step 5. Clean up county name and record county and state ANSI numbers in array\n",
    "abdmines['state'] = 0\n",
    "abdmines['county'] = 0\n",
    "\n",
    "for imine in np.arange(0,len(abdmines)):\n",
    "    abdmines.loc[imine,'state'] = abbr_dict[abdmines['State'][imine].strip()]\n",
    "    #Fix typos\n",
    "    if abdmines['County'][imine] == 'Clearborne':\n",
    "        abdmines.loc[imine,'County'] = 'claiborne'\n",
    "    if abdmines['County'][imine] == 'Dickerson':\n",
    "        abdmines.loc[imine,'County'] = 'dickenson'\n",
    "    if abdmines['County'][imine] == 'Davies':\n",
    "        abdmines.loc[imine,'County'] = 'daviess'\n",
    "    if abdmines['County'][imine] == 'Rosedale':\n",
    "        abdmines.loc[imine,'County'] = 'trousdale'          \n",
    "         \n",
    "    match_arr = np.where((County_ANSI['State']==abdmines['state'][imine]) & \\\n",
    "                         (County_ANSI['Name']==abdmines['County'][imine].strip().lower()))[0]\n",
    "    if len(match_arr) > 0:\n",
    "        match_arr = match_arr[0]\n",
    "        abdmines.loc[imine,'county'] = County_ANSI['County'][match_arr]\n",
    "    else:\n",
    "        abdmines.loc[imine,'county'] = 0\n",
    "\n",
    "#display(abdmines.head(1))\n",
    "\n",
    "# Report the number of mines matched based on each method. \n",
    "print('Only matched if there is a unique match')\n",
    "print('Matched on MSHA:      ', len(mines_matched_msha))\n",
    "print('Matched on name+date: ', len(mines_matched_namedate))\n",
    "print('Matched on date:      ', len(mines_matched_date))\n",
    "print('Matched on name:      ', len(mines_matched_name))\n",
    "\n",
    "#Throw out mines without either county or latitude [This throws out 2 mine]\n",
    "abdmines = abdmines[(abdmines['county'] > 0)|(abdmines['lat'] > 0)]\n",
    "abdmines.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2.2.4 Check for Mines that have been reopened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check abandoned mines database for mines that have reopened\n",
    "\n",
    "#NOTES:\n",
    "# 1) Mines reopened in 2020 will not affect this notebook run for 2012-2018. \n",
    "# 2) MSHA says mine 3600840 is active, but it is not in active mine GHGI workbook. It is in the abandoned mine workbook.\n",
    "#    abandoned in 1994. We keep it here. \n",
    "# 3) Mine 4200079 is present in active mines notebook and also has abandoned emissions. However, \n",
    "#    its emissions are only ~0.8% of Utah's abandoned mines emissions. We keep it here. \n",
    "#    Old: We remove it in the flux calculation block for 2016-2018. \n",
    "# 4) Mine 1100588 is listed as a refuse recovery mine in the active mines notebook, with coal production for the\n",
    "#    years 2012-2016. Refuse recovery mine emissions are not included in the active mining emissions estimates. \n",
    "#    This mine also has abandoned emissions and is in the abandoned GHGI workbook (close in 1995). We keep this here.\n",
    "#    #old: We remove it in the flux calculation block here for years 2014-2018.\n",
    "# 5) Check to see if there are other mines listed below. \n",
    "checker = abdmines['MSHA ID']\n",
    "checker[checker == 'nan'] = np.nan\n",
    "checker.dropna(inplace=True)\n",
    "check = checker.reset_index()\n",
    "print('REOPENED MINES')\n",
    "for idi in np.arange(len(check)):\n",
    "    ind = check['MSHA ID'].iloc[idi]\n",
    "    temp = mine_loc[mine_loc['MINE_ID']==int(ind.replace(\"-\", \"\"))]\n",
    "    #print(temp)\n",
    "    if len(temp)>0:\n",
    "        if temp['CURRENT_MINE_STATUS'].iloc[0]=='Active':\n",
    "            print('MSHA ID: ',temp['MINE_ID'].iloc[0])\n",
    "            print('Date reopened: ', mine_loc[mine_loc['MINE_ID']==int(ind.replace(\"-\", \"\"))]['CURRENT_CONTROLLER_BEGIN_DT'].iloc[0])\n",
    "            print('index',np.where(abdmines['MSHA ID']==ind)[0][0])\n",
    "            print('')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.2.5 Calculate Mine-Level Emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the timeseries of emissions from each mine based on the mine status, time since closure, and the emission \n",
    "# decay curves used in the GHGI. \n",
    "\n",
    "# Basin specific coefficients for sealed, flooded, and vented emission decay curves\n",
    "#Hard-coded coefficients, we use medium values for everything\n",
    "#Old order: NA, IL, CA, BW, WS\n",
    "#New order: CA, IL, NA, WB, WS\n",
    "b_medium = np.array([2.329011,2.314585,2.292595,2.299685,2.342465])\n",
    "D_sealed  = np.array([0.000741,0.000733,0.000725,0.000729,0.000747]) \n",
    "D_venting  = np.array([0.003735,0.003659,0.003564,0.003601,0.003803])\n",
    "D_flooded = np.array([0.672,0.672,0.672,0.672,0.672])\n",
    "\n",
    "# Calculate emissions based on years since closure and the mine status (if known)\n",
    "# If the mine status is unknown, emissions are estimated based on the fraction of mines in the given basin that are\n",
    "# flooded, venting or sealed. \n",
    "# These basin-specific mine type fractions are read in from the GHGI workbook ([year] tabs)\n",
    "\n",
    "# Initialize flux column for each year\n",
    "for iyear in np.arange(0, num_years):\n",
    "    #abdmines['Flux_'+str(year_list[iyear])] = 0.0\n",
    "    abdmines['Emis_mmcfd_'+year_range_str[iyear]] = 0.0\n",
    "    abdmines['Emis_tg_'+year_range_str[iyear]] = 0.0\n",
    "    \n",
    "    \n",
    "for iyear in np.arange(0, num_years):\n",
    "    if year_range[iyear]==2012 or year_range[iyear]==2016:\n",
    "        year_days = np.sum(month_day_leap)\n",
    "    else:\n",
    "        year_days = np.sum(month_day_nonleap)\n",
    "        \n",
    "    if year_range[iyear] == 2012 or year_range[iyear] == 2018:\n",
    "        start_row = 26\n",
    "    else:\n",
    "        start_row = 29\n",
    "        \n",
    "    #Read the fraction of mine types for the given year\n",
    "    Ratios = pd.read_excel(EPA_abdcoal_inputfile,year_range_str[iyear],skiprows=start_row,nrows=5,usecols=np.arange(4))\n",
    "\n",
    "    fra_sealed  = np.array(Ratios['Sealed %'])\n",
    "    fra_venting = np.array(Ratios['Vented %'])\n",
    "    fra_flooded = np.array(Ratios['Flooded %'])\n",
    "\n",
    "    #Normalize to 100%\n",
    "    fra_summed = fra_sealed+fra_venting+fra_flooded\n",
    "    fra_sealed  = fra_sealed  / fra_summed\n",
    "    fra_venting = fra_venting / fra_summed\n",
    "    fra_flooded = fra_flooded / fra_summed\n",
    "    mine_count = 0\n",
    "    \n",
    "    for imine in np.arange(0,len(abdmines)):\n",
    "        ibasin = abdmines['Basin_nr'][imine]\n",
    "        ab_numyrs = abdmines['Days_closed_'+year_range_str[iyear]][imine]/year_days\n",
    "        ab_yea = float(abdmines['Date of Aban.'][imine][6:8])\n",
    "\n",
    "        if ab_numyrs >= 0:\n",
    "            if abdmines['Active Emiss. (mmcfd) '][imine] > 0:\n",
    "                #Deal with recovery projects\n",
    "                if abdmines['Recovering'][imine] == 1:\n",
    "                    abdmines.loc[imine,'Emis_mmcfd_'+year_range_str[iyear]] = 0.0\n",
    "                elif abdmines['Status'][imine] == 'Flooded':\n",
    "                    abdmines.loc[imine,'Emis_mmcfd_'+year_range_str[iyear]] = abdmines['Active Emiss. (mmcfd) '][imine] * \\\n",
    "                        np.exp(-1*D_flooded[ibasin]*ab_numyrs)\n",
    "                elif abdmines['Status'][imine] == 'Venting':\n",
    "                    abdmines.loc[imine,'Emis_mmcfd_'+year_range_str[iyear]] = abdmines['Active Emiss. (mmcfd) '][imine] * \\\n",
    "                        (1+b_medium[ibasin]*D_venting[ibasin]*ab_numyrs)**(-1/float(b_medium[ibasin]))\n",
    "                elif abdmines['Status'][imine] == 'Sealed':\n",
    "                    abdmines.loc[imine,'Emis_mmcfd_'+year_range_str[iyear]] = abdmines['Active Emiss. (mmcfd) '][imine] * \\\n",
    "                    (1-0.8) * (1+b_medium[ibasin]*D_sealed[ibasin]*ab_numyrs)**(-1/float(b_medium[ibasin]))\n",
    "                else:\n",
    "                    em_flo = abdmines.loc[imine,'Active Emiss. (mmcfd) '] * np.exp(-1*D_flooded[ibasin]*ab_numyrs)\n",
    "                    em_ven = abdmines.loc[imine,'Active Emiss. (mmcfd) '] * (1+b_medium[ibasin]*D_venting[ibasin]*ab_numyrs)**(-1/float(b_medium[ibasin]))\n",
    "                    em_sea = abdmines.loc[imine,'Active Emiss. (mmcfd) '] * (1-0.8) * (1+b_medium[ibasin]*D_sealed[ibasin]*ab_numyrs)**(-1/float(b_medium[ibasin]))\n",
    "                    abdmines.loc[imine,'Emis_mmcfd_'+year_range_str[iyear]] = fra_flooded[ibasin]*em_flo + fra_venting[ibasin]*em_ven + fra_sealed[ibasin]*em_sea\n",
    "                    \n",
    "                #Special treatment for mines that closed the same year\n",
    "                # Given that we are reporting annual emissions, the emissions from mines closed in the given year\n",
    "                # are scaled down to reflect that they were not emitting at the above calculated rate for the entire\n",
    "                # year, but only a fraction of the year\n",
    "                # annual emissions rate  = calculated flow rate * fraction of year closed\n",
    "                if year_range[iyear] == (2000 + ab_yea):\n",
    "                    mine_count +=1\n",
    "                    abdmines.loc[imine,'Emis_mmcfd_'+year_range_str[iyear]] = \\\n",
    "                        abdmines.loc[imine,'Emis_mmcfd_'+year_range_str[iyear]]*abdmines.loc[imine,'Fraction_year_closed_'+year_range_str[iyear]]\n",
    "            \n",
    "        #Remove active mine years [See block above]\n",
    "        #if abdmines['MSHA ID'][imine] == '4200079' and year_range[iyear] > 2015:\n",
    "        #    abdmines.loc[imine,'Emis_mmcfd_'+year_range_str[iyear]] = np.nan\n",
    "        #if abdmines['MSHA ID'][imine] == '1100588' and year_range[iyear] > 2014:\n",
    "        #    abdmines.loc[imine,'Emis_mmcfd_'+year_range_str[iyear]] = np.nan\n",
    "    \n",
    "    #Report number of mines that were closed during the current year\n",
    "    print('Mines closed in the current year:',mine_count,'of',len(abdmines))\n",
    "    # Set emission value by scaling against national total\n",
    "    #abdmines['Emis_tg_'+year_range_str[iyear]] = abdmines['Emis_mmcfd_'+year_range_str[iyear]]/float(np.sum(abdmines['Emis_mmcfd_'+year_range_str[iyear]]))*EPA_emi_abdcoal_total.iloc[0,iyear+1]  \n",
    "    \n",
    "    \n",
    "# Replace NaN with zero \n",
    "for iyear in np.arange(0, num_years):\n",
    "    abdmines['Emis_mmcfd_'+year_range_str[iyear]] = abdmines['Emis_mmcfd_'+year_range_str[iyear]].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.3. Place Mine-Level Emissions onto a 0.01x0.01 CONUS Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Allocate emissions to a 0.01x0.01 degree CONUS grid\n",
    "# Note that all emissions are from basins within the CONUS region, and therefore there are no 'non-grid' emissions\n",
    "\n",
    "map_mine_emis = np.zeros([len(lat001),len(lon001),num_years])\n",
    "map_mine_emis_nongrid = np.zeros([num_years])\n",
    "CM_Emissions = np.zeros([len(State_ANSI),len(County_ANSI),num_years])\n",
    "\n",
    "print('QA/QC: Number of missed mine locations (emissions allocated to the county-level)')\n",
    "for iyear in np.arange(0, num_years):\n",
    "    missed_locations = 0 \n",
    "    missed_emis = 0\n",
    "    for imine in np.arange(0,len(abdmines)):\n",
    "        ansi_state = abdmines['state'][imine]\n",
    "        ansi_county = abdmines['county'][imine]\n",
    "        \n",
    "        if abdmines['lat'][imine] > 0:\n",
    "            #Set ilon and ilat\n",
    "            ilat = int((abdmines['lat'][imine] - Lat_low)/Res_01)\n",
    "            ilon = int((abdmines['lon'][imine] - Lon_left)/Res_01)\n",
    "            \n",
    "        #Check is given location matches with state [Or if match is one grid box to either side cause we may be at the edges of states]\n",
    "            if np.sum(state_ANSI_map[ilat-1:ilat+2,ilon-1:ilon+2] == abdmines['state'][imine]) > 0:\n",
    "                map_mine_emis[ilat,ilon,iyear] += abdmines['Emis_mmcfd_'+year_range_str[iyear]][imine]# * 10**12 * Avagrado / float(Molarch4 * 366 * 24 * 60 * 60) / float(10000*are_map[i_lat,i_lon])\n",
    "            else:\n",
    "                # If the state isn't correct, allocate based on the county level because the lat/lon is probably way off\n",
    "                missed_locations += 1\n",
    "                CM_Emissions[ansi_state,ansi_county,iyear] += abdmines['Emis_mmcfd_'+year_range_str[iyear]][imine]\n",
    "                mask_county = np.ma.ones(np.shape(county_ANSI_map))\n",
    "                mask_county = np.ma.masked_where(county_ANSI_map != ansi_county, mask_county)\n",
    "                mask_county = np.ma.masked_where(state_ANSI_map != ansi_state, mask_county)\n",
    "                mask_county = np.ma.filled(mask_county,0)\n",
    "                # allocate the emissions evenly across all grid cells in county (e.g., mine emissions * area in grid cell in county/total county area)\n",
    "                map_mine_emis[:,:,iyear]+=((mask_county * area_map)/np.sum(mask_county * area_map))*abdmines['Emis_mmcfd_'+year_range_str[iyear]][imine]\n",
    "                missed_emis += abdmines['Emis_mmcfd_'+year_range_str[iyear]][imine]\n",
    "        else:\n",
    "            missed_locations +=1\n",
    "            CM_Emissions[ansi_state,ansi_county,iyear] += abdmines['Emis_mmcfd_'+year_range_str[iyear]][imine]\n",
    "            mask_county = np.ma.ones(np.shape(county_ANSI_map))\n",
    "            mask_county = np.ma.masked_where(county_ANSI_map != ansi_county, mask_county)\n",
    "            mask_county = np.ma.masked_where(state_ANSI_map != ansi_state, mask_county)\n",
    "            mask_county = np.ma.filled(mask_county,0)\n",
    "            # allocate the emissions evenly across all grid cells in county (e.g., mine emissions * area in grid cell in county/total county area)\n",
    "            map_mine_emis[:,:,iyear]+=((mask_county * area_map)/np.sum(mask_county * area_map))*abdmines['Emis_mmcfd_'+year_range_str[iyear]][imine]\n",
    "            missed_emis += abdmines['Emis_mmcfd_'+year_range_str[iyear]][imine]\n",
    "\n",
    "    print('Year', year_range[iyear],':', missed_locations)\n",
    "    print('Percent of emissions allocated to the county level:', missed_emis/np.sum(map_mine_emis[:,:,iyear]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "## Step 3. Read in and Format US EPA GHGI Emissions\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Read in Data from InvDB tab in the Inventory workbook (Tg == 1000 kt)\n",
    "\n",
    "names = pd.read_excel(EPA_abdcoal_inputfile, sheet_name = \"InvDB\", usecols = \"A:AJ\",skiprows = 15, header = 0)\n",
    "colnames = names.columns.values\n",
    "EPA_emi_abdcoal_CH4 = pd.read_excel(EPA_abdcoal_inputfile, sheet_name = \"InvDB\", usecols = \"A:AJ\", skiprows = 15, nrows = 2,names = colnames)\n",
    "EPA_emi_abdcoal_CH4 = EPA_emi_abdcoal_CH4.fillna('')\n",
    "EPA_emi_abdcoal_CH4 = EPA_emi_abdcoal_CH4.drop(columns = [n for n in range(1990, start_year,1)])\n",
    "EPA_emi_abdcoal_CH4 = EPA_emi_abdcoal_CH4.drop(columns = ['Sector','Source','State','Subsource','Fuel','GHG'])\n",
    "EPA_emi_abdcoal_CH4.rename(columns={'Subref':'Source'},inplace=True)\n",
    "EPA_emi_abdcoal_CH4.reset_index(inplace=True, drop=True)\n",
    "\n",
    "#calculate national total from state values\n",
    "temp = EPA_emi_abdcoal_CH4.sum(axis=0)\n",
    "EPA_emi_abdcoal_CH4 = EPA_emi_abdcoal_CH4.append(temp, ignore_index=True)\n",
    "EPA_emi_abdcoal_CH4.iloc[-1,0] = 'Total'\n",
    "EPA_emi_abdcoal_total = EPA_emi_abdcoal_CH4[EPA_emi_abdcoal_CH4['Source'] == 'Total']\n",
    "\n",
    "display(EPA_emi_abdcoal_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Split Emissions into Gridding Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#split GHG emissions into gridding groups, based on Coal Proxy Mapping file\n",
    "\n",
    "DEBUG =1\n",
    "start_year_idx = EPA_emi_abdcoal_CH4.columns.get_loc((start_year))\n",
    "end_year_idx = EPA_emi_abdcoal_CH4.columns.get_loc((end_year))+1\n",
    "ghgi_abdcoal_groups = ghgi_abdcoal_map['GHGI_Emi_Group'].unique()\n",
    "sum_emi = np.zeros([num_years])\n",
    "\n",
    "for igroup in np.arange(0,len(ghgi_abdcoal_groups)): #loop through all groups, finding the GHGI sources in that group and summing emissions for that region, year        vars()[ghgi_prod_groups[igroup]] = np.zeros([num_regions-1,num_years])\n",
    "    ##DEBUG## print(ghgi_stat_groups[igroup])\n",
    "    vars()[ghgi_abdcoal_groups[igroup]] = np.zeros([num_years])\n",
    "    source_temp = ghgi_abdcoal_map.loc[ghgi_abdcoal_map['GHGI_Emi_Group'] == ghgi_abdcoal_groups[igroup], 'GHGI_Source']\n",
    "    pattern_temp  = '|'.join(source_temp) \n",
    "    emi_temp =EPA_emi_abdcoal_CH4[EPA_emi_abdcoal_CH4['Source'].str.contains(pattern_temp)]\n",
    "    vars()[ghgi_abdcoal_groups[igroup]][:] = emi_temp.iloc[:,start_year_idx:].sum()\n",
    "        \n",
    "        \n",
    "#Check against total summary emissions \n",
    "print('QA/QC #1: Check Processing Emission Sum against GHGI Summary Emissions')\n",
    "for iyear in np.arange(0,num_years): \n",
    "    for igroup in np.arange(0,len(ghgi_abdcoal_groups)):\n",
    "        sum_emi[iyear] += vars()[ghgi_abdcoal_groups[igroup]][iyear]\n",
    "        \n",
    "    summary_emi = EPA_emi_abdcoal_total.iloc[0,iyear+1]  \n",
    "    #Check 1 - make sure that the sums from all the regions equal the totals reported\n",
    "    diff1 = abs(sum_emi[iyear] - summary_emi)/((sum_emi[iyear] + summary_emi)/2)\n",
    "    if DEBUG==1:\n",
    "        print(summary_emi)\n",
    "        print(sum_emi[iyear])\n",
    "    if diff1 < 0.0001:\n",
    "        print('Year ', year_range[iyear],': PASS, difference < 0.01%')\n",
    "    else:\n",
    "        print('Year ', year_range[iyear],': FAIL (check Production & summary tabs): ', diff1,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "## Step 4. Grid Data\n",
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4.1. Allocate emissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 4.1.1 Assign the Appropriate Proxy Variable Names (state & grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The names on the *left* need to match the 'AbandonedCoal_ProxyMapping' names \n",
    "# (these are initialized in Step 2). \n",
    "# The names on the *right* are the variable names used to caluclate the proxies in this code.\n",
    "# Names on the right need to match those from the code in Step 2\n",
    "\n",
    "#national --> grid proxies (0.01x0.01, year)\n",
    "Map_AbdCoal = map_mine_emis\n",
    "Map_AbdCoal_nongrid = map_mine_emis_nongrid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 4.1.2 Allocate emissions to the CONUS region (0.1x0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Allocate national emissions (Tg) onto a 0.1x0.1 grid using gridcell level 'Proxy_Groups'\n",
    "\n",
    "DEBUG =1\n",
    "#Define emission arrays\n",
    "Emissions_array_01 = np.zeros([len(Lat_01),len(Lon_01),num_years])\n",
    "Emissions_array_001 = np.zeros([len(lat001),len(lon001),num_years])\n",
    "Emissions_nongrid = np.zeros([num_years])\n",
    "\n",
    "# For each year, distribute natinal emissions onto a grid proxies specified in the Proxy_Mapping file\n",
    "\n",
    "print('**QA/QC Check: Sum of national gridded emissions vs. GHGI national emissions')\n",
    "for igroup in np.arange(len(proxy_abdcoal_map)):\n",
    "    vars()['Ext_'+proxy_abdcoal_map.loc[igroup,'GHGI_Emi_Group']] = np.zeros([len(Lat_01),len(Lon_01),num_years])\n",
    "\n",
    "\n",
    "for igroup in np.arange(0,len(proxy_abdcoal_map)):\n",
    "    proxy_temp = vars()[proxy_abdcoal_map.loc[igroup,'Proxy_Group']]\n",
    "    proxy_temp_nongrid = vars()[proxy_abdcoal_map.loc[igroup,'Proxy_Group']+'_nongrid']\n",
    "\n",
    "    for iyear in np.arange(0,num_years):\n",
    "        temp_sum = np.sum(vars()[proxy_abdcoal_map.loc[igroup,'Proxy_Group']][:,:,iyear])+np.sum(vars()[proxy_abdcoal_map.loc[igroup,'Proxy_Group']+'_nongrid'][iyear])\n",
    "        emi_temp = vars()[proxy_abdcoal_map.loc[igroup,'GHGI_Emi_Group']][iyear] * \\\n",
    "                       data_fn.safe_div(vars()[proxy_abdcoal_map.loc[igroup,'Proxy_Group']][:,:,iyear], temp_sum)\n",
    "        Emissions_array_001[:,:,iyear] += emi_temp\n",
    "        emi_temp_01 = data_fn.regrid001_to_01(emi_temp, Lat_01, Lon_01)\n",
    "        vars()['Ext_'+proxy_abdcoal_map.loc[igroup,'GHGI_Emi_Group']][:,:,iyear] = emi_temp_01\n",
    "        Emissions_nongrid[iyear] += vars()[proxy_abdcoal_map.loc[igroup,'GHGI_Emi_Group']][iyear] *\\\n",
    "                        data_fn.safe_div(vars()[proxy_abdcoal_map.loc[igroup,'Proxy_Group']+'_nongrid'][iyear], temp_sum)\n",
    "\n",
    "for iyear in np.arange(0, num_years):    \n",
    "    Emissions_array_01[:,:,iyear] = data_fn.regrid001_to_01(Emissions_array_001[:,:,iyear], Lat_01, Lon_01)\n",
    "    calc_emi = 0\n",
    "    for igroup in np.arange(0,len(proxy_abdcoal_map)):\n",
    "        calc_emi += np.sum(vars()['Ext_'+proxy_abdcoal_map.loc[igroup,'GHGI_Emi_Group']][:,:,iyear])\n",
    "    calc_emi += np.sum(Emissions_nongrid[iyear]) \n",
    "    #calc_emi = np.sum(Emissions_array_01[:,:,iyear]) + np.sum(Emissions_nongrid[iyear]) \n",
    "    summary_emi = EPA_emi_abdcoal_total.iloc[0,iyear+1]\n",
    "    emi_diff = abs(summary_emi-calc_emi)/((summary_emi+calc_emi)/2)\n",
    "    if DEBUG==1:\n",
    "        print(calc_emi)\n",
    "        print(summary_emi)\n",
    "    if abs(emi_diff) < 0.0001:\n",
    "        print('Year '+ year_range_str[iyear]+': Difference < 0.01%: PASS')\n",
    "    else: \n",
    "        print('Year '+ year_range_str[iyear]+': Difference > 0.01%: FAIL, diff: '+str(emi_diff))\n",
    "        \n",
    "ct = datetime.datetime.now() \n",
    "print(\"current time:\", ct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4.1.4 Save gridded emissions (kt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save gridded emissions for each gridding group - for extension\n",
    "\n",
    "#Initialize file\n",
    "data_IO_fn.initialize_netCDF(grid_emi_outputfile, netCDF_description, 0, year_range, loc_dimensions, Lat_01, Lon_01)\n",
    "\n",
    "unique_groups = np.unique(proxy_abdcoal_map['GHGI_Emi_Group'])\n",
    "unique_groups = unique_groups[unique_groups != 'Emi_not_mapped']\n",
    "\n",
    "nc_out = Dataset(grid_emi_outputfile, 'r+', format='NETCDF4')\n",
    "\n",
    "for igroup in np.arange(0,len(unique_groups)):\n",
    "    print('Ext_'+unique_groups[igroup])\n",
    "    if len(np.shape(vars()['Ext_'+unique_groups[igroup]])) ==4:\n",
    "        ghgi_temp = np.sum(vars()[unique_groups[igroup]],axis=3) #sum month data if data is monthly\n",
    "    else:\n",
    "        ghgi_temp = vars()['Ext_'+unique_groups[igroup]]\n",
    "\n",
    "    # Write data to netCDF\n",
    "    data_out = nc_out.createVariable('Ext_'+unique_groups[igroup], 'f8', ('lat', 'lon','year'), zlib=True)\n",
    "    data_out[:,:,:] = ghgi_temp[:,:,:]\n",
    "\n",
    "#save nongrid data to calculate non-grid fraction extension\n",
    "data_out = nc_out.createVariable('Emissions_nongrid', 'f8', ('year'), zlib=True)  \n",
    "data_out[:] = Emissions_nongrid[:]\n",
    "nc_out.close()\n",
    "\n",
    "#Confirm file location\n",
    "print('** SUCCESS **')\n",
    "print(\"Gridded emissions (kt) written to file: {}\" .format(os.getcwd())+grid_emi_outputfile)\n",
    "print(' ')\n",
    "\n",
    "del data_out, ghgi_temp, nc_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Calculate Gridded Emission Fluxes (molec./cm2/s) (0.1x0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert emissions to emission flux\n",
    "# conversion: Tg emissions to molec/cm2/s flux\n",
    "\n",
    "Flux_array_01_annual = np.zeros([len(Lat_01),len(Lon_01),num_years])\n",
    "print('**QA/QC Check: Sum of national gridded emissions vs. GHGI national emissions')\n",
    "  \n",
    "for iyear in np.arange(0,num_years):\n",
    "    calc_emi = 0\n",
    "    if year_range[iyear]==2012 or year_range[iyear]==2016:\n",
    "        year_days = np.sum(month_day_leap)\n",
    "    else:\n",
    "        year_days = np.sum(month_day_nonleap)\n",
    "\n",
    "    conversion_factor_01 = 10**12 * Avogadro / float(Molarch4 *year_days * 24 * 60 *60) / area_matrix_01\n",
    "    Flux_array_01_annual[:,:,iyear] = Emissions_array_01[:,:,iyear]*conversion_factor_01\n",
    "    #convert back to mass to check\n",
    "    conversion_factor_annual = 10**12 * Avogadro / float(Molarch4 *year_days * 24 * 60 *60) / area_matrix_01\n",
    "    calc_emi = np.sum(Flux_array_01_annual[:,:,iyear]/conversion_factor_annual)+np.sum(Emissions_nongrid[iyear])\n",
    "    summary_emi = EPA_emi_abdcoal_total.iloc[0,iyear+1]\n",
    "    emi_diff = abs(summary_emi-calc_emi)/((summary_emi+calc_emi)/2)\n",
    "    if DEBUG==1:\n",
    "        print(calc_emi)\n",
    "        print(summary_emi)\n",
    "    if abs(emi_diff) < 0.0001:\n",
    "        print('Year '+ year_range_str[iyear]+': Difference < 0.01%: PASS')\n",
    "    else: \n",
    "        print('Year '+ year_range_str[iyear]+': Difference > 0.01%: FAIL, diff: '+str(emi_diff))\n",
    "        \n",
    "Flux_Emissions_Total_annual = Flux_array_01_annual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "## Step 5. Write netCDF\n",
    "------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yearly data\n",
    "#Initialize file\n",
    "data_IO_fn.initialize_netCDF(gridded_outputfile, netCDF_description, 0, year_range, loc_dimensions, Lat_01, Lon_01)\n",
    "\n",
    "# Write data to netCDF\n",
    "nc_out = Dataset(gridded_outputfile, 'r+', format='NETCDF4')\n",
    "nc_out.variables['emi_ch4'][:,:,:] = Flux_Emissions_Total_annual\n",
    "nc_out.close()\n",
    "#Confirm file location\n",
    "print('** SUCCESS **')\n",
    "print(\"Gridded abandoned underground mine fluxes written to file: {}\" .format(os.getcwd())+gridded_outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "## Step 6. Plot Gridded Data\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6.1. Plot Annual Emission Fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plot Annual Data\n",
    "scale_max = 10\n",
    "save_flag = 0\n",
    "save_outfile = ''\n",
    "data_plot_fn.plot_annual_emission_flux_map(Flux_Emissions_Total_annual, Lat_01, Lon_01, year_range, title_str,scale_max,save_flag,save_outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6.2 Plot Difference between first and last inventory year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot difference between last and first year\n",
    "save_flag = 0\n",
    "save_outfile = ''\n",
    "data_plot_fn.plot_diff_emission_flux_map(Flux_Emissions_Total_annual, Lat_01, Lon_01, year_range, title_diff_str,save_flag,save_outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = datetime.datetime.now() \n",
    "ft = ct.timestamp() \n",
    "time_elapsed = (ft-it)/(60*60)\n",
    "print('Time to run: '+str(time_elapsed)+' hours')\n",
    "print('** GEPA_1B1a_Coal_Abandoned: COMPLETE **')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
