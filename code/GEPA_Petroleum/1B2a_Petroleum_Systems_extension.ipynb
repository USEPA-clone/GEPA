{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridded EPA Methane Inventory\n",
    "## Extension - GHGI 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### Authors: \n",
    "Erin E. McDuffie\n",
    "#### Date Last Updated: \n",
    "see Step 0\n",
    "#### Notebook Purpose: \n",
    "This Notebook extends and reports annual gridded (0.1°x0.1°) methane emission fluxes (molec./cm2/s) from Petroleum sources for the years 2012-2020, using updated inventory values from the 2022 National GHGI.  \n",
    "#### Summary & Notes:\n",
    "EPA annual national methane emissions are read in for the 2022 GHGI (either from the GHGI workbooks or public data). National emissions are then scaled down to CONUS emissions using the relative fraction of CONUS/total emissions from the v2 data (for each year, held constant after 2018). Remaining CONUS data are then allocated to proxy groups using the relevant proxy mapping files and allocated to the grid using the relative mass of emissions in each grid cell from each group from version 2 (for each year, held constant after 2018). Annual emission fluxes (molec./cm2/s) for 2012-2020 are then written to final netCDFs in the ‘/code/Final_Gridded_Data/Extension/v2_ext_final’ folder.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "## Step 0. Set-Up Notebook Modules, Functions, and Local Parameters and Constants\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirm working directory\n",
    "import os\n",
    "import time\n",
    "modtime = os.path.getmtime('./1B2a_Petroleum_Systems_extension.ipynb')\n",
    "modificationTime = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(modtime))\n",
    "print(\"This file was last modified on: \", modificationTime)\n",
    "print('')\n",
    "print(\"The directory we are working in is {}\" .format(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Include plots within notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import base modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import datetime\n",
    "from copy import copy\n",
    "\n",
    "# Import additional modules\n",
    "# Load plotting package Basemap \n",
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "# Load netCDF (for manipulating netCDF file types)\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "# Set up ticker\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "#add path for the global function module (file)\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../Global_Functions/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# Load Tabula (for reading tables from PDFs)\n",
    "import tabula as tb   \n",
    "    \n",
    "# Load user-defined global functions (modules)\n",
    "import data_load_functions as data_load_fn\n",
    "import data_functions as data_fn\n",
    "import data_IO_functions as data_IO_fn\n",
    "import data_plot_functions as data_plot_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INPUT Files\n",
    "# Assign global file names\n",
    "global_filenames = data_load_fn.load_global_file_names()\n",
    "State_ANSI_inputfile = global_filenames[0]\n",
    "County_ANSI_inputfile = global_filenames[1]\n",
    "pop_map_inputfile = global_filenames[2]\n",
    "Grid_area01_inputfile = global_filenames[3]\n",
    "Grid_area001_inputfile = global_filenames[4]\n",
    "Grid_state001_ansi_inputfile = global_filenames[5]\n",
    "Grid_county001_ansi_inputfile = global_filenames[6]\n",
    "globalinputlocation = global_filenames[0][0:20]\n",
    "print(globalinputlocation)\n",
    "\n",
    "# EPA Inventory Data\n",
    "EPA_Petr_inputfile = globalinputlocation+'GHGI/Ch3_Energy/PetroleumSystems_1990-2020_FINAL.xlsx'\n",
    "\n",
    "#proxy mapping file\n",
    "Petr_Mapping_inputfile = './InputData/Petroleum_ProxyMapping.xlsx'\n",
    "\n",
    "#OUTPUT FILES\n",
    "gridded_expl_outputfile = '../Final_Gridded_Data/Extension/v2_ext_final/EPA_v2_1B2a_Petroleum_Systems_Exploration.nc'\n",
    "netCDF_expl_description = 'EXTENSION to the Gridded EPA Inventory - Petroleum Systems Emissions - IPCC Source Category 1B2a - Exploration'\n",
    "title_expl_str = \"EPA methane emissions from exploration\"\n",
    "title_expl_diff_str = \"Emissions from exploration difference: 2020-2012\"\n",
    "\n",
    "gridded_prod_outputfile = '../Final_Gridded_Data/Extension/v2_ext_final/EPA_v2_1B2a_Petroleum_Systems_Production.nc'\n",
    "netCDF_prod_description = 'EXTENSION to the Gridded EPA Inventory - Petroleum Systems Emissions - IPCC Source Category 1B2a - Production'\n",
    "title_prod_str = \"EPA methane emissions from production\"\n",
    "title_prod_diff_str = \"Emissions from production difference: 2020-2012\"\n",
    "\n",
    "gridded_trans_outputfile = '../Final_Gridded_Data/Extension/v2_ext_final/EPA_v2_1B2a_Petroleum_Systems_Transport.nc'\n",
    "netCDF_trans_description = 'EXTENSION to the Gridded EPA Inventory - Petroleum Systems Emissions - IPCC Source Category 1B2a - Oil Transport'\n",
    "title_trans_str = \"EPA methane emissions from transport\"\n",
    "title_trans_diff_str = \"Emissions from gas transport: 2020-2012\"\n",
    "\n",
    "gridded_ref_outputfile = '../Final_Gridded_Data/Extension/v2_ext_final/EPA_v2_1B2a_Petroleum_Systems_Refining.nc'\n",
    "netCDF_ref_description = 'EXTENSION to the Gridded EPA Inventory - Petroleum Systems Emissions - IPCC Source Category 1B2a - Refining'\n",
    "title_ref_str = \"EPA methane emissions from refining\"\n",
    "title_ref_diff_str = \"Emissions from refining difference: 2020-2012\"\n",
    "\n",
    "#output gridded proxy data\n",
    "grid_emi_inputfile = '../Final_Gridded_Data/Extension/v2_input_data/Petroleum_Grid_Emi.nc'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define local variables\n",
    "start_year = 2012  #First year in emission timeseries\n",
    "end_year = 2018    #Last year in emission timeseries\n",
    "ext_year = 2020    #last year in extended dataset\n",
    "end_year_idx = 2018-2012 #index of the year 2018\n",
    "year_range = [*range(start_year, ext_year+1,1)] #List of emission years\n",
    "year_range_str=[str(i) for i in year_range]\n",
    "num_years = len(year_range)\n",
    "\n",
    "# Define constants\n",
    "Avogadro   = 6.02214129 * 10**(23)  #molecules/mol\n",
    "Molarch4   = 16.04                  #g/mol\n",
    "Res01      = 0.1                    # degrees\n",
    "Res_01     = 0.01\n",
    "tg_scale   = 0.001                  #Tg scale number [New file allows for the exclusion of the territories] \n",
    "\n",
    "# Continental US Lat/Lon Limits (for netCDF files)\n",
    "Lon_left = -130       #deg\n",
    "Lon_right = -60       #deg\n",
    "Lat_low  = 20         #deg\n",
    "Lat_up  = 55          #deg\n",
    "loc_dimensions = [Lat_low, Lat_up, Lon_left, Lon_right]\n",
    "\n",
    "ilat_start = int((90+Lat_low)/Res01) #1100:1450 (continental US range)\n",
    "ilat_end = int((90+Lat_up)/Res01)\n",
    "ilon_start = abs(int((-180-Lon_left)/Res01)) #500:1200 (continental US range)\n",
    "ilon_end = abs(int((-180-Lon_right)/Res01))\n",
    "\n",
    "# Number of days in each month\n",
    "month_day_leap  = [  31,  29,  31,  30,  31,  30,  31,  31,  30,  31,  30,  31]\n",
    "month_day_nonleap = [  31,  28,  31,  30,  31,  30,  31,  31,  30,  31,  30,  31]\n",
    "\n",
    "# Month arrays\n",
    "month_range_str = ['January','February','March','April','May','June','July','August','September','October','November','December']\n",
    "num_months = len(month_range_str)\n",
    "\n",
    "area_map, lat001, lon001 = data_load_fn.load_area_map_001(Grid_area001_inputfile)\n",
    "area_map01, Lat01, Lon01 = data_load_fn.load_area_map_01(Grid_area01_inputfile)[0:3]\n",
    "#Select relevant Continental 0.1 x0.1 domain\n",
    "Lat_01 = Lat01[ilat_start:ilat_end]\n",
    "Lon_01 = Lon01[ilon_start:ilon_end]\n",
    "area_matrix_01 = data_fn.regrid001_to_01(area_map, Lat_01, Lon_01)\n",
    "area_matrix_01 *= 10000  #convert from m2 to cm2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.auto_scroll_threshold = 9999;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track run time\n",
    "ct = datetime.datetime.now() \n",
    "it = ct.timestamp() \n",
    "print(\"current time:\", ct) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#General Approach\n",
    "1. Specify Input Files\n",
    "    a. 2022 GHGI\n",
    "    b. Proxy Mapping\n",
    "    c. gridded group emissions\n",
    "2. Read in v2 gridded emission groups\n",
    "3. Calculate CONUS fraction\n",
    "4. Read in 2022 GHGI Data\n",
    "6. Split national data into gridding groups (may need to adjust if source names have changed)\n",
    "7. For each gridding group, multiply by map of relative emissions - and scale by CONUS fractions\n",
    "8. Convert to flux\n",
    "9. Save new extension data\n",
    "10. Plot new extension data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Read in Gridding Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "names = pd.read_excel(Petr_Mapping_inputfile, sheet_name = \"GHGI Map - E&P\", usecols = \"A:B\",skiprows = 1, header = 0)\n",
    "colnames = names.columns.values\n",
    "ghgi_prod_map = pd.read_excel(Petr_Mapping_inputfile, sheet_name = \"GHGI Map - E&P\", usecols = \"A:B\", skiprows = 2, names = colnames)\n",
    "#drop rows with no data, remove the parentheses and \"\"\n",
    "ghgi_prod_map = ghgi_prod_map[ghgi_prod_map['GHGI_Emi_Group'] != 'na']\n",
    "ghgi_prod_map = ghgi_prod_map[ghgi_prod_map['GHGI_Emi_Group'].notna()]\n",
    "ghgi_prod_map['GHGI_Source']= ghgi_prod_map['GHGI_Source'].str.replace(r\"\\(\",\"- \")\n",
    "ghgi_prod_map['GHGI_Source']= ghgi_prod_map['GHGI_Source'].str.replace(r\"\\)\",\"\")\n",
    "ghgi_prod_map['GHGI_Source']= ghgi_prod_map['GHGI_Source'].str.replace(r'\"',\"\")\n",
    "ghgi_prod_map.reset_index(inplace=True, drop=True)\n",
    "display(ghgi_prod_map)\n",
    "\n",
    "#load emission group - proxy map\n",
    "names = pd.read_excel(Petr_Mapping_inputfile, sheet_name = \"Proxy Map - E&P\", usecols = \"A:C\",skiprows = 1, header = 0)\n",
    "colnames = names.columns.values\n",
    "proxy_prod_map = pd.read_excel(Petr_Mapping_inputfile, sheet_name = \"Proxy Map - E&P\", usecols = \"A:C\", skiprows = 1, names = colnames)\n",
    "display((proxy_prod_map))\n",
    "\n",
    "        \n",
    "#Transport\n",
    "#load GHGI Mapping Groups\n",
    "names = pd.read_excel(Petr_Mapping_inputfile, sheet_name = \"GHGI Map - Trans\", usecols = \"A:B\",skiprows = 1, header = 0)\n",
    "colnames = names.columns.values\n",
    "ghgi_trans_map = pd.read_excel(Petr_Mapping_inputfile, sheet_name = \"GHGI Map - Trans\", usecols = \"A:B\", skiprows = 2, names = colnames)\n",
    "#drop rows with no data, remove the parentheses and \"\"\n",
    "ghgi_trans_map = ghgi_trans_map[ghgi_trans_map['GHGI_Emi_Group'] != 'na']\n",
    "ghgi_trans_map = ghgi_trans_map[ghgi_trans_map['GHGI_Emi_Group'].notna()]\n",
    "ghgi_trans_map['GHGI_Source']= ghgi_trans_map['GHGI_Source'].str.replace(r\"\\(\",\"- \")\n",
    "ghgi_trans_map['GHGI_Source']= ghgi_trans_map['GHGI_Source'].str.replace(r\"\\)\",\"\")\n",
    "ghgi_trans_map['GHGI_Source']= ghgi_trans_map['GHGI_Source'].str.replace(r'\"',\"\")\n",
    "ghgi_trans_map.reset_index(inplace=True, drop=True)\n",
    "display(ghgi_prod_map)\n",
    "\n",
    "#load emission group - proxy map\n",
    "names = pd.read_excel(Petr_Mapping_inputfile, sheet_name = \"Proxy Map - Trans\", usecols = \"A:C\",skiprows = 1, header = 0)\n",
    "colnames = names.columns.values\n",
    "proxy_trans_map = pd.read_excel(Petr_Mapping_inputfile, sheet_name = \"Proxy Map - Trans\", usecols = \"A:C\", skiprows = 1, names = colnames)\n",
    "display((proxy_prod_map))\n",
    "\n",
    "        \n",
    "#Refining\n",
    "#load GHGI Mapping Groups\n",
    "names = pd.read_excel(Petr_Mapping_inputfile, sheet_name = \"GHGI Map - Ref\", usecols = \"A:B\",skiprows = 1, header = 0)\n",
    "colnames = names.columns.values\n",
    "ghgi_ref_map = pd.read_excel(Petr_Mapping_inputfile, sheet_name = \"GHGI Map - Ref\", usecols = \"A:B\", skiprows = 2, names = colnames)\n",
    "#drop rows with no data, remove the parentheses and \"\"\n",
    "ghgi_ref_map = ghgi_ref_map[ghgi_ref_map['GHGI_Emi_Group'] != 'na']\n",
    "ghgi_ref_map = ghgi_ref_map[ghgi_ref_map['GHGI_Emi_Group'].notna()]\n",
    "ghgi_ref_map['GHGI_Source']= ghgi_ref_map['GHGI_Source'].str.replace(r\"\\(\",\"- \")\n",
    "ghgi_ref_map['GHGI_Source']= ghgi_ref_map['GHGI_Source'].str.replace(r\"\\)\",\"\")\n",
    "ghgi_ref_map['GHGI_Source']= ghgi_ref_map['GHGI_Source'].str.replace(r'\"',\"\")\n",
    "ghgi_ref_map.reset_index(inplace=True, drop=True)\n",
    "display(ghgi_prod_map)\n",
    "\n",
    "#load emission group - proxy map\n",
    "names = pd.read_excel(Petr_Mapping_inputfile, sheet_name = \"Proxy Map - Ref\", usecols = \"A:C\",skiprows = 1, header = 0)\n",
    "colnames = names.columns.values\n",
    "proxy_ref_map = pd.read_excel(Petr_Mapping_inputfile, sheet_name = \"Proxy Map - Ref\", usecols = \"A:C\", skiprows = 1, names = colnames)\n",
    "display((proxy_prod_map))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "## Step 2. Read in v2 Grid Group Emissions\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#These data will be assigned to 'proxy_+ghgi_emi_name' (because original proxy mapping is not 1:1 with GHGI group)\n",
    "#All proxy data will be in 0.1x0.1xyear dimensions\n",
    "#asign 2018 values to years 2019 ad 2020\n",
    "\n",
    "nc_in = Dataset(grid_emi_inputfile, 'r', format='NETCDF4')\n",
    "Emissions_expl_nongrid = np.zeros([num_years])\n",
    "Emissions_prod_nongrid = np.zeros([num_years])\n",
    "Emissions_trans_nongrid = np.zeros([num_years])\n",
    "Emissions_ref_nongrid = np.zeros([num_years])\n",
    "\n",
    "unique_groups2 = (np.unique(proxy_prod_map['GHGI_Emi_Group']))\n",
    "unique_groups2 = list(unique_groups2[unique_groups2 != 'Emi_not_mapped'])\n",
    "unique_groups3 = list(np.unique(proxy_trans_map['GHGI_Emi_Group']))\n",
    "unique_groups4 = list(np.unique(proxy_ref_map['GHGI_Emi_Group']))\n",
    "unique_groups = unique_groups2+unique_groups3+unique_groups4\n",
    "print(unique_groups2)\n",
    "\n",
    "for igroup in np.arange(0,len(proxy_prod_map)):\n",
    "    if proxy_prod_map.loc[igroup,'GHGI_Emi_Group'] == 'Emi_not_mapped':\n",
    "        continue\n",
    "    else:\n",
    "        vars()['Proxy_'+proxy_prod_map.loc[igroup,'GHGI_Emi_Group']] = np.zeros([len(Lat_01),len(Lon_01),num_years])\n",
    "        temp = nc_in['Ext_'+proxy_prod_map['GHGI_Emi_Group'][igroup]][:,:,:]\n",
    "        for iyear in np.arange(0,num_years):\n",
    "            if year_range[iyear] <= end_year:\n",
    "                vars()['Proxy_'+proxy_prod_map.loc[igroup,'GHGI_Emi_Group']][:,:,iyear] = temp[:,:,iyear]\n",
    "            else:\n",
    "                vars()['Proxy_'+proxy_prod_map.loc[igroup,'GHGI_Emi_Group']][:,:,iyear] = temp[:,:,end_year_idx]\n",
    "            \n",
    "for igroup in np.arange(0,len(proxy_trans_map)):\n",
    "    vars()['Proxy_'+proxy_trans_map.loc[igroup,'GHGI_Emi_Group']] = np.zeros([len(Lat_01),len(Lon_01),num_years])\n",
    "    temp = nc_in['Ext_'+proxy_trans_map['GHGI_Emi_Group'][igroup]][:,:,:]\n",
    "    for iyear in np.arange(0,num_years):\n",
    "        if year_range[iyear] <= end_year:\n",
    "            vars()['Proxy_'+proxy_trans_map.loc[igroup,'GHGI_Emi_Group']][:,:,iyear] = temp[:,:,iyear]\n",
    "        else:\n",
    "            #print('here')\n",
    "            vars()['Proxy_'+proxy_trans_map.loc[igroup,'GHGI_Emi_Group']][:,:,iyear] = temp[:,:,end_year_idx]\n",
    "\n",
    "for igroup in np.arange(0,len(proxy_ref_map)):\n",
    "    vars()['Proxy_'+proxy_ref_map.loc[igroup,'GHGI_Emi_Group']] = np.zeros([len(Lat_01),len(Lon_01),num_years])\n",
    "    temp = nc_in['Ext_'+proxy_ref_map['GHGI_Emi_Group'][igroup]][:,:,:]\n",
    "    for iyear in np.arange(0,num_years):\n",
    "        if year_range[iyear] <= end_year:\n",
    "            vars()['Proxy_'+proxy_ref_map.loc[igroup,'GHGI_Emi_Group']][:,:,iyear] = temp[:,:,iyear]\n",
    "        else:\n",
    "            #print('here')\n",
    "            vars()['Proxy_'+proxy_ref_map.loc[igroup,'GHGI_Emi_Group']][:,:,iyear] = temp[:,:,end_year_idx]\n",
    "\n",
    "\n",
    "#assign 2018 values to years 2019 and 2020\n",
    "for iyear in np.arange(0,num_years):\n",
    "    if year_range[iyear] <= end_year:\n",
    "        Emissions_expl_nongrid[iyear] = nc_in['Emissions_expl_nongrid'][iyear]\n",
    "        Emissions_prod_nongrid[iyear] = nc_in['Emissions_prod_nongrid'][iyear]\n",
    "        Emissions_trans_nongrid[iyear] = nc_in['Emissions_trans_nongrid'][iyear]\n",
    "        Emissions_ref_nongrid[iyear] = nc_in['Emissions_ref_nongrid'][iyear]\n",
    "    else:\n",
    "        #print('here')\n",
    "        Emissions_expl_nongrid[iyear] = nc_in['Emissions_expl_nongrid'][end_year_idx]\n",
    "        Emissions_prod_nongrid[iyear] = nc_in['Emissions_prod_nongrid'][end_year_idx]\n",
    "        Emissions_trans_nongrid[iyear] = nc_in['Emissions_trans_nongrid'][end_year_idx]\n",
    "        Emissions_ref_nongrid[iyear] = nc_in['Emissions_ref_nongrid'][end_year_idx]\n",
    "\n",
    "CONUS_frac_expl = np.zeros([num_years])\n",
    "CONUS_frac_prod = np.zeros([num_years])\n",
    "CONUS_frac_trans = np.zeros([num_years])\n",
    "CONUS_frac_ref = np.zeros([num_years])\n",
    "\n",
    "for iyear in np.arange(0, num_years):\n",
    "    sum_emi = 0\n",
    "    sum_emi1 = 0\n",
    "    sum_emi2 = 0\n",
    "    sum_emi3 = 0\n",
    "    for igroup in np.arange(0,len(proxy_prod_map)):\n",
    "        if proxy_prod_map.loc[igroup,'GHGI_Emi_Group'] == 'Emi_not_mapped':\n",
    "            continue\n",
    "        else:\n",
    "            if proxy_prod_map.loc[igroup,'GHGI_Emi_Group'] == 'Emi_OilWellExp' or \\\n",
    "                proxy_prod_map.loc[igroup,'GHGI_Emi_Group'] == 'Emi_ConvCompExp' or \\\n",
    "                proxy_prod_map.loc[igroup,'GHGI_Emi_Group'] == 'Emi_HFCompExp' or \\\n",
    "                proxy_prod_map.loc[igroup,'GHGI_Emi_Group'] == 'Emi_OilWellDrilledExp':\n",
    "                sum_emi += np.sum( vars()['Proxy_'+proxy_prod_map.loc[igroup,'GHGI_Emi_Group']][:,:,iyear])\n",
    "            else:\n",
    "                sum_emi1 += np.sum( vars()['Proxy_'+proxy_prod_map.loc[igroup,'GHGI_Emi_Group']][:,:,iyear])\n",
    "    for igroup in np.arange(0,len(proxy_trans_map)):\n",
    "        sum_emi2 += np.sum( vars()['Proxy_'+proxy_trans_map.loc[igroup,'GHGI_Emi_Group']][:,:,iyear])\n",
    "    for igroup in np.arange(0,len(proxy_ref_map)):\n",
    "        sum_emi3 += np.sum( vars()['Proxy_'+proxy_ref_map.loc[igroup,'GHGI_Emi_Group']][:,:,iyear])\n",
    "    CONUS_frac_expl[iyear] = Emissions_expl_nongrid[iyear]/sum_emi\n",
    "    CONUS_frac_prod[iyear] = Emissions_prod_nongrid[iyear]/sum_emi1\n",
    "    CONUS_frac_trans[iyear] = Emissions_trans_nongrid[iyear]/sum_emi2\n",
    "    CONUS_frac_ref[iyear] = Emissions_ref_nongrid[iyear]/sum_emi3\n",
    "\n",
    "print(CONUS_frac_expl)    \n",
    "print(CONUS_frac_prod)\n",
    "print(CONUS_frac_trans)\n",
    "print(CONUS_frac_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "## Step 3. Read in and Format 2022 US EPA GHGI Emissions\n",
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.1. Production and Exploration Emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Emissions are in units of MG (= 1x10-6 Tg, 1e-3 kt)\n",
    "# Emissions on this tab account for reductions\n",
    "\n",
    "names = pd.read_excel(EPA_Petr_inputfile, sheet_name = \"Production_CH4 (MT)\", usecols = \"A:AG\", skiprows = 3, header = 0, nrows = 1)\n",
    "colnames = names.columns.values\n",
    "EPA_emi_prod_Petr = pd.read_excel(EPA_Petr_inputfile, sheet_name = \"Production_CH4 (MT)\", usecols = \"A:AG\", skiprows = 5, names = colnames, nrows = 125)\n",
    "EPA_emi_prod_Petr= EPA_emi_prod_Petr.drop(columns = ['Emission\\nSource No.'])\n",
    "EPA_emi_prod_Petr.rename(columns={EPA_emi_prod_Petr.columns[0]:'Source'}, inplace=True)\n",
    "EPA_emi_prod_Petr['Source']= EPA_emi_prod_Petr['Source'].str.replace(r\"\\(\",\"- \")\n",
    "EPA_emi_prod_Petr['Source']= EPA_emi_prod_Petr['Source'].str.replace(r\"\\)\",\"\")\n",
    "EPA_emi_prod_Petr['Source']= EPA_emi_prod_Petr['Source'].str.replace(r'\"',\"\")\n",
    "EPA_emi_prod_Petr = EPA_emi_prod_Petr.fillna('')\n",
    "EPA_emi_prod_Petr = EPA_emi_prod_Petr.drop(columns = [*range(1990, start_year,1)])\n",
    "EPA_emi_prod_Petr.reset_index(inplace=True, drop=True)\n",
    "display(EPA_emi_prod_Petr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.2. Read in Petroleum Transport "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emissions are in units of MT (= 1x10-6 Tg)\n",
    "\n",
    "names = pd.read_excel(EPA_Petr_inputfile, sheet_name = \"Transportation Emissions\", usecols = \"A:AI\", skiprows = 32, header = 0, nrows = 1)\n",
    "colnames = names.columns.values\n",
    "EPA_emi_trans_Petr = pd.read_excel(EPA_Petr_inputfile, sheet_name = \"Transportation Emissions\", usecols = \"A:AI\", skiprows = 34, names = colnames, nrows = 18)\n",
    "EPA_emi_trans_Petr= EPA_emi_trans_Petr.drop(columns = ['Emission\\nSource No.', 'Unnamed: 2', 'Emission Units'])\n",
    "EPA_emi_trans_Petr.rename(columns={EPA_emi_trans_Petr.columns[0]:'Source'}, inplace=True)\n",
    "EPA_emi_trans_Petr = EPA_emi_trans_Petr.fillna('')\n",
    "EPA_emi_trans_Petr = EPA_emi_trans_Petr.drop(columns = [*range(1990, start_year,1)])\n",
    "EPA_emi_trans_Petr.reset_index(inplace=True, drop=True)\n",
    "display(EPA_emi_trans_Petr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.3. Read in Petroleum Refining "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emissions are in units of MT (= 1x10-6 Tg)\n",
    "\n",
    "names = pd.read_excel(EPA_Petr_inputfile, sheet_name = \"Refinery Emissions\", usecols = \"A:AI\", skiprows = 7, header = 0, nrows = 1)\n",
    "colnames = names.columns.values\n",
    "EPA_emi_ref_Petr = pd.read_excel(EPA_Petr_inputfile, sheet_name = \"Refinery Emissions\", usecols = \"A:AI\", skiprows = 8, names = colnames, nrows = 25)\n",
    "EPA_emi_ref_Petr= EPA_emi_ref_Petr.drop(columns = ['Emission\\nSource No.', 'Scaling Factor for 1990-2009 ','Units'])\n",
    "EPA_emi_ref_Petr.rename(columns={EPA_emi_ref_Petr.columns[0]:'Source'}, inplace=True)\n",
    "EPA_emi_ref_Petr = EPA_emi_ref_Petr.fillna('')\n",
    "EPA_emi_ref_Petr = EPA_emi_ref_Petr.drop(columns = [*range(1990, start_year,1)])\n",
    "EPA_emi_ref_Petr.reset_index(inplace=True, drop=True)\n",
    "display(EPA_emi_ref_Petr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.4. Read in Total Petroleum Emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in total production + exploration emissions (with methane reductions accounted for)\n",
    "# data are in kt\n",
    "\n",
    "names = pd.read_excel(EPA_Petr_inputfile, sheet_name = \"CH4 Summary\", usecols = \"A:AF\", skiprows = 4, header = 0, nrows = 1)\n",
    "colnames = names.columns.values\n",
    "EPA_emi_total_Petr = pd.read_excel(EPA_Petr_inputfile, sheet_name = \"CH4 Summary\", usecols = \"A:AF\", skiprows = 19, names = colnames, nrows = 5)\n",
    "EPA_emi_total_Petr.rename(columns={EPA_emi_total_Petr.columns[0]:'Source'}, inplace=True)\n",
    "EPA_emi_total_Petr = EPA_emi_total_Petr.drop(columns = [*range(1990, start_year,1)])\n",
    "EPA_emi_total_Petr.reset_index(inplace=True, drop=True)\n",
    "display(EPA_emi_total_Petr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Split Emissions into Gridding Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_year_idx = EPA_emi_prod_Petr.columns.get_loc(start_year)\n",
    "stop_year_idx = EPA_emi_prod_Petr.columns.get_loc(end_year)+1\n",
    "ghgi_prod_groups = ghgi_prod_map['GHGI_Emi_Group'].unique()\n",
    "ghgi_trans_groups = ghgi_trans_map['GHGI_Emi_Group'].unique()\n",
    "ghgi_ref_groups = ghgi_ref_map['GHGI_Emi_Group'].unique()\n",
    "\n",
    "\n",
    "for igroup in np.arange(0,len(ghgi_prod_groups)):\n",
    "    vars()[ghgi_prod_groups[igroup]] = np.zeros(num_years)\n",
    "    source_temp = ghgi_prod_map.loc[ghgi_prod_map['GHGI_Emi_Group'] == ghgi_prod_groups[igroup], 'GHGI_Source']\n",
    "    pattern_temp  = '|'.join(source_temp) \n",
    "    if ghgi_prod_groups[igroup] =='Emi_OilWellProd':\n",
    "        pattern_temp += '|Produced Water - Regular Pressure Wells|Produced Water - Low Pressure Wells'\n",
    "    emi_temp = EPA_emi_prod_Petr[EPA_emi_prod_Petr['Source'].str.contains(pattern_temp)]\n",
    "    vars()[ghgi_prod_groups[igroup]][:] = np.where(emi_temp.iloc[:,start_year_idx:] =='',[0],emi_temp.iloc[:,start_year_idx:]).sum(axis=0)/float(1000)\n",
    "    \n",
    "for igroup in np.arange(0,len(ghgi_trans_groups)):\n",
    "    vars()[ghgi_trans_groups[igroup]] = np.zeros(num_years)\n",
    "    source_temp = ghgi_trans_map.loc[ghgi_trans_map['GHGI_Emi_Group'] == ghgi_trans_groups[igroup], 'GHGI_Source']\n",
    "    pattern_temp  = '|'.join(source_temp) \n",
    "    emi_temp = EPA_emi_trans_Petr[EPA_emi_trans_Petr['Source'].str.contains(pattern_temp)]\n",
    "    vars()[ghgi_trans_groups[igroup]][:] = np.where(emi_temp.iloc[:,start_year_idx:] =='',[0],emi_temp.iloc[:,start_year_idx:]).sum(axis=0)/float(1000)\n",
    "    \n",
    "for igroup in np.arange(0,len(ghgi_ref_groups)):\n",
    "    vars()[ghgi_ref_groups[igroup]] = np.zeros(num_years)\n",
    "    source_temp = ghgi_ref_map.loc[ghgi_ref_map['GHGI_Emi_Group'] == ghgi_ref_groups[igroup], 'GHGI_Source']\n",
    "    pattern_temp  = '|'.join(source_temp) \n",
    "    emi_temp = EPA_emi_ref_Petr[EPA_emi_ref_Petr['Source'].str.contains(pattern_temp)] \n",
    "    vars()[ghgi_ref_groups[igroup]][:] = np.where(emi_temp.iloc[:,start_year_idx:] =='',[0],emi_temp.iloc[:,start_year_idx:]).sum(axis=0)/float(1000)\n",
    "\n",
    "    \n",
    "print('QA/QC: Check Production, Transport, Refining Emission Sum against GHGI Summary Emissions')\n",
    "for iyear in np.arange(0,num_years): \n",
    "    sum_emi = 0\n",
    "    for igroup in np.arange(0,len(ghgi_prod_groups)):\n",
    "        sum_emi += vars()[ghgi_prod_groups[igroup]][iyear]\n",
    "    for igroup in np.arange(0,len(ghgi_trans_groups)):\n",
    "        sum_emi += vars()[ghgi_trans_groups[igroup]][iyear]\n",
    "    for igroup in np.arange(0,len(ghgi_ref_groups)):\n",
    "        sum_emi += vars()[ghgi_ref_groups[igroup]][iyear]\n",
    "        \n",
    "    summary_emi = EPA_emi_total_Petr.iloc[0,iyear+1]+EPA_emi_total_Petr.iloc[1,iyear+1] +EPA_emi_total_Petr.iloc[2,iyear+1]+\\\n",
    "                    EPA_emi_total_Petr.iloc[3,iyear+1]\n",
    "    #Check 1 - make sure that the sums from all the regions equal the totals reported\n",
    "    diff1 = abs(sum_emi - summary_emi)/((sum_emi + summary_emi)/2)\n",
    "    print(summary_emi)\n",
    "    print(sum_emi)\n",
    "    if diff1 < 0.0001:\n",
    "        print('Year ', year_range[iyear],': PASS, difference < 0.01%')\n",
    "    else:\n",
    "        print('Year ', year_range[iyear],': FAIL (check Production & summary tabs): ', diff1,'%') \n",
    "        \n",
    "## Note: The numbers will not be exactly the same do to conversions and rounding in the Transport sector (between the \n",
    "## Transportation Emissions tab and the CH4 summary tab). This is not an error, just a difference. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "## Step 4. Grid Data\n",
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 4.1 Allocate emissions to the CONUS region (0.1x0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Allocate national emissions (Tg) onto a 0.1x0.1 grid using gridcell level 'Proxy_Groups'\n",
    "\n",
    "DEBUG =1\n",
    "#Define emission arrays\n",
    "Emissions_array_01_expl = np.zeros([len(Lat_01),len(Lon_01),num_years])\n",
    "Emissions_array_01_prod = np.zeros([len(Lat_01),len(Lon_01),num_years])\n",
    "Emissions_array_01_trans = np.zeros([len(Lat_01),len(Lon_01),num_years])\n",
    "Emissions_array_01_ref = np.zeros([len(Lat_01),len(Lon_01),num_years])\n",
    "Emissions_nongrid = np.zeros([num_years])\n",
    "\n",
    "# For each year, distribute natinal emissions onto a grid proxies specified in the Proxy_Mapping file\n",
    "\n",
    "print('**QA/QC Check: Sum of national gridded emissions vs. GHGI national emissions')\n",
    "\n",
    "for igroup in np.arange(0,len(proxy_prod_map)):\n",
    "    if proxy_prod_map.loc[igroup,'GHGI_Emi_Group'] != 'Emi_not_mapped':\n",
    "        proxy_temp = vars()['Proxy_'+proxy_prod_map.loc[igroup,'GHGI_Emi_Group']][:,:,:]\n",
    "        for iyear in np.arange(0,num_years):\n",
    "            proxy_frac = data_fn.safe_div(proxy_temp[:,:,iyear], np.sum(proxy_temp[:,:,iyear]))\n",
    "            if proxy_prod_map.loc[igroup,'GHGI_Emi_Group'] == 'Emi_OilWellExp' or \\\n",
    "                            proxy_prod_map.loc[igroup,'GHGI_Emi_Group'] == 'Emi_ConvCompExp' or \\\n",
    "                            proxy_prod_map.loc[igroup,'GHGI_Emi_Group'] == 'Emi_HFCompExp' or \\\n",
    "                            proxy_prod_map.loc[igroup,'GHGI_Emi_Group'] == 'Emi_OilWellDrilledExp': \n",
    "                ghgi_temp = vars()[proxy_prod_map.loc[igroup,'GHGI_Emi_Group']][iyear] * (1-CONUS_frac_expl[iyear])\n",
    "                if np.sum(proxy_frac)==0 and ghgi_temp ==0:\n",
    "                    Emissions_array_01_prod[:,:,iyear] += ghgi_temp * 0\n",
    "                else:\n",
    "                    Emissions_array_01_expl[:,:,iyear] += ghgi_temp * proxy_frac[:,:]\n",
    "            else:\n",
    "                ghgi_temp = vars()[proxy_prod_map.loc[igroup,'GHGI_Emi_Group']][iyear] * (1-CONUS_frac_prod[iyear])\n",
    "                if np.sum(proxy_frac)==0 and ghgi_temp ==0:\n",
    "                    Emissions_array_01_prod[:,:,iyear] += ghgi_temp * 0\n",
    "                else:\n",
    "                    Emissions_array_01_prod[:,:,iyear] += ghgi_temp * proxy_frac[:,:]\n",
    "            Emissions_nongrid[iyear] += vars()[proxy_prod_map.loc[igroup,'GHGI_Emi_Group']][iyear] - ghgi_temp\n",
    "    else:\n",
    "        for iyear in np.arange(0,num_years):\n",
    "            Emissions_nongrid[iyear] += vars()[proxy_prod_map.loc[igroup,'GHGI_Emi_Group']][iyear]\n",
    "\n",
    "##Transport\n",
    "for igroup in np.arange(0,len(proxy_trans_map)):\n",
    "    proxy_temp = vars()['Proxy_'+proxy_trans_map.loc[igroup,'GHGI_Emi_Group']][:,:,:]\n",
    "    for iyear in np.arange(0,num_years):\n",
    "        proxy_frac = data_fn.safe_div(proxy_temp[:,:,iyear], np.sum(proxy_temp[:,:,iyear]))\n",
    "        ghgi_temp = vars()[proxy_trans_map.loc[igroup,'GHGI_Emi_Group']][iyear] * (1-CONUS_frac_trans[iyear])\n",
    "        Emissions_array_01_trans[:,:,iyear] += ghgi_temp * proxy_frac[:,:]\n",
    "        Emissions_nongrid[iyear] += vars()[proxy_trans_map.loc[igroup,'GHGI_Emi_Group']][iyear] - ghgi_temp\n",
    "\n",
    "##Refining\n",
    "for igroup in np.arange(0,len(proxy_ref_map)):\n",
    "    proxy_temp = vars()['Proxy_'+proxy_ref_map.loc[igroup,'GHGI_Emi_Group']][:,:,:]\n",
    "    for iyear in np.arange(0,num_years):\n",
    "        proxy_frac = data_fn.safe_div(proxy_temp[:,:,iyear], np.sum(proxy_temp[:,:,iyear]))\n",
    "        ghgi_temp = vars()[proxy_ref_map.loc[igroup,'GHGI_Emi_Group']][iyear] * (1-CONUS_frac_ref[iyear])\n",
    "        Emissions_array_01_ref[:,:,iyear] += ghgi_temp * proxy_frac[:,:]\n",
    "        Emissions_nongrid[iyear] += vars()[proxy_ref_map.loc[igroup,'GHGI_Emi_Group']][iyear] - ghgi_temp\n",
    "\n",
    "    \n",
    "for iyear in np.arange(0, num_years):    \n",
    "    calc_emi = np.sum(Emissions_array_01_expl[:,:,iyear])+np.sum(Emissions_array_01_prod[:,:,iyear])+ \\\n",
    "                np.sum(Emissions_array_01_trans[:,:,iyear])+np.sum(Emissions_array_01_ref[:,:,iyear])+ \\\n",
    "                np.sum(Emissions_nongrid[iyear]) \n",
    "\n",
    "    summary_emi = EPA_emi_total_Petr.iloc[0,iyear+1]+EPA_emi_total_Petr.iloc[1,iyear+1] +EPA_emi_total_Petr.iloc[2,iyear+1]+\\\n",
    "                    EPA_emi_total_Petr.iloc[3,iyear+1] \n",
    "    emi_diff = abs(summary_emi-calc_emi)/((summary_emi+calc_emi)/2)\n",
    "    if DEBUG==1:\n",
    "        print(calc_emi)\n",
    "        print(summary_emi)\n",
    "    if abs(emi_diff) < 0.0001:\n",
    "        print('Year '+ year_range_str[iyear]+': Difference < 0.01%: PASS')\n",
    "    else: \n",
    "        print('Year '+ year_range_str[iyear]+': Difference > 0.01%: FAIL, diff: '+str(emi_diff))\n",
    "        \n",
    "ct = datetime.datetime.now() \n",
    "print(\"current time:\", ct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Calculate Gridded Emission Fluxes (molec./cm2/s) (0.1x0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Convert emissions to emission flux\n",
    "# conversion: kt emissions to molec/cm2/s flux\n",
    "\n",
    "Flux_array_01_annual_expl = np.zeros([len(Lat_01),len(Lon_01),num_years])\n",
    "Flux_array_01_annual_prod = np.zeros([len(Lat_01),len(Lon_01),num_years])\n",
    "Flux_array_01_annual_trans = np.zeros([len(Lat_01),len(Lon_01),num_years])\n",
    "Flux_array_01_annual_ref = np.zeros([len(Lat_01),len(Lon_01),num_years])\n",
    "print('**QA/QC Check: Sum of national gridded emissions vs. GHGI national emissions')\n",
    "  \n",
    "for iyear in np.arange(0,num_years):\n",
    "    calc_emi = 0\n",
    "    if year_range[iyear]==2012 or year_range[iyear]==2016:\n",
    "        year_days = np.sum(month_day_leap)\n",
    "    else:\n",
    "        year_days = np.sum(month_day_nonleap)\n",
    "\n",
    "    conversion_factor_01 = 10**9 * Avogadro / float(Molarch4 *year_days * 24 * 60 *60) / area_matrix_01\n",
    "    Flux_array_01_annual_expl[:,:,iyear] = Emissions_array_01_expl[:,:,iyear]*conversion_factor_01\n",
    "    Flux_array_01_annual_prod[:,:,iyear] = Emissions_array_01_prod[:,:,iyear]*conversion_factor_01\n",
    "    Flux_array_01_annual_trans[:,:,iyear] = Emissions_array_01_trans[:,:,iyear]*conversion_factor_01\n",
    "    Flux_array_01_annual_ref[:,:,iyear] = Emissions_array_01_ref[:,:,iyear]*conversion_factor_01\n",
    "    #convert back to mass to check\n",
    "    conversion_factor_annual = 10**9 * Avogadro / float(Molarch4 *year_days * 24 * 60 *60) / area_matrix_01\n",
    "    calc_emi = np.sum(Flux_array_01_annual_expl[:,:,iyear]/conversion_factor_annual)+\\\n",
    "                np.sum(Flux_array_01_annual_prod[:,:,iyear]/conversion_factor_annual)+\\\n",
    "                np.sum(Flux_array_01_annual_trans[:,:,iyear]/conversion_factor_annual)+\\\n",
    "                np.sum(Flux_array_01_annual_ref[:,:,iyear]/conversion_factor_annual)+\\\n",
    "                np.sum(Emissions_nongrid[iyear])\n",
    "    summary_emi = EPA_emi_total_Petr.iloc[0,iyear+1]+EPA_emi_total_Petr.iloc[1,iyear+1] +EPA_emi_total_Petr.iloc[2,iyear+1]+\\\n",
    "                    EPA_emi_total_Petr.iloc[3,iyear+1] \n",
    "    emi_diff = abs(summary_emi-calc_emi)/((summary_emi+calc_emi)/2)\n",
    "    if DEBUG==1:\n",
    "        print(calc_emi)\n",
    "        print(summary_emi)\n",
    "    if abs(emi_diff) < 0.0001:\n",
    "        print('Year '+ year_range_str[iyear]+': Difference < 0.01%: PASS')\n",
    "    else: \n",
    "        print('Year '+ year_range_str[iyear]+': Difference > 0.01%: FAIL, diff: '+str(emi_diff))\n",
    "        \n",
    "Flux_Emissions_Total_annual_expl = Flux_array_01_annual_expl\n",
    "Flux_Emissions_Total_annual_prod = Flux_array_01_annual_prod\n",
    "Flux_Emissions_Total_annual_trans = Flux_array_01_annual_trans\n",
    "Flux_Emissions_Total_annual_ref = Flux_array_01_annual_ref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "## Step 5. Write netCDF\n",
    "------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yearly data\n",
    "#Initialize file\n",
    "data_IO_fn.initialize_netCDF(gridded_expl_outputfile, netCDF_expl_description, 0, year_range, loc_dimensions, Lat_01, Lon_01)\n",
    "\n",
    "# Write data to netCDF\n",
    "nc_out = Dataset(gridded_expl_outputfile, 'r+', format='NETCDF4')\n",
    "nc_out.variables['emi_ch4'][:,:,:] = Flux_Emissions_Total_annual_expl\n",
    "nc_out.close()\n",
    "#Confirm file location\n",
    "print('** SUCCESS **')\n",
    "print(\"Gridded emissions written to file: {}\" .format(os.getcwd())+gridded_expl_outputfile)\n",
    "print('')\n",
    "\n",
    "data_IO_fn.initialize_netCDF(gridded_prod_outputfile, netCDF_prod_description, 0, year_range, loc_dimensions, Lat_01, Lon_01)\n",
    "\n",
    "# Write data to netCDF\n",
    "nc_out = Dataset(gridded_prod_outputfile, 'r+', format='NETCDF4')\n",
    "nc_out.variables['emi_ch4'][:,:,:] = Flux_Emissions_Total_annual_prod\n",
    "nc_out.close()\n",
    "#Confirm file location\n",
    "print('** SUCCESS **')\n",
    "print(\"Gridded emissions written to file: {}\" .format(os.getcwd())+gridded_prod_outputfile)\n",
    "print('')\n",
    "\n",
    "data_IO_fn.initialize_netCDF(gridded_trans_outputfile, netCDF_trans_description, 0, year_range, loc_dimensions, Lat_01, Lon_01)\n",
    "\n",
    "# Write data to netCDF\n",
    "nc_out = Dataset(gridded_trans_outputfile, 'r+', format='NETCDF4')\n",
    "nc_out.variables['emi_ch4'][:,:,:] = Flux_Emissions_Total_annual_trans\n",
    "nc_out.close()\n",
    "#Confirm file location\n",
    "print('** SUCCESS **')\n",
    "print(\"Gridded emissions written to file: {}\" .format(os.getcwd())+gridded_trans_outputfile)\n",
    "print('')\n",
    "\n",
    "data_IO_fn.initialize_netCDF(gridded_ref_outputfile, netCDF_ref_description, 0, year_range, loc_dimensions, Lat_01, Lon_01)\n",
    "\n",
    "# Write data to netCDF\n",
    "nc_out = Dataset(gridded_ref_outputfile, 'r+', format='NETCDF4')\n",
    "nc_out.variables['emi_ch4'][:,:,:] = Flux_Emissions_Total_annual_ref\n",
    "nc_out.close()\n",
    "#Confirm file location\n",
    "print('** SUCCESS **')\n",
    "print(\"Gridded emissions written to file: {}\" .format(os.getcwd())+gridded_ref_outputfile)\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "## Step 6. Plot Gridded Data\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6.1. Plot Annual Emission Fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plot annual data for entire timeseries\n",
    "scale_max = 10\n",
    "save_flag = 0\n",
    "save_outfile = ''\n",
    "data_plot_fn.plot_annual_emission_flux_map(Flux_Emissions_Total_annual_expl, Lat_01, Lon_01, year_range, title_expl_str, scale_max,save_flag,save_outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plot annual data for entire timeseries\n",
    "scale_max = 10\n",
    "save_flag = 0\n",
    "save_outfile = ''\n",
    "data_plot_fn.plot_annual_emission_flux_map(Flux_Emissions_Total_annual_prod, Lat_01, Lon_01, year_range, title_prod_str, scale_max,save_flag,save_outfile)\n",
    "\n",
    "#Plot annual data for entire timeseries\n",
    "scale_max = 10\n",
    "save_flag = 0\n",
    "save_outfile = ''\n",
    "data_plot_fn.plot_annual_emission_flux_map(Flux_Emissions_Total_annual_trans, Lat_01, Lon_01, year_range, title_trans_str, scale_max,save_flag,save_outfile)\n",
    "\n",
    "#Plot annual data for entire timeseries\n",
    "scale_max = 10\n",
    "save_flag = 0\n",
    "save_outfile = ''\n",
    "data_plot_fn.plot_annual_emission_flux_map(Flux_Emissions_Total_annual_ref, Lat_01, Lon_01, year_range, title_ref_str, scale_max,save_flag,save_outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6.2 Plot Difference between first and last inventory year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot difference between last and first year\n",
    "save_flag = 0\n",
    "save_outfile = ''\n",
    "data_plot_fn.plot_diff_emission_flux_map(Flux_Emissions_Total_annual_expl, Lat_01, Lon_01, year_range, title_expl_diff_str,save_flag,save_outfile)\n",
    "\n",
    "save_flag = 0\n",
    "save_outfile = ''\n",
    "data_plot_fn.plot_diff_emission_flux_map(Flux_Emissions_Total_annual_prod, Lat_01, Lon_01, year_range, title_prod_diff_str,save_flag,save_outfile)\n",
    "\n",
    "save_flag = 0\n",
    "save_outfile = ''\n",
    "data_plot_fn.plot_diff_emission_flux_map(Flux_Emissions_Total_annual_trans, Lat_01, Lon_01, year_range, title_trans_diff_str,save_flag,save_outfile)\n",
    "\n",
    "save_flag = 0\n",
    "save_outfile = ''\n",
    "data_plot_fn.plot_diff_emission_flux_map(Flux_Emissions_Total_annual_ref, Lat_01, Lon_01, year_range, title_ref_diff_str,save_flag,save_outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = datetime.datetime.now() \n",
    "ft = ct.timestamp() \n",
    "time_elapsed = (ft-it)/(60*60)\n",
    "print('Time to run: '+str(time_elapsed)+' hours')\n",
    "print('** EXTENSION_GEPA_1B2a_Petroleum_Systems: COMPLETE **')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
